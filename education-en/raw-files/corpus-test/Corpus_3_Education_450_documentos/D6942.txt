#ITI#Low-stakes performance testing in Germany by the VERA assessment: analysis of the mode effects between computer-based testing and paper-pencil testing#FTI#
#IRE#The German school system employs centrally organized performance assessments (some of which are called “VERA”) as a way of promoting lesson development. In recent years, several German federal states introduced a computer-based performance testing system which will replace the paper-pencil testing system in the future. Scores from computer-based testing are required to be equivalent to paper-pencil testing scores so that the new testing medium does not lead to disadvantages for students. Therefore, the current study aimed at investigating the size of the mode effect and the moderating impact of students’ gender, academic achievement and mainly spoken language in everyday life. In addition, the variance of the mode effect across tasks was investigated. The study was conducted in four German federal states in 2019 using a field experimental design. The test scores of 5140 eighth-graders from 165 schools in the subject German were analysed. The results of multi-level modelling revealed that students’ test scores in the computerized version of the VERA test were significantly lower than in the paper-pencil version. Students with a lower academic achievement were more disadvantaged by the VERA computerized test. The results were inconsistent regarding the interactions between testing mode and students’ gender and mainly spoken language in everyday life. The variance of the mode effect across tasks was high. Research into different subjects and in other federal states and countries under different testing conditions might yield further evidence about the generalizability of these results#FRE#
#IPC#Computer-based testing; Lesson development; Paper-pencil testing; Performance tests#FPC#
#IRF#Ackerman R., Lauterman T., Taking reading comprehension exams on screen or on paper? A metacognitive analysis of learning texts under time pressure, Computers in Human Behavior, 28, 5, pp. 1816-1828, (2012); 
Cai Z., Fan X., Du J., Gender and attitudes toward technology use: A meta-analysis, Computers & Education, 105, pp. 1-13, (2017); 
Clariana R., Wallace P., Paper-based versus computer-based assessment: Key factors associated with the test mode effect, British Journal of Educational Technology, 33, 5, pp. 593-602, (2002); 
Csapo B., Molnar G., Nagy J., Computer-based assessment of school readiness and early reasoning, Journal of Educational Psychology, 106, 3, pp. 639-650, (2014); 
Dahan Golan D., Barzillai M., Katzir T., The effect of presentation mode on children’s reading preferences, performance, and self-evaluations, Computers & Education, 126, pp. 346-358, (2018); 
Overview of computer-based tests, Research proposal, (2017); 
Comparing the reading performance of high-achieving adolescents: Computer-based testing versus paper/pencil. Dissertation. Seton Hall University. Retrieved August 10, 2020 from, (2011); 
Eyre J., On or off screen reading in a digital world, Assessment News Set, 1, pp. 53-58, (2017); 
Gnambs T., The development of gender differences in information and communication technology (ICT) literacy in middle adolescence, Computers in Human Behavior, 114, (2021); 
Guimaraes B., Ribeiro J., Cruz B., Ferreira A., Alves H., Cruz Correia R., Madeira M.D., Ferreira M.A., Performance equivalency between computer-based and traditional pen-and-paper assessment: A case study in clinical anatomy, Anatomical Sciences Education, 11, 2, pp. 124-136, (2017); 
Hardcastle J., Herrmann-Abell C.F., DeBoer G.E., Comparing student performance on paper-and-pencil and computer-based-tests. Paper presented at the 2017 AERA Annual Meeting, San Antonio, TX. Retrieved December 8, 2020 from, (2017); 
Helmke A., Unterrichtsqualität und Lehrerprofessionalität. Diagnose, Evaluation und Verbesserung des Unterrichts [Quality of classroom practices and teachers‘ professionalism. Diagnosis, evaluation and improvement of lessons], (2012); 
Jerrim J., PISA 2012: how do results for the paper and computer tests compare? Assessment in Education: Principles, Policy & Practice, 23, 4, pp. 495-518, (2016); 
Jerrim J., Micklewright J., Heine J.-H., Salzer C., McKeown C., PISA 2015: how big is the ‘mode effect’ and what has been done about it?, Oxford Review of Education, 44, 4, pp. 476-493, (2018); 
Gesamtstrategie der Kultusministerkonferenz zum Bildungsmonitorin [Strategic approach of the Standing Conference of the Ministers of Education and Cultural Affairs on educational monitoring], Wolters Kluwer & KMK, (2016); 
Prisacari A.A., Measuring the testing mode in general chemistry: The effect of computer versus paper mode on test performance, cognitive load, and scratch paper, Dissertation. Iowa State University, (2017); 
Siddiq F., Scherer R., Is there a gender gap? A meta-analysis of the gender differences in students’ ICT literacy, Educational Research Review, 27, pp. 205-217, (2019); 
Stole H., Mangen A., Schwippert K., Assessing children’s reading comprehension on paper and screen: A mode-effect study, Computers & Education, 151, (2020); 
Sweller J., Cognitive load theory and educational technology, Educational Technology Research and Development, 68, 1, pp. 1-16, (2020); 
Van Deursen A.J.A.M., van Diepen S., Information and strategic Internet skills of secondary students: A performance test, Computers & Education, 63, pp. 218-226, (2013); 
Education considered in an internationally comparative context.] (pp. 129–162), Waxmann, (2018)#FRF#
