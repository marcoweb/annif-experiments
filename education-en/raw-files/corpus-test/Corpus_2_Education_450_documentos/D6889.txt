#ITI#Fairness of Academic Performance Prediction for the Distribution of Support Measures for Students: Differences in Perceived Fairness of Distributive Justice Norms#FTI#
#IRE#Artificial intelligence in higher education is becoming more prevalent as it promises improvements and acceleration of administrative processes concerning student support, aiming for increasing student success and graduation rates. For instance, Academic Performance Prediction (APP) provides individual feedback and serves as the foundation for distributing student support measures. However, the use of APP with all its challenges (e.g., inherent biases) significantly impacts the future prospects of young adults. Therefore, it is important to weigh the opportunities and risks of such systems carefully and involve affected students in the development phase. This study addresses students’ fairness perceptions of the distribution of support measures based on an APP system. First, we examine how students evaluate three different distributive justice norms, namely, equality, equity, and need. Second, we investigate whether fairness perceptions differ between APP based on human or algorithmic decision-making, and third, we address whether evaluations differ between students studying science, technology, engineering, and math (STEM) or social sciences, humanities, and the arts for people and the economy (SHAPE), respectively. To this end, we conducted a cross-sectional survey with a 2 × 3 factorial design among n = 1378 German students, in which we utilized the distinct distribution norms and decision-making agents as design factors. Our findings suggest that students prefer an equality-based distribution of support measures, and this preference is not influenced by whether APP is based on human or algorithmic decision-making. Moreover, the field of study does not influence the fairness perception, except that students of STEM subjects evaluate a distribution based on the need norm as more fair than students of SHAPE subjects. Based on these findings, higher education institutions should prioritize student-centric decisions when considering APP, weigh the actual need against potential risks, and establish continuous feedback through ongoing consultation with all stakeholders. © The Author(s) 2023.#FRE#
#IPC#Algorithmic decision-making; Algorithmic fairness; Distributive fairness; Higher education; Student support measures#FPC#
#IRF#Adams J.S., Inequity in social exchange, Advances in Experimental Social Psychology, 2, pp. 267-299, (1965); 
Adams Becker S., Cummins M., Davis A., Freeman A., Hall Giesinger C., Ananthanarayanan V., NMC Horizon Report: 2017 Higher Education Edition, Austin, (2017); 
Adams R., McIntyre N., England a-Level Downgrades Hit Pupils from Disadvantaged Areas Hardest: Analysis Also Shows Pupils at Private Schools Benefited Most from Algorithm, The Guardian, (2020); 
Ahmed S.A., Khan S.I., A machine learning approach to predict the engineering students at risk of dropout and factors behind: Bangladesh perspective, In 10Th International Conference on Computing, Communication and Networking Technologies (ICCCNT), pp. 1-6, (2019); 
Allison S.T., Messick D.M., Social decision heuristics in the use of shared resources, Journal of Behavioral Decision Making, 3, 3, pp. 195-204, (1990); 
Allison S.T., McQueen L.R., Schaerfl L.M., Social decision making processes and the equal partitionment of shared resources, Journal of Experimental Social Psychology, 28, 1, pp. 23-42, (1992); 
Alturki S., Hulpus I., Stuckenschmidt H., Predicting academic outcomes: A survey from 2007 till 2018, Technology, Knowledge and Learning, 27, 1, pp. 275-307, (2022); 
Alyahyan E., Dustegor D., Predicting academic success in higher education: Literature review and best practices: Literature review and best Practices, International Journal of Educational Technology in Higher Education, 17, 1, pp. 1-21, (2020); 
Ananny M., Crawford K., Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability, New Media & Society, 20, 3, pp. 973-989, (2018); 
Angwin J., Larson J., Mattu S., Kirchner L., Machine bias: There’s software used across the country to predict future criminals, And It’s Biased against Blacks. Propublica, (2016); 
Araujo T., Helberger N., Kruikemeier S., de Vreese C.H., Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability, AI & Society, 35, 3, pp. 611-623, (2020); 
Arcidiacono P., Hotz V.J., Kang S., Modeling college major choices using elicited measures of expectations and counterfactuals, Journal of Econometrics, 166, 1, pp. 3-16, (2012); 
Armatas C., Kwong T., Chun C., Spratt C., Chan D., Kwan J., Learning analytics for programme review: Evidence, analysis, and action to improve student learning outcomes, Technology, Knowledge and Learning, 27, 2, pp. 461-478, (2022); 
Arnold K.E., Pistilli M.D., Course Signals at Purdue: Using Learning Analytics to Increase Student Success, Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge (LAK 2012), pp. 267-270, (2012); 
Asaria M., Costa-Font J., Cowell F., How does exposure to COVID-19 influence health and income inequality aversion?, Social Choice and Welfare, 61, pp. 625-647, (2023); 
Attaran M., Stark J., Stotler D., Opportunities and challenges for big data analytics in US higher education, Industry and Higher Education, 32, 3, pp. 169-182, (2018); 
Bai B., Dai H., Zhang D., Zhang F., Hu H., The impacts of algorithmic work assignment on fairness perceptions and productivity: Evidence from field experiments, In Academy of Management Proceedings: 81St Annual Meeting of the Academy of Management 2021: Bringing the Manager Back in Management, Aom 2021, (2021); 
Bai B., Dai H., Zhang D.J., Zhang F., Hu H., The Impacts of Algorithmic Work Assignment on Fairness Perceptions and Productivity: Evidence from Field Experiments, Manufacturing & Service Operations Management, 24, 6, pp. 3060-3078, (2022); 
Baker R.S., Hawn A., Algorithmic Bias in education, International Journal of Artificial Intelligence in Education, 32, 4, pp. 1052-1092, (2022); 
Berens J., Schneider K., Gortz S., Oster S., Burghoff J., Early detection of students at risk - predicting student dropouts using administrative student data from German universities and machine learning methods, Journal of Educational Data Mining, 11, 3, pp. 1-41, (2019); 
Bettinger E.P., Baker R.B., The effects of student coaching: An evaluation of a randomized experiment in student advising, Educational Evaluation and Policy Analysis, 36, 1, pp. 3-19, (2014); 
Boyd D., Crawford K., Critical questions for big data: Provocations for a cultural, technological, and scholarly phenomenon, Information, Communication & Society, 15, 5, pp. 662-679, (2012); 
Brade R., Himmler O., Jackle R., Normatively framed relative performance feedback – Field experiment and replication, Munich: MPRA Paper No, (2018); 
Burton J.W., Stein M.-K., Blegind Jensen T., A systematic review of algorithm aversion in augmented decision making, Journal of Behavioral Decision Making, 33, 2, pp. 220-239, (2020); 
Busuioc M., Accountable artificial intelligence: Holding algorithms to account: Holding algorithms to account, Public Administration Review, 81, 5, pp. 825-836, (2021); 
Cheng H.-F., Stapleton L., Wang R., Bullock P., Chouldechova A., Wu Z.S.S., Zhu H., Soliciting stakeholders’ fairness notions in child maltreatment predictive systems, In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI ’21), Edited by Yoshifumi Kitamura, Aaron Quigley, Katherine Isbister, Takeo Igarashi, Pernille Bjørn, and Steven Drucker, Pp, pp. 1-17, (2021); 
Coenen J., Borghans L., Diris R., Personality traits, preferences and educational choices: A focus on STEM, Journal of Economic Psychology, 84, pp. 1-16, (2021); 
Cropanzano R.S., Ambrose M.L., The Oxford handbook of justice in the workplace, Oxford University Press, (2015); 
Three Roads to Organizational Justic, Research in Personnel and Human Resources Management (, 20, pp. 1-113, (2001); 
Fair Machine Learning Under Partial Compliance, Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society (AIES ’21), pp. 55-65, (2021); 
Daniel B., Big data and analytics in higher education: Opportunities and challenges, British Journal of Educational Technology, 46, 5, pp. 904-920, (2015); 
de Cremer D., McGuire J., Human-algorithm collaboration works best if humans lead (Because It Is Fair!), Social Justice Research, 35, 1, pp. 33-55, (2022); 
de Fine Licht K., de Fine Licht J., Artificial intelligence, transparency, and public decision-making: Why explanations are key when trying to produce perceived legitimacy, AI & Society, 35, 4, pp. 917-926, (2020); 
Gomes De Sousa W., Pereira De Melo E.R., de Souza Bermejo P.H., Sousa Farias R.A., Oliveira Gomes A., How and where is artificial intelligence in the public sector going? A literature review and research agenda, Government Information Quarterly, 36, 4, pp. 1-14, (2019); 
Bildung Und Kultur: Studierende an Hochschule, Statistisches Bundesamt (Ed.), (Fachserie 11, Reihe, 4, (2021); 
Deutsch M., Equity, equality, and need: What determines which value will be used as the basis of distributive justice?, Journal of Social Issues, 31, 3, pp. 137-149, (1975); 
Diakopoulos N., Accountability in algorithmic decision making, Communications of the ACM, 59, 2, pp. 56-62, (2016); 
Dietvorst B.J., Bharti S., People reject algorithms in uncertain decision domains because they have diminishing sensitivity to forecasting error, Psychological Science, 31, 10, pp. 1302-1314, (2020); 
Dietvorst B.J., Simmons J.P., Massey C., Algorithm aversion: People erroneously avoid algorithms after seeing them Err, Journal of Experimental Psychology: General, 144, 1, pp. 114-126, (2015); 
Dwork C., Hardt M., Pitassi T., Reingold O., Zemel R., Fairness through awareness, Proceedings of the 3Rd Innovations in Theoretical Computer Science Conference on - ITCS ’12, pp. 214-226, (2012); 
Edwards C., Let the algorithm decide?, Communications of the ACM, 64, 6, pp. 21-22, (2021); 
The promise and peril of predictive analytics in higher education: A landscape analysis.”, (2016); 
Ethics guidelines for trustworthy AI, European Commission., (2019); 
Faul F., Erdfelder E., Buchner A., Lang A.G., Statistical power analyses using g*power 3.1: Tests for correlation and regression analyses, Behavior Research Methods, 41, 4, pp. 1149-1160, (2009); 
Fazelpour S., Danks D., Algorithmic bias: Senses, sources, solutions, Philosophy Compass, 16, 8, pp. 1-16, (2021); 
Folger R., Cropanzano R., Fairness theory: Justice as accountability, Advances in Organizational Justice, pp. 3-55, (2001); 
Friedler S.A., Scheidegger C., Venkatasubramanian S., The (Im)possibility of fairness, Communications of the ACM, 64, 4, pp. 136-143, (2021); 
Gibson J.P., Mourad T., The growing importance of data literacy in life science education, American Journal of Botany, 105, 12, pp. 1953-1956, (2018); 
Greenberg J., A taxonomy of organizational justice theories, Academy of Management Review, 12, 1, pp. 9-22, (1987); 
Greenberg J., Organizational justice: Yesterday, today, and tomorrow, Journal of Management, 16, 2, pp. 399-432, (1990); 
Greenberg J., The social side of fairness: Interpersonal and informational classes of organizational justice, Justice in the Workplace, pp. 79-103, (1993); 
Hagendorff T., Wezel K., 15 challenges for AI: Or What AI (Currently) Can’t Do, AI & Society, 35, 2, pp. 355-365, (2020); 
Harrison G., Hanson J., Jacinto C., Ramirez J., Ur B., An Empirical Study on the Perceived Fairness of Realistic, Imperfect Machine Learning Models, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 392-402, (2020); 
Hausmann L.R.M., Ye F., Schofield J.W., Woods R.L., Sense of belonging and persistence in white and African American first-year students, Research in Higher Education, 50, 7, pp. 649-669, (2009); 
Helberger N., Araujo T., de Vreese C.H., Who is the fairest of them all? Public attitudes and expectations regarding automated decision-making: Public attitudes and expectations regarding automated decision-making, Computer Law & Security Review, 39, pp. 1-16, (2020); 
Holzinger A., Interactive machine learning for health informatics: When do we need the human-in-the-loop?, Brain Informatics, 3, 2, pp. 119-131, (2016); 
Howell J.A., Roberts L.D., Seaman K., Gibson D.C., Are we on our way to becoming a ‘helicopter university’? Academics’ views on learning analytics, Technology, Knowledge and Learning, 23, 1, pp. 1-20, (2018); 
Hsu S., Li T.W., Zhang Z., Fowler M., Zilles C., Karahalios K., Attitudes surrounding an imperfect AI autograder, Proceedings of the 2021 Chi Conference on Human Factors in Computing Systems (CHI ’21), pp. 1-15, (2021); 
Humburg M., Personality and field of study choice in university, Education Economics, 25, 4, pp. 366-378, (2017); 
Huppert E., Cowell J.M., Cheng Y., Contreras-Ibanez C., Gomez-Sicard N., Gonzalez-Gadea M.L., Huepe D., Et al., The development of children’s preferences for equality and equity across 13 individualistic and collectivist cultures, Developmental Science, 22, 2, pp. 1-16, (2019); 
Jang Y., Choi S., Kim H., Development and validation of an instrument to measure undergraduate students’ attitudes toward the ethics of artificial intelligence (AT-EAI) and analysis of its difference by gender and experience of AI education, Education and Information Technologies, 27, 8, pp. 11635-11667, (2022); 
Jiang W., Pardos Z.A., Towards equity and algorithmic fairness in student grade prediction, Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, pp. 608-617, (2021); 
Jones M., Molly D.A., Lahiri A., Shape the future: How the social sciences, humanities and the arts can SHAPE a positive, post-pandemic future for peoples, economies and environments, Journal of the British Academy, 8, pp. 167-266, (2020); 
Jorgensen T.D., Pornprasertmanit S., Schoemann A.M., Rosseel Y., SemTools: Useful tools for structural equation modeling, (2019); 
Kaibel C., Koch-Bayram I., Biemann T., Muhlenbock M., Applicant perceptions of hiring algorithms - Uniqueness and discrimination experiences as moderators, Academy of Management Proceedings, 2019, 1, (2019); 
Kasinidou M., Kleanthous S., Barlas P., Otterbacher J., I agree with the decision, but they didn’t deserve this: Future developers’ perception of fairness in algorithmic decisions, In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 690-700, (2021); 
Keller B., Lunich M., Marcinkowski F., How is socially responsible academic performance prediction possible? Insights from a Concept of Perceived AI Fairness, Strategy, Policy, Practice, and Governance for AI in Higher Education Institutions, pp. 126-155, (2022); 
Kemper L., Vorhoff G., Wigger B.U., Predicting student dropout: A machine learning approach, European Journal of Higher Education, 10, 1, pp. 28-47, (2020); 
Knox J., Hoel T., Yuan L., . From principles to processes: Lessons from higher education from the development of AI ethics, Strategy, Policy, Practice, and Governance for AI in Higher Education Institutions, pp. 101-125, (2022); 
Konig P.D., Wenzelburger G., Between technochauvinism and human-centrism: Can algorithms improve decision-making in democratic politics?, European Political Science, 21, 1, pp. 132-149, (2022); 
Chiteng Kot F., The impact of centralized advising on first-year academic performance and second-year enrollment behavior, Research in Higher Education, 55, 6, pp. 527-563, (2014); 
Kotsiantis S.B., Use of machine learning techniques for educational proposes: A decision support system for forecasting students' grades, Artificial Intelligence Review, 37, 4, pp. 331-344, (2012); 
Kusner M., Loftus J., Russell C., Silva R., Counterfactual Fairness, .), NIPS’17: Proceedings of the 31St International Conference on Neural Information Processing Systems, pp. 1-11, (2017); 
Lee M.K., Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management, Big Data & Society, 5, 1, pp. 1-16, (2018); 
Lee M.K., Baykal S., Algorithmic mediation in group decisions: Fairness perceptions of algorithmically mediated Vs. discussion-based social division, In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, pp. 1035-1048, (2017); 
Lee M.K., Rich K., Who is included in human perceptions of AI?: Trust and perceived fairness around healthcare AI and cultural mistrust: Trust and perceived fairness around healthcare AI and cultural mistrust, In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-14, (2021); 
Lee M.K., Kim J.T., Lizarondo L., A human-centered approach to algorithmic services: Considerations for fair and motivating smart community service management that allocates donations to non-profit organizations, Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp. 3365-3376, (2017); 
Lee M.K., Jain A., Cha H.J., Ojha S., Kusbit D., Procedural justice in algorithmic fairness: Leveraging transparency and outcome control for fair algorithmic mediation, Proceedings of the ACM on Human-Computer Interaction, 3, pp. 1-26, (2019); 
Lee M.K., Kusbit D., Kahng A., Kim J.T., Yuan X., Chan A., See D., Et al., WeBuildAI: Participatory framework for algorithmic governance, Proceedings of the ACM on Human-Computer Interaction, 3, pp. 1-35, (2019); 
Legault L., Green-Demers I., Pelletier L., Why do high school students lack motivation in the classroom? Toward an understanding of academic amotivation and the role of social support, Journal of Educational Psychology, 98, 3, pp. 567-582, (2006); 
Little T.D., Slegers D.W., Card N.A., A non-arbitrary method of identifying and scaling latent variables in SEM and MACS models, Structural Equation Modeling: A Multidisciplinary Journal, 13, 1, pp. 59-72, (2006); 
Logg J.M., Minson J.A., Moore D.A., Algorithm appreciation: People prefer algorithmic to human judgment, Organizational Behavior and Human Decision Processes, 151, pp. 90-103, (2019); 
Lunich M., Kieslich K., Exploring the roles of trust and social group preference on the legitimacy of algorithmic decision-making Vs. Human decision-making for allocating COVID-19 vaccinations, AI & SOCIETY, pp. 1-19, (2022); 
Mah D.-K., Learning analytics and digital badges: Potential impact on student retention in higher education, Technology, Knowledge and Learning, 21, 3, pp. 285-305, (2016); 
Makhlouf K., Zhioua S., Palamidessi C., Machine learning fairness notions: Bridging the gap with real-world applications, Information Processing & Management, 58, 5, pp. 1-32, (2021); 
Mantymaki M., Minkkinen M., Birkstedt T., Viljanen M., Defining organizational AI governance, AI and Ethics, 2, 4, pp. 603-609, (2022); 
Marcinkowski F., Kieslich K., Starke C., Lunich M., Implications of AI (Un-)fairness in Higher Education Admissions: The Effects of Perceived AI (Un-)Fairness on Exit, Voice and Organizational Reputation, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* ’20, pp. 122-130, (2020); 
Martinez Neda B., Zeng Y., Gago-Masague S., Using machine learning in admissions: Reducing human and algorithmic bias in the selection process, Proceedings of the 52Nd ACM Technical Symposium on Computer Science Education (SIGCSE ’21) (P, (2021); 
Morand D., Merriman K., Deckop J., Making sense of egalitarian pay: Reconceptualising its treatment in organisations, Human Resource Management Journal, 30, 2, pp. 180-197, (2020); 
Morosanu L., Handley K., O'Donovan B., Seeking support: Researching first-year students’ experiences of coping with academic life, Higher Education Research & Development, 29, 6, pp. 665-678, (2010); 
Munoz C., Megan S., Patil D.J., Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights., (2016); 
Murphy S.P., Fairness, Encyclopedia of Global Justice, pp. 336-340, (2011); 
Neugebauer M., Heublein U., Daniel A., Studienabbruch in Deutschland: Ausmaß, Ursachen, Folgen, Präventionsmöglichkeiten, Zeitschrift für Erziehungswissenschaft, 22, 5, pp. 1025-1046, (2019); 
Nguyen M.-T., Tran-Tien M., Viet A.P., Vu H.-T., Nguyen V.-H., Building a chatbot for supporting the admission of universities, Proceedings of 2021 13Th International Conference Knowledge and Systems Engineering (KSE 2021) (, pp. 1-6, (2021); 
Nyarko J., Goel S., Sommers R., Breaking taboos in fair machine learning: An experimental study: An experimental study, In Equity and Access in Algorithms, pp. 1-11, (2021); 
Olaya D., Vasquez J., Maldonado S., Miranda J., Verbeke W., Uplift Modeling for preventing student dropout in higher education, Decision Support Systems, 134, pp. 1-11, (2020); 
Ornelas F., Ordonez C., Predicting student success: A Naïve Bayesian application to community college data, Technology, Knowledge and Learning, 22, 3, pp. 299-315, (2017); 
Orwat C., Risks of Discrimination Through the Use of Algorithms: A Study Compiled with a Grant from the Federal Anti-Discrimination Agency, (2020); 
Pelletier K., Brown M., Brooks D.C., McCormack M., Reeves J., Arbino N., Bozkurt A., Et al., 2021 EDUCAUSE Horizon Report: Teaching and Learning Edition, (2021); 
Pistilli M.D., Arnold K.E., Purdue signals: Mining real-time academic data to enhance student success, About Campus, 15, 3, pp. 22-24, (2010); 
Pozzebon J.A., Ashton M.C., Visser B.A., Major changes: Personality, ability, and congruence in the prediction of academic outcomes, Journal of Career Assessment, 22, 1, pp. 75-88, (2014); 
Rawls J., A Theory of Justice, (1999); 
Rosseel Y., Lavaan: An r package for structural equation modeling, Journal of Statistical Software, 48, 2, pp. 1-26, (2012); 
Abu Saa A., Al-Emran M., Shaalan K., Factors affecting students’ performance in higher education: A systematic review of predictive data mining techniques, Technology, Knowledge and Learning, 24, 4, pp. 567-598, (2019); 
Saha D., Schumann C., McElfresh D.C., Dickerson J.P., Mazurek M.L., Tschantz M.C., Human comprehension of fairness in machine learning, Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, (2020); 
Saxena N.A., Huang K., DeFilippis E., Radanovic G., Parkes D.C., Liu Y., How do fairness definitions fare? Testing public attitudes towards three algorithmic definitions of fairness in loan allocations: Testing public attitudes towards three algorithmic definitions of fairness in loan allocations, Artificial Intelligence, 283, pp. 1-15, (2020); 
Schlicker N., Langer M., Otting S., Baum K., Konig C.J., Wallach D., What to expect from opening up ‘black boxes’? Comparing perceptions of justice between human and automated agents, Computers in Human Behavior, 122, pp. 1-16, (2021); 
Jisc briefing: Learning analytics and student success - assessing the evidence.”, Jisc., (2017); 
Sen A.K., The Idea of Justice, (2009); 
Sherrick M.F., Davenport C.A., Colina T.L., Flexibility and satisfaction with college major, Journal of Counseling Psychology, 18, 5, pp. 487-489, (1971); 
Shin D., Toward fair, accountable, and transparent algorithms: Case studies on algorithm initiatives in Korea and China, Javnost - The Public, 26, 3, pp. 274-290, (2019); 
Shin D., User perceptions of algorithmic decisions in the personalized AI system: Perceptual evaluation of fairness, accountability, transparency, and explainability, Journal of Broadcasting & Electronic Media, 64, 4, pp. 541-565, (2020); 
Shin D., The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI, International Journal of Human-Computer Studies, 146, pp. 1-10, (2021); 
Shin D., Zhong B., Biocca F.A., Beyond user experience: What constitutes algorithmic experiences?, International Journal of Information Management, 52, 3, pp. 1-11, (2020); 
Shneiderman B., Bridging the gap between ethics and practice: Guidelines for reliable, safe, and trustworthy human-centered AI systems, ACM Transactions on Interactive Intelligent Systems, 10, 4, pp. 1-31, (2020); 
Slade S., Prinsloo P., Learning analytics: Ethical issues and dilemmas, American Behavioral Scientist, 57, 10, pp. 1510-1529, (2013); 
Smith H., Algorithmic bias: Should students pay the price?, AI & Society, 35, 4, pp. 1077-1078, (2020); 
Smith B.O., Shrader R., White D.R., Wooten J., Dogbey J., Nath S., O'Hara M., Nan X., Rosenman R., Improving student performance through loss aversion, Scholarship of Teaching and Learning in Psychology, 5, 4, pp. 278-288, (2019); 
Srivastava M., Heidari H., Kraus A., Mathematical notions Vs. Human perception of fairness: A descriptive approach to fairness for machine learning, Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD ’19) (Pp., pp. 2459-2468, (2019); 
Starke C., Lunich M., Artificial intelligence for political decision-making in the European Union: Effects on Citizens’ perceptions of input, throughput, and output legitimacy, Data & Policy, 2, pp. 1-17, (2020); 
Starke C., Baleis J., Keller B., Marcinkowski F., Fairness perceptions of algorithmic decision-making: A systematic review of the empirical literature, Big Data & Society, 9, 2, pp. 1-16, (2022); 
Stegmann H., Abiturient Und Studium: Bestimmungsfaktoren für Die Studienaufnahme Und Die Wahl Des Studiengangs, Mitteilungen Aus Der Arbeitsmarkt- Und Berufsforschung, 13, pp. 531-542, (1980); 
Sun L., Tang Y., Data-driven discrimination, perceived fairness, and consumer trust-the perspective of consumer attribution, Frontiers in Psychology, 12, pp. 1-13, (2021); 
Thurman N., Moeller J., Helberger N., Trilling D., My Friends, Editors, Algorithms, and I: Examining audience attitudes to news selection, Digital Journalism, 7, 4, pp. 447-469, (2019); 
Tinto V., Dropout from higher education: A theoretical synthesis of recent research, Review of Educational Research, 45, 1, pp. 89-125, (1975); 
Tversky A., Kahneman D., Loss aversion in riskless choice: A reference-dependent model, The Quarterly Journal of Economics, 106, 4, pp. 1039-1061, (1991); 
Fairness and decision-making in collaborative shift scheduling systems, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-13, (2020); 
van Hootegem A., Abts K., Meuleman B., Differentiated Distributive Justice Preferences? Configurations of preferences for equality, equity and need in three welfare domains, Social Justice Research, 33, 3, pp. 257-283, (2020); 
Veale M., Binns R., Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data: Mitigating discrimination without collecting sensitive data, Big Data & Society, 4, 2, pp. 1-17, (2017); 
Vedel A., Big five personality group differences across academic majors: A systematic review, Personality and Individual Differences, 92, pp. 1-10, (2016); 
Verbree A.-R., Maas L., Hornstra L., Wijngaards-de Meij L., Personality predicts academic achievement in higher education: Differences by academic field of study?, Learning and Individual Differences, 92, pp. 1-11, (2021); 
Verma S., Rubin J., Fairness Definitions Explained, Proceedings of the 40Th International Workshop on Software Fairness (ICSE ’18), pp. 1-7, (2018); 
Vieira D., Chinchilla J.R., Liu B.L., Yerovi C., Morales D., Beyond the chatbot: How are universities using ai nowadays?, IGI Global, (2022); 
Factors influencing perceived fairness in algorithmic decision-making, .), Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-14, (2020); 
Webb H., Koene A., Patel M., Vallejos E.P., Multi-stakeholder dialogue for policy recommendations on algorithmic fairness, In Proceedings of the 9Th International Conference on Social Media and Society, pp. 395-399, (2018); 
Wenzelburger G., Hartmann K., Explaining the rise and the fall of a policy: Investigating the introduction and the dismantling of a French University admission policy through the lens of the multiple streams framework., (2021); 
Wenzelburger G., Hartmann K., Policy formation, termination and the multiple streams framework: the case of introducing and abolishing automated university admission in France, Policy Studies, 43, 5, pp. 1075-1095, (2022); 
Wirtz B.W., Muller W.M., An integrated artificial intelligence framework for public management, Public Management Review, 21, 7, pp. 1076-1100, (2019); 
Wirtz B.W., Weyerer J.C., Geyer C., Artificial intelligence and the public sector-applications and challenges, International Journal of Public Administration, 42, 7, pp. 596-615, (2019); 
Wong P.H., Democratizing algorithmic fairness, Philosophy & Technology, 33, 2, pp. 225-244, (2020); 
Yilmaz K., Gizem F., Yilmaz R., Student opinions about personalized recommendation and feedback based on learning analytics, Technology, Knowledge and Learning, 25, 4, pp. 753-768, (2020); 
Zawacki-Richter O., Marin V.I., Bond M., Gouverneur F., Systematic review of research on artificial intelligence applications in higher education - Where are the educators?, International Journal of Educational Technology in Higher Education, 16, 1, pp. 1-27, (2019); 
Zhou J., Verma S., Mittal M., Chen F., Understanding relations between perception of fairness and trust in algorithmic decision making, In Proceedings of the 8Th International Conference on Behavioral and Social Computing (BESC, 2021, pp. 1-5, (2021)#FRF#
