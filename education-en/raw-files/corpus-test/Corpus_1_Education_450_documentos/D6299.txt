#ITI#Learning from failure: A context-informed perspective on RCTs#FTI#
#IRE#Discussions of randomised controlled trials (RCTs) in education that do not show an impact regularly focus on the intervention and how it failed to impact on expected measures, with typologies identifying persistent critical points of failure. This paper uses one such RCT—the Integrating English programme—to exemplify the application of a new model to explain failure in RCTs. To do so, the paper develops a set of categories of context drawing on the wider social evaluation field: backdrop, design, operation and interpretation. Thus, the paper exposes critical weak points in the commission and interpretation, as well as the implementation, of an RCT. Our aim is to work towards more robust evaluations by demonstrating that it is not simply the programme design, implementation and evaluation that can contribute to a lack of impact; there can be more fundamental system issues at play#FRE#
#IPC#programme development; randomised controlled trials; selected contextual issues#FPC#
#IRF#Acosta S., Garza T., Hsu H.Y., Goodson P., Padron Y., Goltz H.H., Johnston A., The accountability culture: A systematic review of high-stakes testing and English learners in the United States during No Child Left Behind, Educational Psychology Review, 32, 2, pp. 327-352, (2020); 
Au W., High-stakes testing and curricular control: A qualitative metasynthesis, Educational Researcher, 36, 5, pp. 258-267, (2007); 
Boylan M., Coldwell M., Maxwell B., Jordan J., Rethinking models of professional learning as tools: A conceptual analysis to inform research and practice, Professional Development in Education, 44, 1, pp. 120-139, (2018); 
Breuer E., Lee L., De Silva M., Lund C., Using theory of change to design and evaluate public health interventions: A systematic review, Implementation Science, 11, 1, (2015); 
Brill F., Grayson H., Kuhn L., O'Donnell S., What impact does accountability have on curriculum, standards and engagement in education? A literature review, (2018); 
Burnett C., Coldwell M., Randomised controlled trials and the interventionisation of education, Oxford Review of Education, 47, 4, pp. 423-438, (2021); 
Coldwell M., Reconsidering context: Six underlying features of context to improve learning from evaluation, Evaluation, 25, 1, pp. 99-117, (2019); 
Coldwell M., Maxwell B., Using evidence-informed logic models to bridge methods in educational evaluation, The Review of Education, 6, 3, pp. 267-300, (2018); 
Connell J., Kubisch A., Applying a theory of change approach to the evaluation of comprehensive community initiatives: Progress, prospects and problems, New approaches to evaluating community initiatives, Vol. 2: Theory, measurement and analysis, (1998); 
Culliney M., Moore N., Coldwell M., Demack S., Integrating English – evaluation report, (2019); 
Cushing I., Grammar tests, de facto policy and pedagogical coercion in England's primary schools, Language Policy, 20, pp. 599-622, (2021); 
Custance B., Dare B., Polias J., Teaching ESL students in mainstream classrooms: Language in learning across the curriculum, (2012); 
De Costa P., Qin K., English language education in the United States: Past, present and future issues, English language education in a global world, pp. 229-238, (2015); 
Eccles M., Mittman B., Editorial: Welcome to Implementation Science, Implementation Science, 1, 1, pp. 1-3, (2006); 
Annual report 2019, (2019); 
Education Endowment Foundation projects, (2022); 
Education Endowment Foundation: Who we are, (2022); 
Pipeline of EEF trials, (2023); 
Integrating English EEF, (2023); 
Fang Z., Schleppegrell M., Disciplinary literacies across content areas: Supporting secondary reading through functional language analysis, Journal of Adolescent and Adult Literacy, 53, 7, pp. 587-597, (2010); 
Gillborn D., Warmington P., Demack S., QuantCrit: Education, policy, ‘big data’ and principles for a critical race theory of statistics, Race Ethnicity and Education, 21, 2, pp. 158-179, (2018); 
Greany T., Higham R., Hierarchy, markets and networks: Analysing the ‘self-improving school-led system’ agenda in England and the implications for schools, (2018); 
Greenhalgh J., Manzano A., Understanding ‘context’ in realist evaluation and synthesis, International Journal of Social Research Methodology, 25, pp. 583-595, (2021); 
Halliday M.A.K., Towards a language-based theory of learning, Linguistics and Education, 5, pp. 93-116, (1993); 
Haynes L., Service O., Goldacre B., Torgerson D., Test, learn, adapt: Developing public policy with randomised control trials, (2012); 
Humphrey N., Lendrum A., Ashworth E., Frearson K., Buck R., Kerr K., Implementation and process evaluation (IPE) for interventions in educational settings: A synthesis of the literature, (2016); 
Humphrey N., Lendrum A., Ashworth E., Frearson K., Buck R., Kerr K., Implementation and process evaluation (IPE) for interventions in education settings: An introductory handbook, (2019); 
Hutchinson J., Educational outcomes of children with English as an additional language, (2018); 
Jacob R.T., Doolittle F., Kemple J., Somers M.-A., A framework for learning from null results, Educational Researcher, 48, 9, pp. 580-589, (2019); 
Jacobson M.J., Levin J.A., Kapur M., Education as a complex system: Conceptual and methodological implications, Educational Researcher, 48, 2, pp. 112-119, (2019); 
Law J., Ruppert E., The social life of methods: Devices, Journal of Cultural Economy, 6, 3, pp. 229-240, (2013); 
Lendrum A., Humphrey N., The importance of studying the implementation of interventions in school settings, Oxford Review of Education, 38, 5, pp. 635-652, (2012); 
Long R., Danechi S., Teacher recruitment and retention in England, (2022); 
Lortie-Forgues H., Inglis M., Rigorous large-scale educational RCTs are often uninformative: Should we be concerned?, Educational Researcher, 48, 3, pp. 158-166, (2019); 
Mausethagen S., A research review of the impact of accountability policies on teachers' workplace relations, Educational Research Review, 9, pp. 16-33, (2013); 
Maxwell B., Sharples J., Coldwell M., Developing a systems-based approach to research use in education, The Review of Education, 10, 3, (2022); 
Messick S., Meaning and values in test validation: The science and ethics of assessment, Educational Researcher, 18, 2, pp. 5-11, (1989); 
Murphy V.A., Unthiah A., A systematic review of intervention research examining English language and literacy development in children with English as an additional language (EAL), (2015); 
Nevill C., EEF blog: Randomised control trials – 3 good things, 3 bad things, and 5 top tips, (2019); 
Nielsen K., Fredslund H., Christensen K.B., Albertsen K., Success or failure? Interpreting and understanding the impact of interventions in four similar worksites, Work and Stress, 20, 3, pp. 272-287, (2006); 
Nielsen S.B., Lemire S., Tangsig S., Unpacking context in realist evaluations: Findings from a comprehensive review, Evaluation, 28, 1, pp. 91-112, (2021); 
Opfer V.D., Pedder D., Conceptualizing teacher professional learning, Review of Educational Research, 81, 3, pp. 376-407, (2011); 
Pawson R., The science of evaluation: A realist manifesto, (2013); 
Pawson R., Tilley N., Realistic evaluation, (1997); 
Rog D.J., When background becomes foreground: Toward context-sensitive evaluation practice, Context: A framework for its influence on evaluation practice, 135, pp. 25-40, (2012); 
Rogers P., Theory of change, methodological briefs: Impact evaluation 2, (2014); 
Rogers P.J., Implications of complicated and complex characteristics for key tasks in evaluation, Evaluating the complex – attribution, contribution and beyond, pp. 33-52, (2011); 
Rogers P.J., Weiss C.H., Theory-based evaluation: Reflections ten years on. Theory-based evaluation: Past, present, and future, New Directions for Evaluation, 114, pp. 63-81, (2007); 
Rose D., Martin J.R., Learning to write, reading to learn: Genre, knowledge and pedagogy of the Sydney school, (2012); 
Smith B., Morris S., Armitage H., The effects of using examination grade as a primary outcome in education trials to evaluate school-based interventions, (2021); 
Stame N., What doesn't work? Three failures, many answers, Evaluation, 16, 4, pp. 371-387, (2010); 
Strand S., Malmberg L., Hall J., English as an additional language (EAL) and educational achievement in England: An analysis of the National Pupil Database, (2015); 
Strom K.J., Mills T., Abrams L., Non-linear perspectives on teacher development – complexity in professional learning and practice, (2023); 
Supovitz J., Can high stakes testing leverage educational improvement? Prospects from the last decade of testing and accountability reform, Journal of Educational Change, 10, pp. 211-227, (2009); 
Thompson G., Lingard B., Ball S.J., ‘Indentured autonomy’: Headteachers and academisation policy in Northern England, Journal of Educational Administration and History, 53, 3-4, pp. 215-232, (2021); 
Unsworth L., Tytler R., Fenwick L., Humphrey S., Chandler P., Herrington M., Pham L., Multimodal literacy in school science – transdisciplinary perspectives on theory, research and pedagogy, (2022); 
Veel R., Learning how to mean – scientifically speaking: Apprenticeship into scientific discourse in the secondary school, Genre and institutions: Social processes in the workplace and school, pp. 161-195, (1997); 
Wacquant L., Epistemic bandwagons, speculation, and turnkeys: Some lessons from the tale of the urban ‘underclass’, Thesis Eleven, 173, 1, pp. 82-92, (2022); 
Guidance: What Works Network, (2019); 
Wilkins A., Rescaling the local: Multi-academy trusts, private monopoly and statecraft in England, Journal of Educational Administration and History, 49, 2, pp. 171-185, (2017); 
Wrigley T., The power of ‘evidence’: Reliable science or a set of blunt tools?, British Educational Research Journal, 44, 3, pp. 359-376, (2018)#FRF#
