#ITI#Low stakes, high risks: the problem of intertemporal validity of PISA in Latin America#FTI#
#IRE# Since 2000, the PISA test implemented by OECD has become the prime benchmark for international comparisons in education. The 2015 PISA edition introduced methodological changes that altered the nature of its results. PISA made no longer valid non-reached items of the final part of the test, assuming that those unanswered questions were more a problem of motivation than skills. Latin American countries were the only ones that had a large proportion of non-reached items in the first PISA editions. The methodological change had a large impact in these countries and was miscommunicated by the OECD reports. This makes the first two PISA editions (2000 and 2003) no longer comparable with the latest ones (2006, 2009, 2012 and 2015). We analyze hypotheses for the Latin American exception in PISA, suggesting that the introduction of the new Computer-Based Assessment of PISA in 2015, combined with an increasing culture of evaluation and political influences damaged intertemporal comparisons of PISA. Although PISA is a low-stakes assessment for students, it has become high-stakes for governments. This triggered mechanisms to increase test-taking motivation, and students tended to answer more questions of the test, but at the same time, these changes made intertemporal comparisons flawed#FRE#
#IPC# comparative analysis; educational policy; educational quality; Educational testing#FPC#
#IRF# Atkinson J.W., Motivational Determinants of Risk-taking Behavior, Psychological Review, 64, pp. 359-372, (1957); 
Auldmorris E.P., PISA, Policy and Persuasion: Translating Complex Conditions into Education ‘best Practice, Comparative Education, 52, 2, pp. 202-229, (2016); 
Baird J.A.S., Johnson T.N., Hopfenbeck T., Isaacs T., Sprague G., Stobartyu G., On the Supranational Spell of PISA in Policy, Educational Research, 58, 2, pp. 121-138, (2016); 
Baumert J., Demmrich A., Test Motivation in the Assessment of Student Skills: The Effects of Incentives on motivation and Performance, European Journal of Psychology of Education, 16, 3, pp. 441-462, (2001); 
Bruns B.D., Evansluque J., Achieving World-Class Education in Brazil, The Next Agenda, (2012); 
Cabrol M., Szekely M., Educación Para La Transformación, (2012); 
Carnoy M., International Test Score Comparisons and Educational Policy: A Review of the Critiques, (2015); 
Carnoy M.T., Khavenson I., Fonseca L., Costamarotta L., Is Brazilian Education Improving? Evidence from PISA and SAEB, Cadernos De Pesquisa, 45, 157, pp. 450-485, (2015); 
Carnoyrothstein M.R., International Tests Show Achievement Gaps in All Countries, with Big Gains for U.S. Disadvantaged Students, Economic Policy Institute: Washington, DC, (2013); 
Carvalho L.M., Costa E., Seeing Education with One’s Own Eyes and through PISA Lenses: Considerations of the Reception of PISA in European Countries, Discourse: Studies in the Cultural Politics of Education, 36, 5, pp. 638-646, (2015); 
Cetin B., Cross-cultural Structural Parameter Invariance on PISA 2006 Student Questionnaires, Eurasian Journal of Educational Research, 38, pp. 71-89, (2010); 
Chen Y.F., Jiao H., Exploring the Utility of Background and Cognitive Variables in Explaining Latent Differential Item Functioning: An Example of the PISA 2009 Reading Assessment, Educational Assessment, 19, 2, pp. 77-96, (2014); 
Cosgrove J., Changes in Achievement in PISA from 2000 to 2009 in Ireland: Beyond the Test Scores, The Irish Journal of Education Xl, pp. 29-44, (2015); 
DeMars C.E., Test Stakes and Item Form at Interactions, Applied Measurement in Education, 13, 1, pp. 55-77, (2000); 
Demarswise C.E.S.L., Can Diﬀerential Rapid-guessing Behavior Lead to diﬀerential Item Functioning?, International Journal of Test, 10, pp. 207-229, (2010); 
Eccles J.S., Wigfield A., Motivational Beliefs, Values, and Goals, Annual Review of Psychology, 53, 1, pp. 109-132, (2002); 
Eivers E., PISA: Issues in Implementation and Interpretation, Irish Journal of Education/Iris Eireannach an Oideachais, 38, pp. 94-118, (2010); 
Eklof H., Skill and Will: Test‐taking Motivation and Assessment Quality, Assessment in Education: Principles, Policy & Practice, 17, 4, pp. 345-356, (2010); 
Eklof H.B.J., Pavesicgronmo L.S., A Cross-national Comparison of Reported Effort and Mathematics Performance in TIMSS Advanced, Applied Measurement in Education, (2013); 
Ercikan K.W.M., Rothasil M., Cautions about Inferences from International Assessments: The Case of PISA 2009, Teachers College Record, 117, pp. 1-28, (2015); 
Feather N.T., Human Values and the Prediction of Action: An Expectancy-value Analysis, Expectations and Actions: Expectancy-Value Models in Psychology, pp. 263-289, (1982); 
Fernandez Cano A., A Methodological Critique of the PISA Evaluations, Relieve, 22, 1, (2016); 
Finn B., Measuring Motivation in Low-stakes Assessments, ETS Research Report Series, pp. 1-17, (2015); 
Fischman G.E.A., Marcetti Topper I., Silova J., Goebelholloway J.L., Examining the Influence of International Large-scale Assessments on National Education Policies, Journal of Education Policy, (2018); 
Freitas P.L., Catela Nunes A., Balcao Reis C., Seabraferro A., Correcting for Sample Problems in PISA and the Improvement in Portuguese Students’ Performance.” Assessment in Education: Principles, Policy & Practice, 23, 4, pp. 456-472, (2016); 
Gneezy U.J.A., List J.A., Livingston S., Sadoff X., Qinxu Y., Measuring Success in Education: The Role of Effort on the Test Itself, NBER Working Paper No, (2017); 
Goldstein H., International Comparisons of Student Attainment: Some Issues Arising from the PISA Study, Assessment in Education, 11, 3, pp. 319-330, (2004); 
Goldstein H., Measurement and Evaluation Issues with PISA, In the PISA Effect on Global Educational Governance, (2017); 
Grek S., Governing by Numbers: The PISA Eﬀect in Europe, Journal of Education Policy, 24, pp. 23-37, (2009); 
Grisay A.J., de Jong E., Gebhardt A., Breezierhalleux-Monseur B., Translation Equivalence across PISA Countries, Journal of Applied Measurement, 8, 3, pp. 249-266, (2007); 
Harlencrick W.R.D., Testing and Motivation for Learning, Assessment in Education: Principles, Policy & Practice, 10, 2, pp. 169-207, (2003); 
Hopfenbeck T.N., Lenkeit J., El Masri Y., Cantrell K., Ryan J., Baird J., Lessons Learned from PISA: A Systematic Review of Peer-Reviewed Articles on the Programme for International Student Assessment, Scandinavian Journal of Educational Research, 62, 3, pp. 333-353, (2017); 
Huang X., Wilson M., Wang L., Exploring Plausible Causes of Differential Item Functioning in the PISA Science Assessment: Language, Curriculum or Culture, Educational Psychology: an International Journal of Experimental Educational Psychology, 36, 2, pp. 378-390, (2016); 
Informe Nacional De Resultados. Colombia En PISA 2015, Ministerio De Educación De Colombia, (2017); 
Jerrim J., The Socio-economic Gradient in Teenagers’ Reading Skills: How Does England Compare with Other Countries?, Fiscal Studies, 33, 2, pp. 159-184, (2012); 
Jerrim J.J., Micklewright J., Heine C., Salzermckeown C., PISA 2015: How Big Is the ‘mode Effect’ and What Has Been Done about It?, Oxford Review of Education, 44, 4, pp. 476-493, (2018); 
Jodouin H., Differential Omission Rates: Exploring Factors that Influence Omission Rates in a Large-Scale Pan-Canadian Assessment, (2014); 
Klein R., A Re-analysis of the PISA Results: Comparability Problems, [Uma re-análise Dos Resultados Do PISA: Problemas De Comparabilidade]. Ensaio: Avaliação E Políticas Públicas Em Educação 19 (73, (2011); 
Komatsu H., Rappleye J., Did the Shift to Computer-based Testing in PISA 2015 Affect Reading Scores? A View from East Asia, Compare: A Journal of Comparative and International Education, 47, 4, pp. 616-623, (2017); 
Kreiner S., Christensen K.B., Analyses of Model Fit and Robustness. A New Look at the PISA Scaling model Underlying Ranking of Countries according to Reading Literacy, Psychometrika, 79, 2, pp. 210-231, (2014); 
Lewislingard S.B., The Multiple Effects of International Large-Scale, ” Assessment on Education Policy and Research Discourse, 36, 5, pp. 621-637, (2015); 
Lindblad S., Pettersson D., Popkewitz T.S., International Comparisons of School Results: A Systematic Review of Research on Large-scale Assessments in Education, (2015); 
Lu Y., Bolt D.M., Examining the Attitude-achievement Paradox in PISA Using a Multilevel Multidimensional IRT Model for Extreme Response Style, Large-scale Assessments in Education, 3, 2, (2015); 
Ludtke O.A., Robitzsch U., Trautwein F., Kreuterihme Marten J., Are There Test Administrator Effects in Large-scale Educational Assessments?, Methodology: European Journal of Research Methods for the Behavioral and Social Sciences, 3, 4, pp. 149-159, (2007); 
Meyer H.D., Benavot A., (2013); 
Mislevy R.J., Test Theory and Language-learning Assessment, Language Testing, 12, 3, pp. 341-369, (1995); 
Morris A., Student Standardised Testing: Current Practices in OECD Countries and a Literature Review, OECD Education Working Papers, (2011); 
Niemann D.K., Martensteltemann J., PISA and Its Consequences: Shaping Education Policies through International Comparisons, European Journal of Education, 52, 2, pp. 175-183, (2017); 
O'Neil H.F.J., Abedi J., Miyoshimastergeorge A., Monetary Incentives for Lowstakes Tests, Educational Assessment, 10, 3, pp. 185-208, (2005); 
Ecd O., PISA 2015 Results (Volume I): Excellence and Equity in Education, París: Oecdpublishing, (2016); 
Trends in the Percentage of Correct Answers and Treatment of Non-reached Items, (2017); 
Brazil: Encouraging Lessons from a Large Federal System, Strong Performers and Successful Reformers in Education: Lessons from PISA for the United States, (2011); 
PISA 2015: Technical Standards, (2015); 
Programme for International Student Assessment. Results from PISA 2015. Country Note: Colombia, (2016); 
PISA 2015 Assessment and Analytical Framework: Science, Reading, Mathematic, Financial Literacy and Collaborative Problem Solving, (2017); 
PISA 2015: Technical Report, (2017); 
Competencias En Iberoamérica: Análisis De PISA 2015, (2018); 
PISA 2006: Science Competencies for Tomorrow’s World, (2007); 
Olsen R., Lie S., Profiles of Students’ Interest in Science Issues around the World: Analysis of Data from PISA 2006, International Journal of Science Education, 33, 1, pp. 97-120, (2011); 
Pintrich P.R., The Dynamic Interplay of Student Motivation and Cognition in the College Classroom, Advances in Motivation and Achievement, 6, pp. 117-160, (1989); 
Pintrichdegroot P.R.E.V., Motivational and Self-regulated Learning Components of Classroom Academic Performance, Journal of Educational Psychology, 82, 1, pp. 33-40, (1990); 
Pintrich P.R., Schunk D.H., Motivation in Education: Theory, Research, and Applications, (2002); 
Pons X., Fifteen Years of Research on PISA Effects on Education Governance: A Critical Review, European Journal of Education, 52, 2, pp. 131-144, (2017); 
Prais S.J., Cautions on OECD’S Recent Educational Survey (PISA), Oxford Review of Education, 29, 2, pp. 139-163, (2003); 
Puchhammer M., Language-based Item Analysis: Problems in Intercultural Comparisons, In PISA according to PISA: Does PISA Keep What It Promises?, pp. 127-138, (2007); 
Rautalin M.P., Alasuutarivento E., Globalization of Education Policies: Does PISA Have an Effect?, Journal of Education Policy, (2018); 
Rivas A., América Latina Después De PISA: Lecciones Aprendidas de Siete Países, (2015); 
Solano-Floresmilbourn G.T., Evaluation Capacity, Cultural Validity and Consequential validity in PISA, Relieve, 22, 1, (2016); 
Sundre D.L., Does Examinee Motivation Moderate the Relationship between Test Consequences and Test Performance? ”. Paper Presented at the Annual Meeting of The, (1999); 
Sundrekitsantas D.L.A.L., An Exploration of the Psychology of the Examinee: Can Examine Self-regulation and Test Taking Motivation Predict Consequential and Non-consequential test Performance?, Contemporary Educational Psychology, 29, 1, pp. 6-26, (2004); 
Swaffieldthomas S.S., Educational Assessment in Latin America, Assessment in Education: Principles, Policy & Practice, 23, 1, pp. 1-7, (2016); 
Thelk A.D.D.L., Sundre S.J., Horstfinney S.J., Motivation Matters: Using the Student Opinion Scale to Make Valid Inferences about student Performance, The Journal of General Education, 58, 3, pp. 129-151, (2009); 
Vegas E., Petrow J., Raising Student Learning in Latin America. The Challenge for the 21st Century, (2008); 
Wigfieldeccles A.J., The Development of Competence Beliefs, Expectancies for Success, and Achievement Values from Childhood through Adolescence, Development of Achievement Motivation, Edited by A., Wigfield and J., Eccles, pp. 92-120, (2002); 
Wisedemars S.L.C., Low Examinee Effort in Low-stakes Assessment: Problems and Possible Solutions, Educational Assessment, 10, 1, pp. 1-17, (2005); 
Wolff L., Educational Assessments in Latin America: The State of Art, International Association of Applied Psychology, 53, 2, pp. 192-214, (2004); 
Wolffsmith L.F.J.K., The Consequence of Consequence: Motivation, Anxiety, and Test Performance, ” Applied Measurement in Education, 8, 3, pp. 227-242, (1995); 
Wuttke J., Uncertainties and Bias in PISA. PISA according to PISA. Does PISA Keep What It Promises?, pp. 241-263, (2007); 
Zamarro G.C., Hittmendez I., When Students Don’t Care: Reexamining International Differences in Achievement and Non-Cognitive Skills, (2016)#FRF#
