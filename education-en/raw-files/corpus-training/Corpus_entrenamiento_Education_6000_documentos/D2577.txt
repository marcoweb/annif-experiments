#ITI#The answer is (not only) technological: Considering student data privacy in learning analytics#FTI#
#IRE# Evidence shows that appropriate use of technology in education has the potential to increase the effectiveness of, eg, teaching, learning and student support. There is also evidence that technology can introduce new problems and ethical issues, eg, student privacy. This article maps some limitations of technological approaches that ensure student data privacy in learning analytics from a critical data studies (CDS) perspective. In this conceptual article, we map the claims, grounds and warrants of technological solutions to maintaining student data privacy in learning analytics. Our findings suggest that many technological solutions are based on assumptions, such as that individuals have control over their data (‘data as commodity’), which can be exchanged under agreed conditions, or that individuals embrace their personal data privacy as a human right to be respected and protected. Regulating student data privacy in the context of learning analytics through technology mostly depends on institutional data governance, consent, data security and accountability. We consider alternative approaches to viewing (student) data privacy, such as contextual integrity; data privacy as ontological; group privacy; and indigenous understandings of privacy. Such perspectives destabilise many assumptions informing technological solutions, including privacy enhancing technology (PET). Practitioner notes What is already known about this topic Various actors (including those in higher education) have access to and collect, use and analyse greater volumes of personal (student) data, with finer granularity, increasingly from multiplatforms and data sources. There is growing awareness and concern about individual (student) privacy. Privacy enhancing technologies (PETs) offer a range of solutions to individuals to protect their data privacy. What this paper adds A review of the assumption that technology provides adequate or complete solutions for ensuring individual data privacy. A mapping of five alternative understandings of personal data privacy and its implications for technological solutions. Consideration of implications for the protection of student privacy in learning analytics. Implications for practice and/or policy Student data privacy is not only a technological problem to be solved but should also be understood as a social problem. The use of PETs offers some solutions for data privacy in learning analytics. Strategies to protect student data privacy should include student agency, literacy and a whole-system approach#FRE#
#IPC# learning analytics; privacy; privacy enhancing technology (PET); technology#FPC#
#IRF# African declaration on internet rights and freedoms, (2021); 
Aguilar J., Sanchez M., Cordero J., Valdiviezo-Diaz P., Barba-Guaman L., Chamba-Eras L., Learning analytics tasks as services in smart classrooms, Universal Access in the Information Society, 17, 4, pp. 693-709, (2018); 
Bareis J., Katzenbach C., Talking AI into being: The narratives and imaginaries of national AI strategies and their performative politics, Science, Technology, & Human Values, (2021); 
Basso T., Matsunaga R., Moraes R., Antunes N., Challenges on anonymity, privacy, and big data, 2016 Seventh Latin-American Symposium on Dependable Computing (LADC), pp. 164-171, (2016); 
Beer D., The data gaze: Capitalism, power and perception, (2019); 
Black S., Marx’s Ghost in the Shell: Troubling techno-solutionism in post-secondary education and training policy imaginaries, (2021); 
Brandimarte L., Acquisti A., Loewenstein G., Misplaced confidences: Privacy and the control paradox, Social Psychological and Personality Science, 4, pp. 340-347, (2013); 
Brunton F., Nissenbaum H., Obfuscation: A user's guide for privacy and protest, (2015); 
Burkert H., Privacy-enhancing technologies: Typology, critique, vision, Technology and privacy: The new landscape, pp. 125-142, (1997); 
Bygrave L.A., Data protection pursuant to the right to privacy in human rights treaties, International Journal of Law and Information Technology, 6, 3, pp. 247-284, (1998); 
Clutterbuck J., Hardy I., Creagh S., Data infrastructures as sites of preclusion and omission: The representation of students and schooling, Journal of Education Policy, pp. 1-22, (2021); 
Cormack A.N., Downstream consent: A better legal framework for big data, Journal of Information Rights, Policy and Practice, 1, 1, (2016); 
Couldry N., Mejias U.A., The costs of connection, (2019); 
Working Paper, Research agenda, (2020); 
De Cristofaro E., Soriente C., Short paper: PEPSI - Privacy-enhanced participatory sensing infrastructure, Proceedings of WISEC'11: Fourth ACM Conference on Wireless Network Security Hamburg Germany June 14 - 17, pp. 23-28, (2011); 
DeCew J.W., The feminist critique of privacy: Past arguments and new social understandings, Social dimensions of privacy: Interdisciplinary perspectives, pp. 85-103, (2015); 
Dourish P., Anderson K., Collective information practice: Exploring privacy and security as social and cultural phenomena, Human-computer Interaction, 21, 3, pp. 319-342, (2006); 
Du X., Yang J., Shelton B.E., Hung J.L., Zhang M., A systematic meta-Review and analysis of learning analytics research, Behaviour & Information Technology, 40, 1, pp. 49-62, (2021); 
Eastman N.J., Hansen E.E., Classroom exchanges: Big data and the commodification of educational communication, Education and Culture, 37, 1, pp. 76-93, (2021); 
Felten E., Privacy as a social problem, not a technology problem, (2009); 
Floridi L., The ontological interpretation of informational privacy, Ethics and Information Technology, 7, 4, pp. 185-200, (2005); 
Gilson L.L., Goldberg C.B., Editors’ comment: So, what is a conceptual paper?, Group & Organization Management, 40, 2, pp. 127-130, (2015); 
Gursoy M.E., Inan A., Nergiz M.E., Saygin Y., Privacy-preserving learning analytics: Challenges and techniques, IEEE Transactions on Learning Technologies, 10, 1, pp. 68-81, (2016); 
Gutwirth S., Privacy and the information age, (2002); 
Heinrich M., Does education impact the use of privacy enhancing behaviour? A longitudinal study, (2021); 
Heurix J., Zimmermann P., Neubauer T., Fenz S., A taxonomy for privacy enhancing technologies, Computers & Security, 53, pp. 1-17, (2015); 
Hirschheim R., Some guidelines for the critical reviewing of conceptual papers, Journal of the Association for Information Systems, 9, 8, pp. 432-441, (2008); 
Hudson J., The world’s most liveable city—For Māori: Data advocacy and Māori wellbeing in Tāmaki Makaurau (Auckland), Data sovereignty for indigenous peoples: Current practice and future needs, pp. 179-191, (2016); 
Human rights watch: 2021 Domestic transition priorities for the next US administration, (2020); 
The EU general data protection regulation, (2021); 
Ifenthaler D., Gibson D., Prasse D., Shimada A., Yamada M., Putting learning back into learning analytics: Actions for policy makers, researchers, and practitioners, Educational Technology Research and Development, 69, 4, pp. 2131-2150, (2021); 
Ifenthaler D., Schumacher C., Student perceptions of privacy principles for learning analytics, Educational Technology Research and Development, 64, 5, pp. 923-938, (2016); 
Iliadis A., Russo F., Critical data studies: An introduction, Big Data & Society, 3, 2, pp. 1-7, (2016); 
Jaakkola E., Designing conceptual articles: Four approaches, AMS Review, 10, 1, pp. 18-26, (2020); 
Jerman-Blazic B., Klobucar T., Privacy provision in e-learning standardized systems: Status and improvements, Computer Standards & Interfaces, 27, 6, pp. 561-578, (2005); 
Joksimovic S., Marshall R., Rakotoarivelo T., Ladjal D., Zhan C., Pardo A., Privacy-driven learning analytics, Manage your own learning analytics, pp. 1-22, (2022); 
Jones K.M., What is a data double?, (2018); 
Jones K.M., Learning analytics and higher education: A proposed model for establishing informed consent mechanisms to promote student privacy and autonomy, International Journal of Educational Technology in Higher Education, 16, 1, pp. 1-22, (2019); 
Jones K.M., Rubel A., LeClere E., A matter of trust: Higher education institutions as information fiduciaries in an age of educational data mining and learning analytics, Journal of the Association for Information Science and Technology, 71, pp. 1227-1241, (2020); 
Juan M., Fixations, Charismatic technologies and the perennial enthusiasm of techno-solutionism, Anthropology Book Forum, 7, 1, pp. 1-16, (2021); 
Kaaniche N., Laurent M., Belguith S., Privacy enhancing technologies for solving the privacy-personalization paradox: Taxonomy and survey, Journal of Network and Computer Applications, 171, (2020); 
Kakarlapudi P.V., Mahmoud Q.H., A systematic review of Blockchain for consent management, Healthcare, 9, 2, (2021); 
Khalil M., Ebner M., De-identification in learning analytics, Journal of Learning Analytics, 3, 1, pp. 129-138, (2016); 
Khalil M., Prinsloo P., Slade S., The unbearable lightness of consent: Mapping MOOC providers' response to consent, Proceedings of the fifth annual ACM conference on Learning at Scale, pp. 1-11, (2018); 
Khalil M., Prinsloo P., Slade S., Realising the potential of learning analytics: Reflections from a pandemic, Learning analytics in an online world, pp. 79-94, (2021); 
Kitchin R., The data revolution: Big data, open data, data infrastructures and their consequences, (2014); 
Kitchin R., Lauriault T., Towards critical data studies: Charting and unpacking data assemblages and their work, The Programmable City Working Paper 29th July 2014, (2014); 
Komljenovic J., The rise of education rentiers: Digital platforms, digital data and rents, Learning, Media and Technology, 46, 3, pp. 320-332, (2021); 
Krontiris I., Benenson Z., Girard A., Sabouri A., Rannenberg K., Schoo P., Privacy-ABCs as a case for studying the adoption of PETs by users and service providers, Privacy Technology and Policy, pp. 104-123, (2015); 
Kukutai T., Taylor J., Data sovereignty for indigenous peoples: Current practice and future needs, (2016); 
Loi M., Christen M., Two concepts of group privacy, Philosophy & Technology, 33, 2, pp. 207-224, (2020); 
Lomas N., Dutch court will hear another Facebook privacy lawsuit, (2021); 
Lupton D., Thinking with care about personal data profiling: A more-than-human approach, International Journal of Communication, 14, pp. 3165-3183, (2020); 
Lupton D., ‘Honestly no, I’ve never looked at it’: Teachers’ understandings and practices related to students’ personal data in digitised health and physical education, Learning, Media and Technology, 46, 3, pp. 281-293, (2021); 
Mann M., Devitt S.K., Daly A., What Is (in) Good Data?, Good data, pp. 8-25, (2019); 
Margulis S.T., Privacy as a social issue and behavioral concept, Journal of Social Issues, 59, 2, pp. 243-261, (2003); 
Means A.J., Slater G.B., The dark mirror of capital: On post-neoliberal formations and the future of education, Discourse: Studies in the Cultural Politics of Education, 40, 2, pp. 162-175, (2019); 
Morozov E., To save everything, click here: The folly of technological solutionism, (2013); 
Morphy F., Indigenising demographic categories: A prolegomenon to indigenous data sovereignty, Data sovereignty for indigenous peoples: Current practice and future needs, pp. 99-115, (2016); 
Newell P.B., A cross-cultural comparison of privacy definitions and functions: A systems approach, Journal of Environmental Psychology, 18, 4, pp. 357-371, (1998); 
Nissenbaum H., Privacy as contextual integrity, Washington Law Review, 79, pp. 119-158, (2004); 
Nissenbaum H., Privacy in context. Technology, policy and the integrity of social life, (2010); 
Oelschlaeger M., The myth of the technological fix, Southwestern Journal of Philosophy, 10, 1, pp. 43-53, (1979); 
Okhuysen G., Bonardi J., The challenges of building theory by combining lenses, Academy of Management Review, 36, 1, pp. 6-11, (2011); 
Oomen I., Leenes R., Privacy risk perceptions and privacy protection strategies, Policies and research in identity management, pp. 121-138, (2008); 
Paris B., Reynolds R., McGowan C., Sins of omission: Critical informatics perspectives on privacy in e-learning systems in higher education, Journal of the Association for Information Science and Technology, (2021); 
Prato S., Sonkin F., Inequalities, financialisation, technology: Sometimes the nearest exit is behind you, Development, 61, 1, pp. 1-5, (2018); 
Prinsloo P., Context matters: An African perspective on institutionalising learning analytics, Include us all! Directions for adoption of learning analytics in the Global South, pp. 29-40, (2018); 
Prinsloo P., Khalil M., Slade S., Learning analytics in a time of pandemics: Mapping the field, EDEN Conference Proceedings, 1, pp. 59-70, (2021); 
Prinsloo P., Slade S., Student privacy self-management: Implications for learning analytics, Proceedings of the fifth international conference on learning analytics and knowledge, pp. 83-92, (2015); 
Prinsloo P., Slade S., Building the learning analytics curriculum: Should we teach (a code of) ethics?, (2017); 
Prinsloo P., Slade S., An elephant in the learning analytics room: The obligation to act, Proceedings of the seventh international learning analytics & knowledge conference, pp. 46-55, (2017); 
Samuelsen J., Chen W., Wasson B., Integrating multiple data sources for learning analytics—Review of literature, Research and Practice in Technology Enhanced Learning, 14, 1, pp. 1-20, (2019); 
Scassa T., A human rights-based approach to data protection in Canada, Citizenship in a connected Canada: A research and policy agenda, pp. 173-188, (2020); 
Sims C., Pedagogic fixation, The digital age and its discontents: Critical reflections in education, pp. 183-210, (2020); 
Skinner G., Han S., Chang E., An information privacy taxonomy for collaborative environments, Information Management and Computer Security, 14, 4, pp. 382-394, (2006); 
Skinner-Thompson S., Privacy at the margins, (2020); 
Slade S., Prinsloo P., Learning analytics: Ethical issues and dilemmas, American Behavioral Scientist, 57, 10, pp. 1510-1529, (2013); 
Slade S., Prinsloo P., Student perspectives on the use of their data: Between intrusion, surveillance and care, European Journal of Open, Distance and Elearning, pp. 16-28, (2015); 
Smith D.E., Governing data and data for governance: The everyday practice of Indigenous sovereignty, Indigenous data sovereignty. Toward an agenda, pp. 117-135, (2016); 
Solove D.J., Conceptualising privacy, Calif. L. Rev, 90, (2002); 
Solove D.J., The digital person: Technology and privacy in the information age, 1, (2004); 
Solove D.J., Introduction: Privacy self-management and the consent dilemma, Harvard Law Review, pp. 1880-1903, (2013); 
Taylor L., Floridi L., van der Sloot B., Group Privacy: New challenges of data technologies, 126, (2016); 
Protecting privacy in practice: The current use, development and limits of Privacy Enhancing Technologies in data analysis, (2019); 
Tillay M., Litigation firm launches class action against Facebook following Cambridge Analytica scandal, (2020); 
Trepte S., Reinecke L., The reciprocal effects of social network site use and the disposition for self-disclosure: A longitudinal study, Computers in Human Behavior, 29, pp. 1102-1112, (2013); 
Tsai Y.-S., Whitelock-Wainwright A., Gasevic D., The privacy paradox and its implications for learning analytics, Proceedings of the Tenth International Conference on Learning Analytics & Knowledge, pp. 230-239, (2020); 
A human rights-based approach to data - Leaving no-one behind in the 2030 agenda for sustainable development, (2018); 
Van Blarkom G.W., Borking J.J., Olk J.E., Handbook of privacy and privacy-enhancing technologies, (2003); 
Viljoen S., Democratic data: A relational theory for data governance, The Yale Law Journal, pp. 573-654, (2021); 
Vis-Dunbar M., Williams J., Jahnke J.H.W., Indigenous and community-based notions of privacy. A technical report of the informational privacy interdisciplinary group, (2011); 
Walter M., Lovett R., Maher B., Williamson B., Prehn J., Bodkin-Andrews G., Lee V., Indigenous data sovereignty in the era of big data and open data, Australian Journal of Social Issues, 56, 2, pp. 143-156, (2021); 
Westin A.F., Privacy and freedom, (1967); 
Whetten D., What constitutes a theoretical contribution?, Academy of Management Review, 14, pp. 490-495, (1989); 
Williamson B., Bayne S., Shay S., The datafication of teaching in higher education: Critical issues and perspectives, Teaching in Higher Education, 25, 4, pp. 351-365, (2020); 
Wilson M.P., The politics of privacy protection: An analysis of resistance to metadata retention and encryption access laws, (2020); 
Wu X., Chu C.H., Wang Y., Liu F., Yue D., Privacy preserving data mining research: Current status and key issues, Lecture Notes in Computer Science, International Conference on Computational Science, 4489, pp. 762-772, (2007); 
Xanthoulis N., Conceptualising a right to oblivion in the digital world: A human rights-based approach, (2012); 
Zuboff S., The age of surveillance capitalism. The fight for a human future at the new frontier of power, (2019)#FRF#
