#ITI#The great detectives: humans versus AI detectors in catching large language model-generated medical writing#FTI#
#IRE#Background: The application of artificial intelligence (AI) in academic writing has raised concerns regarding accuracy, ethics, and scientific rigour. Some AI content detectors may not accurately identify AI-generated texts, especially those that have undergone paraphrasing. Therefore, there is a pressing need for efficacious approaches or guidelines to govern AI usage in specific disciplines. Objective: Our study aims to compare the accuracy of mainstream AI content detectors and human reviewers in detecting AI-generated rehabilitation-related articles with or without paraphrasing. Study design: This cross-sectional study purposively chose 50 rehabilitation-related articles from four peer-reviewed journals, and then fabricated another 50 articles using ChatGPT. Specifically, ChatGPT was used to generate the introduction, discussion, and conclusion sections based on the original titles, methods, and results. Wordtune was then used to rephrase the ChatGPT-generated articles. Six common AI content detectors (Originality.ai, Turnitin, ZeroGPT, GPTZero, Content at Scale, and GPT-2 Output Detector) were employed to identify AI content for the original, ChatGPT-generated and AI-rephrased articles. Four human reviewers (two student reviewers and two professorial reviewers) were recruited to differentiate between the original articles and AI-rephrased articles, which were expected to be more difficult to detect. They were instructed to give reasons for their judgements. Results: Originality.ai correctly detected 100% of ChatGPT-generated and AI-rephrased texts. ZeroGPT accurately detected 96% of ChatGPT-generated and 88% of AI-rephrased articles. The areas under the receiver operating characteristic curve (AUROC) of ZeroGPT were 0.98 for identifying human-written and AI articles. Turnitin showed a 0% misclassification rate for human-written articles, although it only identified 30% of AI-rephrased articles. Professorial reviewers accurately discriminated at least 96% of AI-rephrased articles, but they misclassified 12% of human-written articles as AI-generated. On average, students only identified 76% of AI-rephrased articles. Reviewers identified AI-rephrased articles based on ‘incoherent content’ (34.36%), followed by ‘grammatical errors’ (20.26%), and ‘insufficient evidence’ (16.15%). Conclusions and relevance: This study directly compared the accuracy of advanced AI detectors and human reviewers in detecting AI-generated medical writing after paraphrasing. Our findings demonstrate that specific detectors and experienced reviewers can accurately identify articles generated by Large Language Models, even after paraphrasing. The rationale employed by our reviewers in their assessments can inform future evaluation strategies for monitoring AI usage in medical education or publications. AI content detectors may be incorporated as an additional screening tool in the peer-review process of academic journals. © The Author(s) 2024.#FRE#
#IPC#Academic integrity; Accuracy; AI content detectors; Artificial intelligence; ChatGPT; Generative AI; Paraphrasing tools; Peer review; Perplexity scores; Scientific rigour#FPC#
#IRF#Anderson N., Belavy D.L., Perle S.M., Hendricks S., Hespanhol L., Verhagen E., Memon A.R., AI did not write this manuscript, or did it? Can we trick the AI text detector into generating texts? The potential future of ChatGPT and AI in sports & exercise medicine manuscript generation, BMJ Open Sport Exerc Med, 9, 1, (2023); 
Ariyaratne S., Iyengar K.P., Nischal N., Chitti Babu N., Botchu R., A comparison of ChatGPT-generated articles with human-written articles, Skeletal Radiol, 52, pp. 1755-1758, (2023); 
Detailed Insights on Users., (2023); 
Crothers E., Japkowicz N., Viktor H.L., Machine-generated text: a comprehensive survey of threat models and detection methods, (2023); 
Fisher J.S., Radvansky G.A., Patterns of forgetting, J Mem Lang, 102, pp. 130-141, (2018); 
Gao C.A., Howard F.M., Markov N.S., Dyer E.C., Ramesh S., Luo Y., Pearson A.T., Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers, NPJ Digit Med, 6, (2023); 
Gilson A., Safranek C.W., Huang T., Socrates V., Chi L., Taylor R.A., Chartash D., How does ChatGPT perform on the United States medical licensing examination? The implications of large language models for medical education and knowledge assessment, JMIR Med Educ, 9, (2023); 
, How Do I Interpret Burstiness Or Perplexity?, (2023); 
Hopkins A.M., Logan J.M., Kichenadasse G., Sorich M.J., Artificial intelligence chatbots will revolutionize how cancer patients access information: ChatGPT represents a paradigm-shift, JNCI Cancer Spectr, 7, (2023); 
Imran M., Almusharraf N., Analyzing the role of ChatGPT as a writing assistant at higher education level: a systematic review of the literature, Contemp Educ Technol, 15, (2023); 
Lee M., Liang P.Q., Coauthor_ designing a human-ai collaborative writing dataset for exploring language model capabilities, . In: CHI Conference on Human Factors in Computing Systems, pp. 1-19, (2022); 
Liang W., Yuksekgonul M., Mao Y., Wu E., Zou J., GPT detectors are biased against non-native English writers, Patterns (N Y), 4, 7, (2023); 
Manohar N., Prasad S.S., Use of ChatGPT in academic publishing: A rare case of seronegative systemic lupus erythematosus in a patient with HIV infection, Cureus, 15, 2, (2023); 
Mehnen L., Gruarin S., Vasileva M., Knapp B., ChatGPT as a medical doctor?, A Diagnostic Accuracy Study on Common and Rare Diseases Medrxiv, (2023); 
Introducing Chatgpt, (2023); 
Patel S.B., Lam K., ChatGPT: the future of discharge summaries?, Lancet Digital Health, 5, pp. e107-e108, (2023); 
Prillaman M., ChatGPT detector' catches AI-generated papers with unprecedented accuracy, Nature., (2023); 
Sadasivan V., Kumar A., Balasubramanian S., Wang W., Feizi S., Can AI-generated text be reliably detected?, Arxiv E-Prints, 2303, (2023); 
Sallam M., ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns, In Healthcare MDPI, 887, (2023); 
(2023); 
Sinha R.K., Deb Roy A., Kumar N., Mondal H., Applicability of ChatGPT in assisting to solve higher order problems in pathology, Cureus, 15, 2, (2023); 
Stokel-Walker C., ChatGPT listed as author on research papers: many scientists disapprove, Nature, 613, 7945, pp. 620-621, (2023); 
Top 10 AI Detector Tools, 2023, You Should Use; 
Walters W.H., The effectiveness of software designed to detect AI-generated writing: a comparison of 16 AI text detectors, Open Information Science, 7, (2023); 
Wang Y.-M., Shen H.-W., Chen T.-J., Performance of ChatGPT on the pharmacist licensing examination in Taiwan, J Chin Med Assoc, 10, (2023); 
Weber-Wulff D., Anohina-Naumeca A., Bjelobaba S., Foltynek T., Guerrero-Dib J., Popoola O., Sigut P., Waddington L., Testing of detection tools for AI-generated text, Int J Educ Integrity, 19, 1, (2023); 
Welding L., Half of college students say using AI on schoolwork is cheating or plagiarism, (2023); 
Wordtune, (2023); 
Yeadon W., Inyang O.-O., Mizouri A., Peach A., Testrow C.P., The death of the short-form physics essay in the coming AI revolution, Phys Educ, 58, (2023); 
Zong H., Li J., Wu E., Wu R., Lu J., Shen B., Performance of ChatGPT on Chinese National Medical Licensing Examinations: A five-year examination evaluation study for physicians, pharmacists and nurses. medRxiv:2023.2007, 2009.23292415, (2023)#FRF#
