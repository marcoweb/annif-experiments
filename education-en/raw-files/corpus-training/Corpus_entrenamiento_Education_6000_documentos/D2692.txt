#ITI#Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach#FTI#
#IRE# Artificial intelligence (AI) literacy is at the top of the agenda for education today in developing learners' AI knowledge, skills, attitudes and values in the 21st century. However, there are few validated research instruments for educators to examine how secondary students develop and perceive their learning outcomes. After reviewing the literature on AI literacy questionnaires, we categorized the identified competencies in four dimensions: (1) affective learning (intrinsic motivation and self-efficacy/confidence), (2) behavioural learning (behavioural commitment and collaboration), (3) cognitive learning (know and understand; apply, evaluate and create) and (4) ethical learning. Then, a 32-item self-reported questionnaire on AI literacy (AILQ) was developed and validated to measure students' literacy development in the four dimensions. The design and validation of AILQ were examined through theoretical review, expert judgement, interview, pilot study and first- and second-order confirmatory factor analysis. This article reports the findings of a pilot study using a preliminary version of the AILQ among 363 secondary school students in Hong Kong to analyse the psychometric properties of the instrument. Results indicated a four-factor structure of the AILQ and revealed good reliability and validity. The AILQ is recommended as a reliable measurement scale for assessing how secondary students foster their AI literacy and inform better instructional design based on the proposed affective, behavioural, cognitive and ethical (ABCE) learning framework. Practitioner notes What is already known about this topic AI literacy has drawn increasing attention in recent years and has been identified as an important digital literacy. Schools and universities around the world started to incorporate AI into their curriculum to foster young learners' AI literacy. Some studies have worked to design suitable measurement tools, especially questionnaires, to examine students' learning outcomes in AI learning programmes. What this paper adds Develops an AI literacy questionnaire (AILQ) to evaluate students' literacy development in terms of affective, behavioural, cognitive and ethical (ABCE) dimensions. Proposes a parsimonious model based on the ABCE framework and addresses a skill set of AI literacy. Implications for practice and/or policy Researchers are able to use the AILQ as a guide to measure students' AI literacy. Practitioners are able to use the AILQ to assess students' AI literacy development#FRE#
#IPC# AI education; AI literacy; AI literacy questionnaire (AILQ); artificial intelligence; questionnaire validation#FPC#
#IRF# Agarwal P.K., Retrieval practice & Bloom's taxonomy: Do students need fact knowledge before higher order learning?, Journal of Educational Psychology, 111, 2, pp. 189-209, (2019); 
Ali S., Payne B.H., Williams R., Park H.W., Breazeal C., Constructionism, ethics, and creativity: Developing primary and middle school artificial intelligence education, International Workshop on Education in Artificial Intelligence k-12 (eduai’19), 2, pp. 1-4, (2019); 
Araujo T., Living up to the chatbot hype: The influence of anthropomorphic design cues and communicative agency framing on conversational agent and company perceptions, Computers in Human Behavior, 85, pp. 183-189, (2018); 
Arroyo I., Woolf B.P., Burelson W., Muldner K., Rai D., Tai M., A multimedia adaptive tutoring system for mathematics that addresses cognition, metacognition and affect, International Journal of Artificial Intelligence in Education, 24, 4, pp. 387-426, (2014); 
Aschbacher P.R., Ing M., Tsai S.M., Is science me? Exploring middle school students' STE-M career aspirations, Journal of Science Education and Technology, 23, pp. 735-743, (2014); 
Asparouhov T., Muthen B., Multiple-group factor analysis alignment, Structural Equation Modeling: A Multidisciplinary Journal, 21, 4, pp. 495-508, (2014); 
Audrin C., Audrin B., Key factors in digital literacy in learning and education: A systematic literature review using text mining, Education and Information Technologies, 27, 6, pp. 7395-7419, (2022); 
Bandalos D.L., Finney S.J., Factor analysis: Exploratory and confirmatory, The reviewer's guide to quantitative methods in the social sciences, pp. 98-122, (2018); 
Ben-Eliyahu A., Moore D., Dorph R., Schunn C.D., Investigating the multidimensionality of engagement: Affective, behavioral, and cognitive engagement across science activities and contexts, Contemporary Educational Psychology, 53, pp. 87-105, (2018); 
Borenstein J., Howard A., Emerging challenges in AI and the need for AI ethics education, AI and Ethics, 1, pp. 61-65, (2021); 
Caicedo Cavagnis E., Zalazar-Jaime M.F., Entrevistas cognitivas: revisión, directrices de uso y aplicación en investigaciones psicológicas, Avaliação Psicológica, 17, 3, pp. 362-370, (2018); 
Carolus A., Koch M., Straka S., Latoschik M.E., Wienrich C., MAILS—Meta AI Literacy Scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change-and meta-competencies, (2023); 
Celik I., Towards intelligent-TPACK: An empirical study on teachers' professional knowledge to ethically integrate artificial intelligence (AI)-based tools into education, Computers in Human Behavior, 138, (2023); 
Computing and digital literacy: Call for a holistic approach, (2015); 
Chai C.S., Lin P.Y., Jong M.S.Y., Dai Y., Chiu T.K., Huang B., Factors influencing students' behavioral intention to continue artificial intelligence learning, 2020 international symposium on educational technology (ISET), pp. 147-150, (2020); 
Chai C.S., Lin P.Y., Jong M.S.Y., Dai Y., Chiu T.K., Qin J., Perceptions of and behavioral intentions towards learning artificial intelligence in primary school students, Educational Technology & Society, 24, 3, pp. 89-101, (2021); 
Chai C.S., Wang X., Xu C., An extended theory of planned behavior for the modelling of Chinese secondary school students' intention to learn artificial intelligence, Mathematics, 8, 11, (2020); 
Chiu T.K., Chai C.S., Sustainable curriculum planning for artificial intelligence education: A self-determination theory perspective, Sustainability, 12, 14, (2020); 
Chiu T.K., Meng H., Chai C.S., King I., Wong S., Yam Y., Creation and evaluation of a pretertiary artificial intelligence (AI) curriculum, IEEE Transactions on Education, 65, 1, pp. 30-39, (2021); 
Chiu T.K., Sun J.C.Y., Ismailov M., Investigating the relationship of technology learning support to digital literacy from the perspective of self-determination theory, Educational Psychology, 42, 10, pp. 1263-1282, (2022); 
Choi M., Glassman M., Cristol D., What it means to be a citizen in the internet age: Development of a reliable and valid digital citizenship scale, Computers & Education, 107, pp. 100-112, (2017); 
Cosgun Ogeyik M., Using bloom's digital taxonomy as a framework to evaluate webcast learning experience in the context of Covid-19 pandemic, Education and Information Technologies, 27, 8, pp. 11219-11235, (2022); 
Covello S., Lei J., A review of digital literacy assessment instruments, Syracuse University, 1, (2010); 
Dai Y., Chai C.S., Lin P.Y., Jong M.S.Y., Guo Y., Qin J., Promoting students’ well-being by developing their readiness for the artificial intelligence age, Sustainability, 12, 16, (2020); 
DiStefano C., The impact of categorization with confirmatory factor analysis, Structural Equation Modeling, 9, 3, pp. 327-346, (2002); 
Druga S., Vu S.T., Likhith E., Qiu T., Inclusive AI literacy for kids around the world, pp. 104-111, (2019); 
Fernandez-Gomez E., Martin-Salvador A., Luque-Vara T., Sanchez-Ojeda M.A., Navarro-Prado S., Enrique-Miron C., Content validation through expert judgement of an instrument on the nutritional knowledge, beliefs, and habits of pregnant women, Nutrients, 12, 4, (2020); 
Flora D.B., Curran P.J., An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data, Psychological Methods, 9, 4, pp. 466-491, (2004); 
Fornell C., Larcker D.F., Evaluating structural equation models with unobservable variables and measurement error, Journal of Marketing Research, 18, 1, pp. 39-50, (1981); 
Guo Y.R., Goh D.H.L., Evaluation of affective embodied agents in an information literacy game, Computers & Education, 103, pp. 59-75, (2016); 
Henseler J., Ringle C.M., Sarstedt M., A new criterion for assessing discriminant validity in variance-based structural equation modeling, Journal of the Academy of Marketing Science, 43, pp. 115-135, (2015); 
Hunsu N.J., Adesope O., Bayly D.J., A meta-analysis of the effects of audience response systems (clicker-based technologies) on cognition and affect, Computers & Education, 94, pp. 102-119, (2016); 
Jackson D.L., Revisiting sample size and number of parameter estimates: Some support for the N:q hypothesis, Structural Equation Modeling, 10, 1, pp. 128-141, (2003); 
Jin K.Y., Reichert F., Cagasan L.P., de La Torre J., Law N., Measuring digital literacy across three age cohorts: Exploring test dimensionality and performance differences, Computers & Education, 157, (2020); 
Jobin A., Ienca M., Vayena E., The global landscape of AI ethics guidelines, Nature Machine Intelligence, 1, 9, pp. 389-399, (2019); 
Jung Y., Lee J., Learning engagement and persistence in massive open online courses (MOOCS), Computers & Education, 122, pp. 9-22, (2018); 
Kandlhofer M., Steinbauer G., Hirschmugl-Gaisch S., Huber P., Artificial intelligence and computer science in education: From kindergarten to university, IEEE Frontiers in Education Conference (FIE), pp. 1-9, (2016); 
Kell H.J., Motowidlo S.J., Deconstructing organizational commitment: Associations among its affective and cognitive components, personality antecedents, and behavioral outcomes, Journal of Applied Social Psychology, 42, 1, pp. 213-251, (2012); 
Kim M., Choi D., Development of youth digital citizenship scale and implication for educational setting, Journal of Educational Technology & Society, 21, 1, pp. 155-171, (2018); 
Kim H.L., Han J., Do employees in a “good” company comply better with information security policy? A corporate social responsibility perspective, Information Technology & People, 32, 4, pp. 858-875, (2019); 
Kline P., An easy guide to factor analysis, (2014); 
Kong S.C., Cheung W.M.Y., Zhang G., Evaluating artificial intelligence literacy courses for fostering conceptual learning, literacy and empowerment in university students: Refocusing to conceptual building, Computers in Human Behavior Reports, 7, (2022); 
Kong S.C., Cheung W.M.Y., Zhang G., Evaluating an artificial intelligence literacy programme for developing university students' conceptual understanding, literacy, empowerment and ethical awareness, Educational Technology and Society, 26, 1, pp. 16-30, (2023); 
Lamb R.L., Annetta L., Firestone J., Etopio E., A meta-analysis with examination of moderators of student cognition, affect, and learning outcomes while using serious educational games, serious games, and simulations, Computers in Human Behavior, 80, pp. 158-167, (2018); 
Laupichler M.C., Aster A., Schirch J., Artificial intelligence literacy in higher and adult education: A scoping, Computers & Education: Artificial Intelligence, 3, (2022); 
Law N., Woo D., de la Torre J., Wong G., A global framework of reference on digital literacy skills for indicator 4.4.2, (2018); 
Lazonder A.W., Walraven A., Gijlers H., Janssen N., Longitudinal assessment of digital literacy in children: Findings from a large Dutch single-school study, Computers & Education, 143, (2020); 
Lee M.K., Kusbit D., Kahng A., Kim J.T., Yuan X., Chan A., See D., Noothigattu R., Lee S., Psomas A., Procaccia A.D., WeBuildAI: Participatory framework for algorithmic governance, Proceedings of the ACM on Human-Computer Interaction, 3, CSCW, pp. 1-35, (2019); 
Lemov D., Bloom's taxonomy: That pyramid is a problem [Blog post], (2017); 
Lin P.Y., Chai C.S., Jong M.S.Y., Dai Y., Guo Y., Qin J., Modeling the structural relationship among primary students’ motivation to learn artificial intelligence, Computers and Education: Artificial Intelligence, 2, (2021); 
Lin P., Van Brummelen J., Engaging teachers to co-design integrated AI curriculum for K-12 classrooms, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-12, (2021); 
Liu C.J., Yang S.C., Applying the practical inquiry model to investigate the quality of students' online discourse in an information ethics course based on Bloom's teaching goal and Bird's 3C model, Computers & Education, 59, 2, pp. 466-480, (2012); 
Long D., Magerko B., What is AI literacy? Competencies and design considerations, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-16, (2020); 
Lowyck J., Poysa J., Design of collaborative learning environments, Computers in Human Behavior, 17, 5-6, pp. 507-516, (2001); 
MacKenzie S.B., Podsakoff P.M., Podsakoff N.P., Construct measurement and validation procedures in MIS and behavioral research: Integrating new and existing techniques, MIS Quarterly, pp. 293-334, (2011); 
Marsh H.W., Hau K.T., Wen Z., In search of golden rules: Comment on hypothesis-testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing Hu and Bentler's (1999) findings, Structural Equation Modeling, 11, 3, pp. 320-341, (2004); 
Marsh H.W., Ludtke O., Pekrun R., Parker P.D., Murayama K., Guo J., Basarkod G., Dicke T., Donald J.N., Morin A.J., School leaders' self-efficacy and job satisfaction over nine annual waves: A substantive-methodological synergy juxtaposing competing models of directional ordering, Contemporary Educational Psychology, 73, (2023); 
Marsh H.W., Hau K.T., Wen Z., In search of golden rules: Comment on hypothesis-testing approaches to setting cutoff values for fit indexes and dangers in overgeneralizing Hu and Bentler's (1999) findings, Structural Equation Modeling, 11, 3, pp. 320-341, (2004); 
Merzbacher M., Open artificial intelligence-one course for all, pp. 110-113, (2001); 
Responsible and trusted AI, (2023); 
Mota-Valtierra G., Rodriguez-Resendiz J., Herrera-Ruiz G., Constructivism-based methodology for teaching artificial intelligence topics focused on sustainable development, Sustainability, 11, 17, (2019); 
Ng W., Can we teach digital natives digital literacy?, Computers & Education, 59, 3, pp. 1065-1078, (2012); 
Ng D.T.K., Chu S.K.W., Motivating Students to Learn AI Through Social Networking Sites: A Case Study in Hong Kong, Online Learning, 25, 1, pp. 195-208, (2021); 
Ng D.T.K., Lee M., Tan R.J.Y., Hu X., Downie J.S., Chu S.K.W., A review of AI teaching and learning from 2000 to 2020, Education and Information Technologies, 28, 7, pp. 8445-8501, (2023); 
Ng D.T.K., Leung J.K.L., Chu K.W.S., Qiao M.S., AI literacy: Definition, teaching, evaluation and ethical issues, Proceedings of the Association for Information Science and Technology, 58, 1, pp. 504-509, (2021); 
Ng D.T.K., Leung J.K.L., Chu S.K.W., Qiao M.S., Conceptualizing AI literacy: An exploratory review, Computers and Education: Artificial Intelligence, 2, (2021); 
Ng D.T.K., Leung J.K.L., Su J., Ng R.C.W., Chu S.K.W., Teachers’ AI digital competencies and twenty-first century skills in the post-pandemic world, Educational Technology Research and Development, 71, 1, pp. 137-161, (2023); 
Ng D.T.K., Leung J.K.L., Su M.J., Yim I.H.Y., Qiao M.S., Chu S.K.W., AI literacy in K-16 classrooms, (2023); 
Ng D.T.K., Luo W., Chan H.M.Y., Chu S.K.W., Using digital story writing as a pedagogy to develop AI literacy among primary students, Computers and Education: Artificial Intelligence, 3, (2022); 
Ng D.T.K., Su J., Chu S.K.W., Fostering secondary school students’ AI literacy through making AI-driven recycling bins, Education and Information Technologies, pp. 1-32, (2023); 
Ng D.T.K., Wu W., Leung J.K.L., Chu S.K.W., Artificial Intelligence (AI) literacy questionnaire with confirmatory factor analysis, 2023 IEEE International Conference on Advanced Learning Technologies (ICALT), pp. 233-235, (2023); 
Park S.Y., Nam M.W., Cha S.B., University students' behavioral intention to use mobile learning: Evaluating the technology acceptance model, British Journal of Educational Technology, 43, 4, pp. 592-605, (2012); 
Pinski M., Benlian A., AI literacy-towards measuring human competency in artificial intelligence, (2023); 
Proulx V.K., Computer science vs computer literacy. Which to teach, (1994); 
Rodriguez-de-Dios I., Igartua J.J., Gonzalez-Vazquez A., Development and validation of a digital literacy scale for teenagers, Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality, pp. 1067-1072, (2016); 
Rogaten J., Rienties B., Sharpe R., Cross S., Whitelock D., Lygo-Baker S., Littlejohn A., Reviewing affective, behavioural and cognitive learning gains in higher education, Assessment & Evaluation in Higher Education, 44, 3, pp. 321-337, (2019); 
Sakulkueakulsuk B., Witoon S., Ngarmkajornwiwat P., Pataranutaporn P., Surareungchai W., Pataranutaporn P., Subsoontorn P., Kids making AI: Integrating machine learning, gamification, and social context in STEM education, IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE), pp. 1005-1010, (2018); 
Searson M., Hancock M., Soheil N., Shepherd G., Digital citizenship within global contexts, Education and Information Technologies, 20, pp. 729-741, (2015); 
Segun S.T., From machine ethics to computational ethics, AI & Society, 36, 1, pp. 263-276, (2021); 
Selwyn N., Gallo Cordoba B., Australian public understandings of artificial intelligence, AI & Society, 1-18, pp. 1645-1662, (2021); 
Sims R.R., Business ethics teaching for effective learning, Teaching Business Ethics, 6, 4, pp. 393-410, (2002); 
Song S.H., Keller J.M., The ARCS model for the design of motivationally adaptive computer-mediated instruction, Journal of Educational Technology, 14, 1, pp. 119-134, (1999); 
Stoeger H., Duan X., Schirner S., Greindl T., Ziegler A., The effectiveness of a one-year online mentoring program for girls in STEM, Computers & Education, 69, pp. 408-418, (2013); 
Su J., Zhong Y., Ng D.T.K., A meta-review of literature on educational approaches for teaching AI at the K-12 levels in the Asia-Pacific region, Computers and Education: Artificial Intelligence, 3, (2022); 
Sun J., Ma H., Zeng Y., Han D., Jin Y., Promoting the AI teaching competency of K-12 computer science teachers: A TPACK-based professional development approach, Education and Information Technologies, 28, 2, pp. 1509-1533, (2023); 
Tinmaz H., Lee Y.T., Fanea-Ivanovici M., Baber H., A systematic review on digital literacy, Smart Learning Environments, 9, 1, pp. 1-18, (2022); 
Touretzky D., Gardner-McCune C., Martin F., Seehorn D., Envisioning AI for K-12: What should every child know about AI?, Proceedings of the AAAI Conference on Artificial Intelligence, 33, 1, pp. 9795-9799, (2019); 
K-12 AI curricula: A mapping of government-endorsed AI curricula, (2022); 
van Harreveld F., Nohlen H.U., Schneider I.K., The ABC of ambivalence: Affective, behavioral, and cognitive consequences of attitudinal conflict, Advances in Experimental Social Psychology, 52, pp. 285-324, (2015); 
Vrieze S.I., Model selection and psychological theory: A discussion of the differences between the Akaike information criterion (AIC) and the Bayesian information criterion (BIC), Psychological Methods, 17, 2, pp. 228-243, (2012); 
Waelen R., Why AI ethics is a critical theory, Philosophy & Technology, 35, 1, pp. 1-16, (2022); 
Wan X., Zhou X., Ye Z., Mortensen C.K., Bai Z., SmileyCluster: Supporting accessible machine learning in K-12 scientific discovery, pp. 23-35, (2020); 
Wang B., Rau P.L.P., Yuan T., Measuring user competence in using artificial intelligence: Validity and reliability of artificial intelligence literacy scale, Behaviour & Information Technology, 1-14, pp. 1324-1337, (2022); 
Wei X., Saab N., Admiraal W., Assessment of cognitive, behavioral, and affective learning outcomes in massive open online courses: A systematic literature review, Computers & Education, 163, (2021); 
Williams R., Ali S., Devasia N., DiPaola D., Hong J., Kaputsos S.P., Jordan B., Breazeal C., AI+ ethics curricula for middle school youth: Lessons learned from three project-based curricula, International Journal of Artificial Intelligence in Education, 1-59, pp. 1-59, (2022); 
Xia Q., Chiu T.K., Lee M., Sanusi I.T., Dai Y., Chai C.S., A self-determination theory (SDT) design approach for inclusive and diverse artificial intelligence (AI) education, Computers & Education, 189, (2022); 
Xu J., Qiu X., The influence of self-regulation on learner's behavioral intention to reuse E-learning systems: A moderated mediation model, Frontiers in Psychology, 12, (2021); 
Yue M., Jong M.S.Y., Dai Y., Pedagogical design of K-12 artificial intelligence education: A systematic review, Sustainability, 14, 23, (2022); 
Yurdakul I.K., Coklar A.N., Modeling preservice teachers' TPACK competencies based on ICT usage, Journal of Computer Assisted Learning, 30, 4, pp. 363-376, (2014); 
Zhang H., Lee I., Ali S., DiPaola D., Cheng Y., Breazeal C., Integrating ethics and career futures with technical learning to promote AI literacy for middle school students: An exploratory study, International Journal of Artificial Intelligence in Education, 33, 2, pp. 290-324, (2023); 
Zhang Y., Wu M., Tian G.Y., Zhang G., Lu J., Ethics and privacy of artificial intelligence: Understandings from bibliometrics, Knowledge-Based Systems, 222, (2021)#FRF#
