#ITI#Effects of Feedback Types and Opportunities to Change Answers on Achievement and Ability to Solve Physics Problems#FTI#
#IRE#This study aimed to investigate the effects of feedback types and opportunities to change answers on the learners’ achievement and their ability to solve physics problems. We compared three feedback types, namely (1) static feedback with hints, (2) reducing feedback with hints, and (3) knowledge of response, and two types of opportunities to change answers, namely (a) no answer changing allowed and (b) answer changing allowed. Each participant was randomly assigned to take one of the six experimental conditions. It was found that participants provided with static feedback with hints and those provided with reducing feedback with hints had significantly higher achievement and ability to solve physics problems than those provided with knowledge of response feedback. Moreover, participants who were allowed to change the answers had significantly higher achievement and ability to solve physics problems than those who were not allowed to change the answers. Additionally, there was no interaction between feedback types and opportunities to change answers on achievement and ability to solve physics problems#FRE#
#IPC#Ability to solve physics problems; Answer changing; Feedback; Feedback schedules; Hints; Physics achievement#FPC#
#IRF#Al-Hamly M., Coombe C., To change or not to change: Investigating the value of MCQ answer changing for Gulf Arab students, Language Testing, 22, 4, pp. 509-531, (2005); 
Attali Y., Immediate feedback and opportunity to revise answers: application of a graded response IRT model, Applied Psychological Measurement, 35, 6, pp. 472-479, (2011); 
Attali Y., Effects of multiple-try feedback and question type during mathematics problem solving on performance in similar problems, Computers & Education, 86, pp. 260-267, (2015); 
Attali Y., Powers D., Immediate feedback and opportunity to revise answers to open-ended questions, Educational and Psychological Measurement, 70, 1, pp. 22-35, (2010); 
Attali Y., van der Kleij F., Effects of feedback elaboration and feedback timing during computer-based practice in mathematics problem solving, Computers & Education, 110, pp. 154-169, (2017); 
Attali Y., Laitusis C., Stone E., Differences in reaction to immediate feedback and opportunity to revise answers for multiple-choice and open-ended questions, Educational and Psychological Measurement, 76, 5, pp. 787-802, (2016); 
Belikov B.S., General methods for solving physics problems, (1989); 
Benjamin L.T., Cavell T.A., Shallenberger W.R., Staying with initial answers on objective tests: Is it a myth?, Teaching of Psychology, 11, 3, pp. 133-141, (1984); 
Bridgeman B., A simple answer to a simple question on changing answers, Journal of Educational Measurement, 49, 4, pp. 467-468, (2012); 
Brookhart S.M., How to give effective feedback to your students, (2008); 
Cohen J., Statistic power analysis for the behavioral sciences, (1988); 
Goodman J.S., Wood R.E., Faded versus increasing feedback, task variability trajectories, and transfer of training, Human Performance, 22, 1, pp. 64-85, (2009); 
Hattie J., Timperley H., The power of feedback, Review of Educational Research, 77, 1, pp. 81-112, (2007); 
Johnson A.M., Reisslein J., Reisslein M., Transitional feedback schedules during computer-based problem-solving practice, Computers & Education, 81, pp. 270-280, (2015); 
Liu O.L., Bridgeman B., Gu L., Xu J., Kong N., Investigation of response changes in the GRE revised general test, Educational and Psychological Measurement, 75, 6, pp. 1002-1020, (2015); 
Maier U., Wolf N., Randler C., Effects of a computer-assisted formative assessment intervention based on multiple-tier diagnostic items and different feedback types, Computers & Education, 95, pp. 85-98, (2016); 
Mason B.J., Bruning R., Providing feedback in computer-based instruction: What the research tells us, CLASS Research Report, 9, (2001); 
McMillan J.H., Classroom assessment: principles and practice for effective standards-based instruction, (2014); 
Merrel J.D., Cirillo P.F., Schwartz P.M., Webb J., Multiple-choice testing using immediate feedback-assessment technique (IF AT®) forms: second-chance guessing vs. second-chance learning?, Higher Education Studies, 5, 5, pp. 50-55, (2015); 
Miller M.D., Linn R., Gronlund N., Measurement and assessment in teaching, (2013); 
Narciss S., Sosnovsky S., Schnaubert L., Andres E., Eichelmann A., Goguadze G., Melis E., Exploring feedback and student characteristics relevant for personalizing feedback strategies, Computers & Education, 71, pp. 56-76, (2014); 
Nitko A.J., Educational assessment of students, (2004); 
Prinsell C.P., Ramsey P.H., Ramsey P.P., Score gains, attitudes, and behavior changes due to answer-changing instruction, Journal of Educational Measurement, 31, 4, pp. 327-337, (1994); 
Selcuk G.S., Caliskan S., Erol M., The effects of problem solving instruction on physics achievement, problem solving performance and strategy use, Latin American Journal of Physics Education, 2, 3, pp. 151-166, (2008); 
Shute V.J., Focus on Formative Feedback.Ets Research Report No. RR-, pp. 07-11, (2007); 
van der Kleij F.M., Feskens R.C., Eggen T.J., Effects of feedback in a computer-based learning environment on students’ learning outcomes: a meta-analysis, Review of Educational Research, 85, 4, pp. 475-511, (2015); 
Vispoel W.P., Hendrickson A.B., Bleiler T., Limiting answer review and change on computerized adaptive vocabulary tests: psychometric and attitudinal results, Journal of Educational Measurement, 37, 1, pp. 21-38, (2000)#FRF#
