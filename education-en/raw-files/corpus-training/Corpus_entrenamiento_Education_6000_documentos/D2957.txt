#ITI#P-hacking in meta-analyses: A formalization and new meta-analytic methods#FTI#
#IRE# As traditionally conceived, publication bias arises from selection operating on a collection of individually unbiased estimates. A canonical form of such selection across studies (SAS) is the preferential publication of affirmative studies (i.e., those with significant, positive estimates) versus nonaffirmative studies (i.e., those with nonsignificant or negative estimates). However, meta-analyses can also be compromised by selection within studies (SWS), in which investigators “p-hack” results within their study to obtain an affirmative estimate. Published estimates can then be biased even conditional on affirmative status, which comprises the performance of existing methods that only consider SAS. We propose two new analysis methods that accommodate joint SAS and SWS; both analyze only the published nonaffirmative estimates. First, we propose estimating the underlying meta-analytic mean by fitting “right-truncated meta-analysis” (RTMA) to the published nonaffirmative estimates. This method essentially imputes the entire underlying distribution of population effects. Second, we propose conducting a standard meta-analysis of only the nonaffirmative studies (MAN); this estimate is conservative (negatively biased) under weakened assumptions. We provide an R package (phacking) and website (metabias.io). Our proposed methods supplement existing methods by assessing the robustness of meta-analyses to joint SAS and SWS#FRE#
#IPC# Bayesian analysis; data dredging; file drawer; selective reporting; truncation#FPC#
#IRF# Marks-Anglin A., Chen Y., A historical review of publication bias, Res Synth Methods, 11, 6, pp. 725-742, (2020); 
Jin Z.-C., Zhou X.-H., He J., Statistical methods for dealing with publication bias in meta-analysis, Stat Med, 34, 2, pp. 343-360, (2015); 
Duval S., Tweedie R., Trim and fill: a simple funnel-plot–based method of testing and adjusting for publication bias in meta-analysis, Biometrics, 56, 2, pp. 455-463, (2000); 
Egger M., Smith G.D., Schneider M., Minder C., Bias in meta-analysis detected by a simple, graphical test, BMJ, 315, 7109, pp. 629-634, (1997); 
Dear K.B.G., Begg C.B., An approach for assessing publication bias prior to performing a meta-analysis, Stat Sci, 7, pp. 237-245, (1992); 
Hedges L.V., Modeling publication selection effects in meta-analysis, Stat Sci, 7, pp. 246-255, (1992); 
Vevea J.L., Hedges L.V., A general linear model for estimating effect size in the presence of publication bias, Psychometrika, 60, 3, pp. 419-435, (1995); 
Andrews I., Kasy M., Identification of and correction for publication bias, Am Econ Rev, 109, 8, pp. 2766-2794, (2019); 
Mathur M.B., VanderWeele T.J., Sensitivity analysis for publication bias in meta-analyses, J R Stat Soc Ser C Appl Stat, 69, 5, pp. 1091-1119, (2020); 
Stanley T.D., Doucouliagos H., Meta-regression approximations to reduce publication selection bias, Res Synth Methods, 5, 1, pp. 60-78, (2014); 
Bom P.R.D., Rachinger H., A kinked meta-regression model for publication bias correction, Res Synth Methods, 10, 4, pp. 497-514, (2019); 
Bartos F., Maier M., Wagenmakers E.-J., Doucouliagos H., Stanley T.D., Robust bayesian meta-analysis: model-averaging across complementary publication bias adjustment methods, Res Synth Methods, 14, 1, pp. 99-116, (2023); 
Dwan K., Altman D.G., Arnaiz J.A., Et al., Systematic review of the empirical evidence of study publication bias and outcome reporting bias, PLoS One, 3, 8, (2008); 
Franco A., Malhotra N., Simonovits G., Publication bias in the social sciences: unlocking the file drawer, Science, 345, 6203, pp. 1502-1505, (2014); 
Greenwald A.G., Consequences of prejudice against the null hypothesis, Psychol Bull, 82, 1, pp. 1-20, (1975); 
Hahn S., Williamson P.R., Hutton J.L., Investigation of within-study selective reporting in clinical research: follow-up of applications submitted to a local research ethics committee, J Eval Clin Pract, 8, 3, pp. 353-359, (2002); 
Simonsohn U., Nelson L.D., Simmons J.P., P-curve: a key to the file-drawer, J Exp Psychol Gen, 143, 2, (2014); 
Simmons J.P., Nelson L.D., Simonsohn U., False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant, Psychol Sci, 22, 11, pp. 1359-1366, (2011); 
Brodeur A., Le M., Sangnier M., Zylberberg Y., Star wars: the empirics strike back, Am Econ J Appl Econ, 8, 1, pp. 1-32, (2016); 
Jager L.R., Leek J.T., An estimate of the science-wise false discovery rate and application to the top medical literature, Biostatistics, 15, 1, pp. 1-12, (2014); 
Brodeur A., Cook N., Heyes A., Methods matter: P-hacking and publication bias in causal analysis in economics, Am Econ Rev, 110, 11, pp. 3634-3660, (2020); 
John L.K., Loewenstein G., Prelec D., Measuring the prevalence of questionable research practices with incentives for truth telling, Psychol Sci, 23, 5, pp. 524-532, (2012); 
Stefan A.M., Schonbrodt F.D., Big little lies: a compendium and simulation of p-hacking strategies, R Soc Open Sci, 10, 2, (2023); 
Phillips C.V., Publication bias in situ, BMC Med Res Methodol, 4, 1, (2004); 
Carter E.C., Schonbrodt F.D., Gervais W.M., Hilgard J., Correcting for bias in psychology: a comparison of meta-analytic methods, Adv Methods Pract Psychol Sci, 2, 2, pp. 115-144, (2019); 
Van Assen M.A.L.M., van Aert R., Wicherts J.M., Meta-analysis using effect size distributions of only statistically significant studies, Psychol Methods, 20, 3, pp. 293-309, (2015); 
McShane B.B., Bockenholt U., Hansen K.T., Adjusting for publication bias in meta-analysis: an evaluation of selection methods and some cautionary notes, Perspect Psychol Sci, 11, 5, pp. 730-749, (2016); 
Mathur M.B., VanderWeele T.J., Estimating publication bias in meta-analyses of peer-reviewed studies: a meta-meta-analysis across disciplines and journal tiers, Res Synth Methods, 12, 2, pp. 176-191, (2021); 
Moss J., De Bin R., Modelling publication bias and p-hacking, Biometrics, 79, pp. 319-331, (2021); 
McShane B.B., Gal D., Statistical significance and the dichotomization of evidence, J Am Stat Assoc, 112, 519, pp. 885-895, (2017); 
Head M.L., Holman L., Lanfear R., Kahn A.T., Jennions M.D., The extent and consequences of p-hacking in science, PLoS Biol, 13, 3, (2015); 
Masicampo E.J., Lalande D.R., A peculiar prevalence of p values just below.05, Q J Exp Psychol, 65, 11, pp. 2271-2279, (2012); 
Cope E.W., Penalized likelihood estimators for truncated data, J Stat Plan Inference, 141, 1, pp. 345-358, (2011); 
Zhou X., Giacometti R., Fabozzi F.J., Tucker A.H., Bayesian estimation of truncated data with applications to operational risk measurement, Quant Finance, 14, 5, pp. 863-888, (2014); 
Mittal M.M., Dahiya R.C., Estimating the parameters of a doubly truncated normal distribution: estimating the parameters, Commun Stat Simul Comput, 16, 1, pp. 141-159, (1987); 
Jeffreys H., An invariant form for the prior probability in estimation problems, Proc R Soc A Math Phy. En. Sc., 186, 1007, pp. 453-461, (1946); 
Firth D., Bias reduction of maximum likelihood estimates, Biometrika, 80, 1, pp. 27-38, (1993); 
DerSimonian R., Laird N., Meta-analysis in clinical trials, Control Clin Trials, 7, 3, pp. 177-188, (1986); 
Rodgers M.A., Pustejovsky J.E., Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes, Psychol Methods, 26, 2, pp. 141-160, (2021); 
Copas J., Jackson D., A bound for publication bias based on the fraction of unpublished studies, Biometrics, 60, 1, pp. 146-153, (2004); 
Hedges L.V., Tipton E., Johnson M.C., Robust variance estimation in meta-regression with dependent effect size estimates, Res Synth Methods, 1, 1, pp. 39-65, (2010); 
Fisher Z., Tipton E., Robumeta: an R-package for robust variance estimation in meta-analysis, arXiv, (2015); 
Pustejovsky J.E., Tipton E., Meta-analysis with robust variance estimation: expanding the range of working models, Prev Sci, 23, 3, pp. 425-438, (2022); 
Tipton E., Small sample adjustments for robust variance estimation with meta-regression, Psychol Methods, 20, 3, pp. 375-393, (2015); 
Lodder P., Ong H.H., Grasman R.P.P.P., Wicherts J.M., A comprehensive meta-analysis of money priming, J Exp Psychol Gen, 148, 4, pp. 688-712, (2019); 
Gelman A., Carlin J., Stern H., Dunson D., Vehtari A., Rubin D.B., Bayesian data analysis., (2014); 
Vehtari A., Gelman A., Simpson D., Carpenter B., Burkner P.-C., Rank-normalization, folding, and localization: an improved R̂ for assessing convergence of MCMC (with discussion), Bayesian Anal, 16, 2, (2021); 
Carpenter B., Gelman A., Hoffman M.D., Et al., Stan: a probabilistic programming language, J Stat Softw, 76, 1, (2017); 
Iyengar S., Greenhouse J.B., Selection models and the file drawer problem, Stat Sci, 3, pp. 109-117, (1988); 
Miguel A.V., Hardwicke T.E., Shanks D.R., Selection bias, vote counting, and money-priming effects: a comment on Rohrer, Pashler, and Harris (2015) and Vohs (2015), J Exp Psychol Gen, 145, 5, pp. 655-663, (2016); 
Allen C., Mehler D.M.A., Open science challenges, benefits and tips in early career and beyond, PLoS Biol, 17, 5, (2019); 
Kaplan R.M., Irvin V.L., Likelihood of null effects of large NHLBI clinical trials has increased over time, PLoS One, 10, 8, (2015); 
Hedges L.V., Distribution theory for Glass's estimator of effect size and related estimators, J Educ Stat, 6, 2, pp. 107-128, (1981); 
Viechtbauer W., Conducting meta-analyses in R with the metafor package, J Stat Softw, 36, 3, (2010); 
Viechtbauer W., Bias and efficiency of meta-analytic variance estimators in the random-effects model, J Educ Behav Stat, 30, 3, pp. 261-293, (2005); 
Knapp G., Hartung J., Improved tests for a random effects meta-regression with a single covariate, Stat Med, 22, 17, pp. 2693-2710, (2003); 
Coburn K.M., Vevea J.L., weightr: Estimating weight-function models for publication bias. R package version 2.0.2, (2019); 
Claesen A., Gomes S., Tuerlinckx F., Vanpaemel W., Comparing dream to reality: an assessment of adherence of the first generation of preregistered studies, R Soc Open Sci, 8, 10, (2021); 
Stefan A.M., phackR: Simulate p-Hacking. R package version 0.0.0.9000, (2023); 
Mathur M.B., Sensitivity analysis for the interactive effects of internal bias and publication bias in meta-analyses. Res Synth Methods; 
Mathur M.B., VanderWeele T.J., New metrics for meta-analyses of heterogeneous effects, Stat Med, 38, 8, pp. 1336-1342, (2019); 
Mathur M.B., VanderWeele T.J., Robust metrics and sensitivity analyses for meta-analyses of heterogeneous effects, Epidemiology, 31, 3, pp. 356-358, (2020); 
Mathur M.B., VanderWeele T.J., Sensitivity analysis for unmeasured confounding in meta-analyses, J Am Stat Assoc, 115, 529, pp. 163-172, (2020); 
Mathur M.B., Wang R., VanderWeele T.J., MetaUtility: Utility Functions for Conducting and Interpreting Meta-Analyses. R package version 2.1.0, (2019); 
Alinaghi N., Robert Reed W., Meta-analysis and publication bias: how well does the FAT-PET-PEESE procedure work?, Res Synth Methods, 9, 2, pp. 285-311, (2018); 
Maier M., VanderWeele T., Mathur M., Using selection models to assess sensitivity to publication bias: a tutorial and call for more routine use. Campbell Syst Rev, (2022)#FRF#
