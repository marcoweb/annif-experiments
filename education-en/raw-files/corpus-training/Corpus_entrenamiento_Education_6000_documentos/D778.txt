#ITI#Assessment of factual recall and higher-order cognitive domains in an open-book medical school examination#FTI#
#IRE# Open-book examinations (OBEs) will likely become increasingly important assessment tools. We investigated how access to open-book resources affected questions testing factual recall, which might be easy to look-up, versus questions testing higher-order cognitive domains. Few studies have investigated OBEs using modern Internet resources or as summative assessments. We compared performance on an examination conducted as a traditional closed-book exam (CBE) in 2019 (N = 320) and a remote OBE with free access to Internet resources in 2020 (N = 337) due to COVID-19. This summative, end-of-year assessment focused on basic science for second-year medical students. We categorized questions by Bloom’s taxonomy (‘Remember’, versus ‘Understand/Apply’). We predicted higher performance on the OBE, driven by higher performance on ‘Remember’ questions. We used an item-centric analysis by using performance per item over all examinees as the outcome variable in logistic regression, with terms ‘Open-Book, ‘Bloom Category’ and their interaction. Performance was higher on OBE questions than CBE questions (OR 2.2, 95% CI: 2.14–2.39), and higher on ‘Remember’ than ‘Understand/Apply’ questions (OR 1.13, 95% CI: 1.09–1.19). The difference in performance between ‘Remember’ and ‘Understand/Apply’ questions was greater in the OBE than the CBE (‘Open-Book’ * ‘Bloom Category’ interaction: OR 1.2, 95% CI: 1.19–1.37). Access to open-book resources had a greater effect on performance on factual recall questions than higher-order questions, though performance was higher in the OBE overall. OBE design must consider how searching for information affects performance, particularly on questions measuring different domains of knowledge#FRE#
#IPC# Assessment; Medical education; Open-book examinations#FPC#
#IRF# Agarwal P.K., Roediger H.L., Expectancy of an open-book test decreases performance on a delayed closed-book test, Memory, 19, 8, pp. 836-852, (2011); 
Anderson L.W., Krathwohl D.R., Bloom B.S., A taxonomy for learning, teaching, and assessing: A revision of Bloom’s taxonomy of educational objectives, (2001); 
Baillie C., Toohey S., The “power test”: Its impact on student learning in a materials science course for engineering students, Assessment and Evaluation in Higher Education, 22, 1, pp. 33-48, (1997); 
Barsky E., Bar-Ilan J., The impact of task phrasing on the choice of search keywords and on the search process and success, Journal of the American Society for Information Science and Technology, 63, 10, pp. 1987-2005, (2012); 
Bell D.J., Ruthven L., Lecture Notes in Computer Science (Including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Searcher’s Assessments of Task Complexity for Web Searching, 2997, (2004); 
Betts L.R., Elder T.J., Hartley J., Trueman M., Does correction for guessing reduce students’ performance on multiple-choice examinations? yes? no? sometimes?, Assessment and Evaluation in Higher Education, 34, 1, pp. 1-15, (2009); 
Bloom B.S., Taxonomy of Educational Objectives: Cognitive Domain (Vol. 1). New York: Mckay, pp. 10-111, (1965); 
Boniface D., Candidates’ use of notes and textbooks during an open-book examination, Educational Research, 27, 3, pp. 201-209, (1985); 
Broyles I.L., Cyr P.R., Korsen N., Open book tests: Assessment of academic learning in clerkships, Medical Teacher, 27, 5, pp. 456-462, (2005); 
Bystrom K., Jarvelin K., Task complexity affects information seeking and use, Information Processing and Management, 31, 2, pp. 191-213, (1995); 
Campbell D.J., Task complexity: A review and analysis, Academy of Management Review, 13, 1, pp. 40-52, (1988); 
Chevalier A., Dommes A., Marquie J.C., Information searching on the web: The cognitive difficulties experienced by older users in modifying unsuccessful information searches, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 6781, pp. 225-232, (2011); 
Craig C., Kasana N., Modi A., Virtual OSCE delivery: The way of the future?, Medical Education, Medu, 14286, (2020); 
Cronbach L.J., Coefficient alpha and the internal structure of tests, Psychometrika, 16, (1951); 
Cunnington J.P.W., Norman G.R., Blake J.M., Dauphinee W.D., Blackmore D.E., Applying learning taxonomies to test items: Is a fact an artifact?, Academic Medicine, 71, 10, pp. s31-s33, (1996); 
Dickson K.L., Miller M.D., Authorized crib cards do not improve exam performance, Teaching of Psychology, 32, 4, pp. 230-233, (2005); 
Dinet J., Chevalier A., Tricot A., Information search activity: An overview, Revue Europeene De Psychologie Appliquee, 62, 2, pp. 49-62, (2012); 
Dommes A., Chevalier A., The role of cognitive flexibility and vocabulary abilities of younger and older users in searching for information on the web, Article in Applied Cognitive Psychology, 25, 5, pp. 717-726, (2011); 
Durning S.J., Dong T., Ratcliffe T., Schuwirth L., Artino A.R., Boulet J.R., Eva K., Comparing open-book and closed-book examinations: A systematic review, Academic Medicine, (2016); 
Eva K.W., Anderson M.B., Medical education adaptations: Really good stuff for educational transition during a pandemic, Medical Education, 54, 6, (2020); 
Ford N., Miller D., Moss N., Web search strategies and human individual differences: Cognitive and demographic factors, internet attitudes, and approaches, Journal of the American Society for Information Science and Technology, 56, 7, pp. 741-756, (2005); 
Fuller R., Joynes V., Cooper J., Boursicot K., Roberts T., Could COVID-19 be our ‘There is no alternative’ (TINA) opportunity to enhance assessment?, Medical Teacher, 42, 7, pp. 781-786, (2020); 
Furst E.J., Bloom’s taxonomy of educational objectives for the cognitive domain: Philosophical and educational issues, Review of Educational Research, 51, 4, pp. 441-453, (1981); 
Gharib A., Phillips W., Mathew N., Cheat Sheet or Open-Book? A Comparison of the Effects of Exam Types on Performance, Retention, and Anxiety *, Psychology Research, 2, (2012); 
Gierl M.J., Comparing cognitive representations of test developers and students on a mathematics test with bloom’s taxonomy, Journal of Educational Research, 91, 1, pp. 26-32, (1997); 
Goethals G.R., Theories of group behavior: commentary, Theories of Group Behavior, (1987); 
Haladyna T.M., Rodriguez M.C., Developing and validating test items, Developing and Validating Test Items, (2013); 
Hamamoto Filho P.T., Silva E., Ribeiro Z.M.T., de Hafner M., Cecilio-Fernandes A.M., Relationships between Bloom’s taxonomy, judges’ estimation of item difficulty and psychometric properties of items from a progress test: A prospective observational study, Sao Paulo Medical Journal, 138, 1, pp. 33-39, (2020); 
Hancock G.R., Cognitive complexity and the comparability of multiple-choice and constructed-response test formats, Journal of Experimental Education, 62, 2, pp. 143-157, (1994); 
Hannon P., Lappe K., Griffin C., Roussel D., Colbert-Getz J., An objective structured clinical examination: From examination room to Zoom breakout room, Medical Education, 54, 9, (2020); 
Hargittai E., Digital Na(t)ives? Variation in internet skills and uses among members of the “Net Generation, Sociological Inquiry, 80, 1, pp. 92-113, (2010); 
Hargittai E., Hinnant A., Digital inequality, Communication Research, 35, 5, pp. 602-621, (2008); 
Heijne-Penninga M., Kuks J.B.M., Hofman W.H.A., Cohen-Schotanus J., Influence of open- and closed-book tests on medical students’ learning approaches, Medical Education, 42, 10, pp. 967-974, (2008); 
Kane M., Educational measurement, Validation, (2006); 
Kass R.E., Raftery A.E., Bayes factors, Journal of the American Statistical Association, 90, 430, pp. 773-795, (1995); 
Krarup N., Naeraa N., Olsen C., Open-book tests in a university course, Higher Education, 3, 2, pp. 157-164, (1974); 
Larwin K.H., Gorman J., Larwin D.A., Assessing the impact of testing aids on post-secondary student performance: A meta-analytic investigation, Educational Psychology Review, 25, 3, pp. 429-443, (2013); 
Lizzio A., Wilson K., Simons R., University students’ perceptions of the learning environment and academic outcomes: Implications for theory and practice, Studies in Higher Education, 27, 1, pp. 27-52, (2002); 
Martinez M.E., Cognition and the question of test item format, Educational Psychologist, 34, 4, pp. 207-218, (1999); 
Marzano R.J., Kendall J.S., The new taxonomy of educational objectives, The New Taxonomy of Educational Objectives 2Nd, 2nd, (2007); 
Messick S., The psychology of educational measurement, ETS Research Report Series, 1984, 1, (1984); 
Momsen J.L., Long T.M., Wyse S.A., Ebert-May D., Just the facts? introductory undergraduate biology courses focus on low-level cognitive skills, CBE Life Sciences Education, 9, 4, pp. 435-440, (2010); 
Mooney C.J., Peyre S.E., Clark N.S., Nofziger A.C., Rapid transition to online assessment: Practical steps and unanticipated advantages, Medical Education, 54, 9, pp. 857-858, (2020); 
Moore B.R., Jensen P.A., Do Open-Book Exams Impede Long-Term Learning in Introductory Biology Coursesâ€¯?, Journal of College Science Teaching, pp. 46-50, (2007); 
Robinson L., Cotten S.R., Ono H., Quan-Haase A., Mesch G., Chen W., Et al., Digital inequalities and why they matter, Information Communication and Society, 18, 5, pp. 569-582, (2015); 
Sam A.H., Reid M.D., Amin A., High-stakes, remote-access, open-book examinations, Medical Education, 54, 8, pp. 767-768, (2020); 
Sanchiz M., Chin J., Chevalier A., Fu W.T., Amadieu F., He J., Searching for information on the web: Impact of cognitive aging, prior domain knowledge and complexity of the search problems, Information Processing and Management, 53, 1, pp. 281-294, (2017); 
Schwartzstein R.M., Roberts D.H., Saying goodbye to lectures in medical school—Paradigm shift or passing fad?, New England Journal of Medicine, 377, 7, pp. 605-607, (2017); 
Tamblyn R., Abrahamowicz M., Dauphinee D., Wenghofer E., Jacques A., Klass D., Et al., Physician scores on a national clinical skills examination as predictors of complaints to medical regulatory authorities, Journal of the American Medical Association, 298, 9, pp. 993-1001, (2007); 
Theophilides C., Dionysiou O., The major functions of the open-book examination at the university level: A factor analytic study, Studies in Educational Evaluation, 22, 2, pp. 157-170, (1996); 
Trigwell K., Prosser M., Improving the quality of student learning: The influence of learning context and student approaches to learning on learning outcomes, Higher Education, 22, 3, pp. 251-266, (1991); 
Ward A.F., Supernormal: How the internet is changing our memories and our minds, Psychological Inquiry, 24, 4, pp. 341-348, (2013); 
Zagury-Orly I., Durning S.J., Assessing open-book examination in medical education: The time is now, Medical Teacher, (2020)#FRF#
