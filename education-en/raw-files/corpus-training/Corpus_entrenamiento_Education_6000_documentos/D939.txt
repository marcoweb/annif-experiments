#ITI#Digitalization of Multistep Chemistry Exercises with Automated Formative Feedback#FTI#
#IRE# For various reasons, students receive less formative feedback at post-secondary institutions compared to secondary school. Considering feedback as one of the most important influencing factors on learning processes, formative feedback is a promising approach to improving students’ performances. In this context, new technologies, such as learning management systems (LMS) or intelligent tutoring systems (ITS), can make a valuable contribution to improving higher education teaching by providing automated and individualized error-specific just-in-time (JIT) feedback. However, the digitalization especially of paper-based open-ended tasks that can be used by LMS is currently still associated with a loss of quality. In this paper, we present an approach that allows us to transfer open-ended paper-based tasks in the field of chemistry into online tasks without losing quality and provide large university courses with automated and individualized error-specific JIT feedback. Results of a study of 238 first-year chemistry students reveal that the automated individualized error-specific JIT feedback had a significant positive influence on students’ performance#FRE#
#IPC# Automated formative feedback; Chemistry education; E-assessment; Higher education#FPC#
#IRF# Atlas of science literacy, 1, (2001); 
Anderson J.R., Bower G.H., Recognition and retrieval process in free recall, Psychological Review, 79, pp. 97-132, (1972); 
Ashton H., Beevers C.E., Korabinski A.A., Youngson M.A., Investigating the medium effect in computer-aided assessment of school chemistry and college computing national examinations, British Journal of Educational Technology, 36, 5, pp. 771-787, (2005); 
Averbeck D., Zum Studienerfolg in der Studieneingangsphase des Chemiestudiums: Der Einfluss kognitiver und affektiv-motivationaler Variablen [On academic success in the introductory phase of chemistry studies, The Influence of Cognitive and Affective-Motivational Variables, (2021); 
Bonner S.M., Mathematics strategy use in solving test items in varied formats, The Journal of Experimental Education, 81, pp. 409-428, (2013); 
Bridgeman B., Trapani C., Attali Y., Comparison of human and machine scoring of essays: Differences by gender, ethnicity, and country, Applied Measurement in Education, 25, pp. 27-40, (2012); 
Busker M., Parchmann I., Wickleder M., Eingangsvoraussetzungen von Studienanfängern im Fach Chemie: Welches Vorwissen und welche Interessen zeigen Studierende? [Entrance requirements for first-year students in chemistry: What prior knowledge and interests do students have?], Chemkon, 17, 4, pp. 163-168, (2010); 
Avalcanti A.P., Barbosa A., Carvalho R., Freitas F., Tsai Y.-S., Gasevic D., Mello R.F., Automatic feedback in online learning environments: A systematic literature review, Computers and Education: Artificial Intelligence, C, (2021); 
Chamala R.R., Ciochina R., Grossmann R.B., Finkel R.A., Kannan S., Ramachandran P., EPOCH: An organic chemistry homework program that offers responsive-specific feedback to students, Journal of Chemical Education, 83, 1, pp. 164-169, (2006); 
Chen X., STEM attrition. College students‘ path into and out of STEM fields, Statistical Analysis Report. Nces, pp. 2014-3001, (2013); 
Cole R., Todd J., Effects of web-based multimedia homework with immediate rich feedback on students learning in general chemistry, Journal of Chemical Education, 80, 11, pp. 1338-1343, (2003); 
Deboer G.E., Hermann-Abell C.F., Wertheim J., Roseman J.E., Assessment linked to middle school science learning goals: A report on field test results for four middle school science topics [Conference Paper], Annual Conference of the National Association of Research in Science Teaching, (2009); 
de Bruin A.B.H., Kok E.M., Lobbestael J., de Grip A., The impact of an online tool for monitoring and regulating learning at university: Overconfidence, learning strategy, and personality, Metacognition Learning, 12, 1, pp. 21-43, (2017); 
Ferber N., Entwicklung Und Validierung Eines Testinstruments Zur Erfassung Von Kompetenzentwicklung Im Fach Chemie in Der Sekundarstufe I, (2014); 
Freasier B., Collins G., Newitt P., A web-based interactive homework quiz and tutorial package to motivate undergraduate chemistry students and improve learning, Journal of Chemical Education, 80, 11, pp. 1344-1347, (2003); 
Freyer K., Zum Einfluss von Studieneingangsvoraussetzungen auf den Studienerfolg Erstsemesterstudierender im Fach Chemie [On the influence of study entry requirements on the study success of first-semester students in chemistry], (2013); 
Haladyna T.M., Rodriguez M.C., Developing and validating test items, (2013); 
Hattie J., Timperley H., The power of feedback, Review of Educational Research, 77, 1, pp. 81-112, (2007); 
Hattie J., Calibration and confidence: Where to next?, Learning and Instruction, 24, pp. 62-66, (2013); 
Hedtrich S., Graulich N., Using software tools to provide students in large classes with individualized formative feedback, Journal of Chemical Education, 95, pp. 2263-2267, (2018); 
Herding D., Zimmermann M., Bescherer C., Schroeder U., (2010). Entwicklung Eines Frameworks für Semi-Automatisches Feedback Zur Unterstützung Bei Lernprozessen. Development of a Framework for Semi-Automated Feedback to Support Learning Processes [Conference Paper]. Proceedings of the Delfi, (2010); 
Heublein U., Richter J., Schmelzer R., Die Entwicklung der Studienabbruchquoten in Deutschland. The Development of Dropout Rates in Germany, (DZHW Brief 3|2020), (2020); 
Heublein U., Ebert J., Hutzsch C., Isleib S., Konig R., Richter J., Woisch A., Zwischen Studienerwartungen und Studienwirklichkeit: Ursachen des Studienabbruchs, beruflicher Verbleib der Studienabbrecherinnen und Studienabbrecher und Entwicklung der Studienabbruchquote an deutschen Hochschulen. Between study expectations and study reality: Causes of termination of studies, occupational reasons for termination of studies and development of the rate of termination of studies at German universities. DZHW: Hannover., (2017); 
Hohensinn C., Kubinger K.D., Applying item response theory methods to examine the impact of different response formats, Educational and Psychological Measurement, 71, pp. 732-746, (2011); 
Hussein M.A., Hassan H., Nassef M., Automated language essay scoring systems: A literature review, PeerJ Computer Science, 5, (2019); 
Kanuka H., University student perceptions of the use of the web in distance-delivered programs, The Canadian Journal of Higher Education, 31, pp. 49-71, (2001); 
Kastner M., Stangl B., Multiple choice and constructed response tests: Do test format and scoring matter?, Procedia –Social and Behavioral Sciences, 12, pp. 263-273, (2011); 
Keuning H., Jeuring J., Heeren B.A., Systematic literature review of automated feedback generation for programming exercises, ACM Transactions on Computing Education (TOCE), 19, 1, pp. 1-43, (2018); 
Kluger A.N., DeNisi A., The effects of feedback interventions on performance: A historical review, a meta-analysis, and a preliminary feedback intervention theory, Psychological Bulletin, 119, 2, pp. 254-284, (1996); 
Kruger J., Dunning D., Unskilled and unaware of it: How difficulties in recognizing one’s own incompetence lead to inflated self-assessments, Journal of Personality and Social Psychology, 77, 6, pp. 1121-1134, (1999); 
Leacock C., Chodorow M., C-rater: Automated scoring of short-answer questions, Computers and the Humanities, 37, 4, pp. 389-405, (2003); 
Lindner M.A., Strobel B., Koller O., Multiple choice-Prüfungen an Hochschulen? Ein Literaturüberblick und Plädoyer für mehr praxisorientierte Forschung [Multiple choice exams at universities? A literature review and plea for more practice-oriented research], Zeitschrift Für Pädagogische Psychologie, 29, 3-4, pp. 133-149, (2015); 
Liu O.L., Lee H.S., Linn M.C., An investigation of explanation multiple choice items in science assessment, Educational Assessment, 16, pp. 164-184, (2011); 
Lodder J., Heeren B.A., A teaching tool for proving equivalences between logical formulae [Conference paper, ]. International Congress on Tools for Teaching Logic, (2011); 
Ma W., Adesope O., Nesbit J., Liu Q., Intelligent tutoring systems and learning outcomes: A meta-analysis, Journal of Educational Psychology, 106, 4, (2014); 
Malik K., Martinez N., Romero J., Schubel S., Janowicz P.A., Mixed-methods study of online and written organic chemistry homework, Journal of Chemical Education, 91, 11, pp. 1804-1809, (2014); 
Muller W., Bescherer C., Kortenkamp U., Spannagel C., Intelligent computer-aided assessment in math classroom: State-of-the-art and perspectives [Conference paper], Proceedings of the Conference on Imaging the Future for ICT and Education, Alesund University College, Norway., (2006); 
Narciss S., Huth K., Fostering achievement and motivation with bug-related tutoring feedback in a computer-based training for written subtraction, Learning and Instruction, 16, pp. 310-322, (2006); 
Pazicni S., Bauer C.F., Characterizing illusions of competence in introductory chemistry students, Chemistry Education Research and Practice, 15, 1, pp. 24-34, (2014); 
Penn J.H., Al-Shammari A.G., Teaching reaction mechanisms using the curved arrow neglect (CAN) method, Journal of Chemical Education, 85, 9, pp. 1291-1295, (2008); 
Perry S., Bulatov I., Roberts E., The use of E-assessment in chemical engineering education, Chemical Engineering Transaction, 12, pp. 555-560, (2007); 
Domain-specific extensions for an E-assessment system, Advances in Web-Based Learning – ICWL 2019. Lecture Notes in Computer Science, 11841, (2019); 
Schmid U., Goertz L., Radomski S., Thom S., Behrens J., Monitor Digitale Bildung: Die Hochschulen Im Digitalen Zeitalter, (2017); 
Shepherd T.D., Mastering chemistry, Journal of Chemical Education, 86, 6, (2009); 
Shermis M.D., Burstein J.C., Automated essay scoring: A cross-disciplinary perspective, (2002); 
Shermis M.D., Burstein J.C., Handbook of automated essay evaluation: Current applications and new directions, (2013); 
Striewe M., An architecture for modular grading and feedback generation for complex exercises, Science of Computer Programming, 129, pp. 35-47, (2016); 
Trauten F., Eitemuller C., Walpuski M., Entwicklung und Evaluation von feedbackgestützten Online-Chemieaufgaben, 2018, pp. 846-849, (2019); 
Walpuski M., Ropohl M., Sumfleth E., Students’ knowledge about chemical reactions - development and analysis of standard-based test items, Chemistry Education Research and Practice, 12, pp. 174-183, (2011); 
Wisniewski B., Zierer K., Hattie J., The power of feedback revisited: A meta-analysis of educational feedback research, Frontiers in Psychology, 10, 3087, (2020); 
Yorke M., Formative assessment in higher education, Higher Education, 45, 4, pp. 477-501, (2003)#FRF#
