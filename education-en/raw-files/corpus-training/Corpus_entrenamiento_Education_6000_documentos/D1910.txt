#ITI#Algorithmic Bias in Education#FTI#
#IRE# In this paper, we review algorithmic bias in education, discussing the causes of that bias and reviewing the empirical literature on the specific ways that algorithmic bias is known to have manifested in education. While other recent work has reviewed mathematical definitions of fairness and expanded algorithmic approaches to reducing bias, our review focuses instead on solidifying the current understanding of the concrete impacts of algorithmic bias in education—which groups are known to be impacted and which stages and agents in the development and deployment of educational algorithms are implicated. We discuss theoretical and formal perspectives on algorithmic bias, connect those perspectives to the machine learning pipeline, and review metrics for assessing bias. Next, we review the evidence around algorithmic bias in education, beginning with the most heavily-studied categories of race/ethnicity, gender, and nationality, and moving to the available evidence of bias for less-studied categories, such as socioeconomic status, disability, and military-connected status. Acknowledging the gaps in what has been studied, we propose a framework for moving from unknown bias to known bias and from fairness to equity. We discuss obstacles to addressing these challenges and propose four areas of effort for mitigating and resolving the problems of algorithmic bias in AIED systems and other educational technology#FRE#
#IPC# Algorithmic bias; Algorithmic fairness; Artificial intelligence and education; Machine learning#FPC#
#IRF# Ali M., Sapiezynski P., Bogen M., Korolova A., Mislove A., Rieke A., Discrimination through optimization: How Facebook’s ad delivery can Lead to biased outcomes, Proceedings of the ACM on Human-Computer Interaction, 3, CSCW, (2019); 
Anderson H., Boodhwani A., Baker R.S., Assessing the fairness of graduation predictions, Proceedings of the 12Th International Conference on Educational Data Mining, pp. 488-491, (2019); 
Angwin J., Larson J., Mattu S., Kirchner L., Machine Bias: There’s software used across the country to predict future criminals., (2016); 
Arroyo I., Burleson W., Tai M., Muldner K., Woolf B.P., Gender differences in the use and benefit of advanced learning Technologies for Mathematics, Journal of Educational Psychology, 105, 4, pp. 957-969, (2013); 
ASSISTmentsData: Terms of Use for Using Data. Retrieved January 7, 2021, From, (2014); 
Baker R.S., Challenges for the future of educational data mining: The Baker learning analytics prizes, Journal of Educational Data Mining, 11, 1, pp. 1-17, (2019); 
Baker R.S.J.D., Corbett A.T., Koedinger K.R., Evenson S., Roll I., Wagner A.Z., Naim M., Raspat J., Baker D.J., Beck J.E., Adapting to When Students Game an Intelligent Tutoring System, Proceedings of the 8Th International Conference on Intelligent Tutoring Systems, pp. 392-401, (2006); 
Baker R.S., Walker E., Ogan A., Madaio M., Culture in computer-based learning systems: Challenges and opportunities, Computer-Based Learning in Context, 1, 1, pp. 1-13, (2019); 
Baker R.S., Berning A., Gowda S.M., Differentiating military-connected and non-military-connected students: Predictors of graduation and SAT score., (2020); 
Bakken D.E., Rarameswaran R., Blough D.M., Franz A.A., Palmer T.J., Data obfuscation: Anonymity and desensitization of usable data sets, IEEE Security & Privacy, 2, 6, pp. 34-41, (2004); 
Barocas S., Hardt M., Narayanan A., Fairness and Machine Learning. Fairmlbook.org., (2019); 
Bellamy R.K.E., Dey K., Hind M., Hoffman S.C., Houde S., Kannan K., Lohia P., Martino J., Mehta S., Mojsilovic A., Nagar S., Ramamurthy K.N., Richards J., Saha D., Sattigeri P., Singh M., Varshney K.R., Zhang Y., AI fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias, IBM Journal of Research and Development, 63, 4-5, pp. 4:1-4:15, (2019); 
Benitez K., Malin B., Evaluating re-identification risks with respect to the HIPAA privacy rule, Journal of the American Medical Informatics Association, 17, 2, pp. 169-177, (2010); 
Benner K., Thrush G., Isaac M., Facebook Engages in Housing Discrimination With Its Ad Practices, U.S., (2019); 
Benzeghiba M., De Mori R., Deroo O., Dupont S., Erbes T., Jouvet D., Fissore L., Laface P., Mertins A., Ris C., Rose R., Tyagi V., Wellekens C., Automatic speech recognition and speech variability: A review, Speech Communication, 49, 10, pp. 763-786, (2007); 
Berk R., Heidari H., Jabbari S., Kearns M., Roth A., Fairness in criminal justice risk assessments: The state of the art, Sociological Methods & Research, 50, 1, pp. 3-44, (2018); 
Bird S., Dale R., Dorr B.J., Gibson B., Joseph M.T., Kan M.Y., Lee D., Powley B., Radev D.R., Tan Y.F., No Title. Proceedings of the 6Th International Conference on Language Resources and Evaluation, pp. 1755-1759, (2008); 
Bireda M.R., Eliminating racial profiling in school discipline: Cultures in conflict, (2002); 
Blodgett S.L., O'Connor B., Racial disparity in natural language processing: A case study of social media African-American English, (2017); 
Blodgett S.L., Barocas S., Language (Technology) is Power: A Critical Survey of “Bias” in NLP, . Proceedings of the 58Th Annual Meeting of the Association for Computational Linguistics, pp. 5454-5476, (2020); 
Bridgeman B., Trapani C., Attali Y., Considering fairness and validity in evaluating automated scoring [Paper presentation], Annual Meeting of the National Council on Measurement in Education, (2009); 
Bridgeman B., Trapani C., Attali Y., Comparison of human and machine scoring of essays: Differences by gender, ethnicity, and country, Applied Measurement in Education, 25, 1, pp. 27-40, (2012); 
Cabrera A.A., Epperson W., Hohman F., Kahng M., Morgenstern J., Chau D.H., FAIRVIS: Visual analytics for discovering intersectional Bias in machine learning, IEEE Conference on Visual Analytics Science and Technology (VAST), 2019, pp. 46-56, (2019); 
Caton S., Haas C., Fairness in machine learning: A survey., (2020); 
Why am I always being researched? A guidebook for community organizations, researchers, and funders to help us get from insufficient understanding to more authentic truth. Chicago Beyond, ] Chicago Beyond, (2019); 
Chouldechova A., Fair prediction with disparate impact: A study of Bias in recidivism prediction instruments, Big Data, 5, 2, pp. 153-163, (2017); 
Christie S.T., Jarratt D.C., Olson L.A., Taijala T.T., Machine-learned school dropout early warning at scale, Proceedings of the 12Th International Conference on Educational Data Mining (EDM 2019), pp. 726-731, (2019); 
Ciociola A.A., Cohen L.B., Kulkarni P., How drugs are developed and approved by the FDA: Current process and future directions, The American Journal of Gastroenterology, 109, 5, pp. 620-623, (2014); 
Cole N.S., Zieky M.J., The new faces of fairness, Journal of Educational Measurement, 38, 4, pp. 369-382, (2001); 
Cramer H., Holstein K., Vaughan J.W., Daume H., Dudik M., Wallach H., Reddy S., Jean G.-G., [The Conference on Fairness, Accountability, and Transparency (FAT*)]. (2019). FAT* 2019 Translation Tutorial: Challenges of Incorporating Algorithmic Fairness [Video]. Youtube.; 
Crawford K., [The Artificial Intelligence Channel]., 2017, (2017); 
Crenshaw K., Mapping the margins: Intersectionality, identity politics, and violence against women of color, Stanford Law Review, 43, 6, pp. 1241-1300, (1991); 
Darlington R.B., Another look at “cultural fairness, Journal of Educational Measurement, 8, 2, pp. 71-82, (1971); 
Dieterle E., Dede C., Walker M.; 
D'ignazio C., Klein L.F., Data feminism, (2020); 
Doran D., Schulz S., Besold T.R., What Does Explainable AI Really Mean? A New Conceptualization of Perspectives, CEUR Workshop Proceedings, 2071., (2018); 
Dorans N.J., Misrepresentations in unfair treatment by Santelices and Wilson, Harvard Educational Review, 80, 3, pp. 404-413, (2010); 
Doroudi S., Brunskill E., Fairer but not fair enough on the equitability of knowledge tracing, Proceedings of the 9Th International Conference on Learning Analytics & Knowledge, pp. 335-339, (2019); 
Dwork C., Hardt M., Pitassi T., Reingold O., Zemel R., Fairness through awareness, Proceedings of the 3Rd Innovations in Theoretical Computer Science Conference, pp. 214-226, (2012); 
Ferrero F., Gewerc Barujel A., Algorithmic driven decision-making Systems in Education: Analyzing Bias from the sociocultural perspective, 2019 XIV Latin American Conference on Learning Technologies (LACLO), pp. 166-173, (2019); 
Finkelstein S., Yarzebinski E., Vaughn C., Ogan A., Cassell J., The effects of culturally congruent educational technologies on student achievement, Proceedings of the 16Th International Conference on Artificial Intelligence in Education, pp. 493-502, (2013); 
Friedman B., Nissenbaum H., Bias in computer systems, ACM Transactions on Information Systems, 14, 3, pp. 330-347, (1996); 
Garcia M., Racist in the Machine: The Disturbing Implications of Algorithmic Bias, World Policy Journal, 33, 4, pp. 111-117, (2016); 
Gardner J., Brooks C., Andres J.M., Baker R.S., MORF: A framework for predictive modeling and replication at scale with privacy-restricted MOOC data, . 2018 IEEE International Conference on Big Data (Big Data, pp. 3235-3244, (2018); 
Gardner J., Brooks C., Baker R., Evaluating the Fairness of Predictive Student Models Through Slicing Analysis, Proceedings of the 9Th International Conference on Learning Analytics & Knowledge, pp. 225-234, (2019); 
Gebru T., Morgenstern J., Vecchione B., Wortman Vaughan J., Wallach H., Daume Hal I.I.I., Crawford K., Datasheets for Datasets, (2018); 
Green B., The false promise of risk assessments: Epistemic reform and the limits of fairness, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 594-606, (2020); 
Green B., Hu L., (2018); 
Green B., Viljoen S., Algorithmic realism: Expanding the boundaries of algorithmic thought, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 19-31, (2020); 
Guo A., Kamar E., Vaughan J.W., Wallach H., Morris M.R., Toward fairness in AI for people with disabilities: A research roadmap., (2019); 
Hajian S., Bonchi F., Castillo C., Algorithmic Bias: From Discrimination Discovery to Fairness-Aware Data Mining, Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 2125-2126, (2016); 
Halevy A., Norvig P., Pereira F., The unreasonable effectiveness of data, IEEE Intelligent Systems, 24, 2, pp. 8-12, (2009); 
Hanna A., Denton E., Smart A., Smith-Loud J., Towards a critical race methodology in algorithmic fairness, In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 501-512, (2020); 
Hardt M., Price E., Srebro N., Equality of Opportunity in Supervised Learning, Proceedings of the 30Th International Conference on Neural Information Processing Systems, pp. 3323-3331, (2016); 
Hellstrom T., Dignum V., Bensch S., Bias in Machine Learning -- What is it Good for?, Proceedings of the First International Workshop on New Foundations for Human-Centered AI, pp. 3-10, (2020); 
Holstein K., Doroudi S.; 
Holstein K., Wortman Vaughan J., Daume H., Dudik M., Wallach H., Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?, Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, pp. 1-16, (2019); 
Howley I., If an algorithm is openly accessible, and no one can understand it, is it actually open?, Artificial Intelligence in Education Workshop on Ethics in AIED, (2018); 
Hu Q., Rangwala H., Towards Fair Educational Data Mining: A Case Study on Detecting At-risk Students, Proceedings of the 13Th International Conference on Educational Data Mining (EDM 2020), pp. 431-437, (2020); 
Hunter J.E., Schmidt F.L., Critical analysis of the statistical and ethical implications of various definitions of test bias, Psychological Bulletin, 83, 6, pp. 1053-1071, (1976); 
Hutchinson B., Mitchell M., 50 years of test (Un)fairness: Lessons for machine learning, Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 49-58, (2019); 
James R., Bexley E., Anderson M., Devlin M., Garnett R., Marginson S., Maxwell L., Participation and equity: A review of the participation in higher education of people from low socioeconomic backgrounds and Indigenous people., (2008); 
Jiang J., Wang R., Wang M., Gao K., Nguyen D.D., Wei G.-W., Boosting tree-assisted multitask deep learning for small scientific datasets, Journal of Chemical Information and Modeling, 60, 3, pp. 1235-1244, (2020); 
Johns J., Woolf B., A Dynamic Mixture Model to Detect Student Motivation and Proficiency, Proceedings of the 21St National Conference on Artificial Intelligence, 1, pp. 163-168, (2006); 
Kai S., Andres J.M.L., Paquette L., Baker R.S., Molnar K., Watkins H., Moore M., Predicting Student Retention from Behavior in an Online Orientation Course, Proceedings of the 10Th International Conference on Educational Data Mining, pp. 250-255, (2017); 
Kaser Jacober T., Modeling and Optimizing Computer-Assisted Mathematics Learning in Children [Doctoral dissetation, ETH Zurich], ETH Library., (2014); 
Kay M., Matuszek C., Munson S.A., Unequal Representation and Gender Stereotypes in Image Search Results for Occupations, In Proceedings of the 33Rd Annual ACM Conference on Human Factors in Computing Systems, pp. 3819-3828, (2015); 
Kizilcec R.F., Brooks C., Diverse big data and randomized field experiments in MOOCs, Handbook of Learning Analytics, pp. 211-222, (2017); 
Kizilcec R.F., Lee H., Algorithmic Fairness in Education, Algorithmic Fairness in Education, (2021); 
Klare B.F., Burge M.J., Klontz J.C., Bruegge R.W.V., Jain A.K., Face recognition performance: Role of demographic information, IEEE Transactions on Information Forensics and Security, 7, 6, pp. 1789-1801, (2012); 
Kleinberg J., Mullainathan S., Raghavan M., Inherent trade-offs in the fair determination of risk scores, .), Proceedings of the 8Th Innovations in Theoretical Computer Science Conference (ITCS 2017, 67, pp. 1-43, (2017); 
Klingler S., Wampfler R., Kaser T., Solenthaler B., Gross M., Efficient Feature Embeddings for Student Classification with Variational Auto-Encoders, Proceedings of the 10Th International Conference on Educational Data Mining, pp. 72-79, (2017); 
Knight W., The Apple Card Didn’t “See” Gender—and That’s the Problem, (2019); 
Kraemer H.C., Blasey C., How Many Subjects?, Statistical Power Analysis in Research, (2015); 
Kraiger K., Ford J.K., A meta-analysis of ratee race effects in performance ratings, Journal of Applied Psychology, 70, 1, pp. 56-65, (1985); 
Le Bras R., Swayamdipta S., Bhagavatula C., Zellers R., Peters M., Sabharwal A., Choi Y., Adversarial filters of dataset biases, Proceedings of the 37Th International Conference on Machine Learning, 119, pp. 1078-1088, (2020); 
Lee M.K., Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management, Big Data & Society, 5, 1, (2018); 
Lee H., Kizilcec R.F., Evaluation of fairness trade-offs in predicting student success, (2020); 
Lee M.K., Jain A., Cha H.J., Ojha S., Kusbit D., Procedural Justice in Algorithmic Fairness: Leveraging Transparency and Outcome Control for Fair Algorithmic Mediation. Proceedings of the ACM on Human-Computer Interaction, 3(CSCW), (2019); 
Li X., Song D., Han M., Zhang Y., Kizilcec R.F., On the Limits of Algorithmic Prediction across the Globe, (2021); 
Loukina A., Buzick H., Use of automated scoring in spoken language assessments for test takers with speech impairments, ETS Research Report Series, 2017, 1, pp. 1-10, (2017); 
Loukina A., Madnani N., Zechner K., The many dimensions of algorithmic fairness in educational applications, Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pp. 1-10, (2019); 
Lundberg S.M., Erion G., Chen H., DeGrave A., Prutkin J.M., Nair B., Katz R., Himmelfarb J., Bansal N., Lee S.-I., From local explanations to global understanding with explainable AI for trees, Nature Machine Intelligence, 2, 1, pp. 56-67, (2020); 
Makhlouf K., Zhioua S., Palamidessi C., On the applicability of ML fairness notions, (2020); 
Mayfield E., Madaio M., Prabhumoye S., Gerritsen D., McLaughlin B., Dixon-Roman E., Black A.W., Equity Beyond Bias in Language Technologies for Education, Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pp. 444-460, (2019); 
Mehrabi N., Morstatter F., Saxena N., Lerman K., Galstyan A., A survey on Bias and fairness in machine learning, (2019); 
Melis E., Goguadze G., Libbrecht P., Ullrich C., Culturally adapted mathematics education with ActiveMath, AI & SOCIETY, 24, 3, pp. 251-265, (2009); 
Milliron M.D., Malcolm L., Kil D., Insight and action analytics: Three case studies to consider, Research & Practice in Assessment, 9, pp. 70-89, (2014); 
Mitchell S., Potash E., Barocas S., D'Amour A., Lum K., Algorithmic fairness: Choices, assumptions, and definitions, Annual Review of Statistics and Its Application, 8, (2021); 
Naismith B., Han N.-R., Juffs A., Hill B., Zheng D., Accurate Measurement of Lexical Sophistication with Reference to ESL Learner Data, Proceedings of 11Th International Conference on Educational Data Mining, pp. 259-265, (2018); 
O'Reilly-Shah V.N., Gentry K.R., Walters A.M., Zivot J., Anderson C.T., Tighe P.J., Bias and ethical considerations in machine learning and the automation of perioperative risk assessment, British Journal of Anaesthesia, 125, 6, pp. 843-846, (2020); 
Obermeyer Z., Powers B., Vogeli C., Mullainathan S., Dissecting racial bias in an algorithm used to manage the health of populations, Science, 366, 6464, pp. 447-453, (2019); 
Ocumpaugh J., Baker R., Gowda S., Heffernan N., Heffernan C., Population validity for educational data mining models: A case study in affect detection, British Journal of Educational Technology, 45, 3, pp. 487-501, (2014); 
Ogan A., Walker E., Baker R., Rodrigo M.M.T., Soriano J.C., Castro M.J., Towards understanding how to assess help-seeking behavior across cultures, International Journal of Artificial Intelligence in Education, 25, 2, pp. 229-248, (2015); 
Okur E., Aslan S., Alyuz N., Arslan Esme A., Baker R.S., Role of socio-cultural differences in labeling students’ affective states, Proceedings of the 19Th International Conference on Artificial Intelligence in Education (, pp. 367-380, (2018); 
Olteanu A., Castillo C., Diaz F., Kiciman E., Social data: Biases, methodological pitfalls, and ethical boundaries, Frontiers in Big Data, 2, (2019); 
Paquette L., Ocumpaugh J., Li Z., Andres A., Baker R., Who’s learning? Using demographics in EDM research, Journal of Educational Data Mining, 12, 3, pp. 1-30, (2020); 
Paullada A., Raji I.D., Bender E.M., Denton E., Hanna A., Data and its (Dis)contents: A survey of dataset development and use in machine learning research, (2020); 
Petersen N.S., Novick M.R., An evaluation of some models for culture-fair selection, Journal of Educational Measurement, 13, 1, pp. 3-29, (1976); 
Ramineni C., Williamson D.M., Automated essay scoring: Psychometric guidelines and practices, Assessing Writing, 18, 1, pp. 25-39, (2013); 
Ramineni C., Williamson D., Understanding mean score differences between the e-rater® automated scoring engine and humans for demographically based groups in the GRE® general test, ETS Research Report Series, 2018, 1, pp. 1-31, (2018); 
Rauf D.S., The New, Tough Expectations Education Companies Face on Race and Diversity, Market Brief: Market Trends, (2020); 
Reich J., Rebooting MOOC research, Science, 347, 6217, pp. 34-35, (2015); 
Riazy S., Simbeck K., Schreck V., Fairness in Learning Analytics: Student At-risk Prediction in Virtual Learning Environments, Proceedings of the 12Th International Conference on Computer Supported Education (CSEDU 2020, 1, pp. 15-25, (2020); 
Ritter S., Yudelson M., Fancsali S.E., Berman S.R., How Mastery Learning Works at Scale, Proceedings of the Third (2016) ACM Conference on Learning @ Scale, pp. 71-79, (2016); 
Samei B., Olney A.M., Kelly S., Nystrand M., D'Mello S., Blanchard N., Graesser A., Modeling Classroom Discourse: Do Models That Predict Dialogic Instruction Properties Generalize across Populations?, Proceedings of the 8Th International Conference on Educational Data Mining, pp. 444-447, (2015); 
Santelices M.V., Wilson M., Unfair treatment? The case of Freedle, the SAT, and the standardization approach to differential item functioning, Harvard Educational Review, 80, 1, pp. 106-134, (2010); 
Selent D., Patikorn T., Heffernan N., ASSISTments Dataset from Multiple Randomized Controlled Experiments, Proceedings of the Third (2016) ACM Conference on Learning @ Scale, pp. 181-184, (2016); 
Silva S., Kenney M., Algorithms, platforms, and ethnic Bias: An integrative essay, Phylon (1960-), 55, 12, pp. 9-37, (2018); 
Slater S., Baker R.S., Degree of error in Bayesian knowledge tracing estimates from differences in sample sizes, Behaviormetrika, 45, pp. 475-493, (2018); 
Smith L.T., Decolonizing Methodologies: Research and Indigenous Peoples, Zed Books, (2013); 
Smith H., Algorithmic bias: Should students pay the price?, AI & SOCIETY, 35, 4, pp. 1077-1078, (2020); 
Soomro K., Zamir A.R., Shah M., UCF101: A dataset of 101 human actions classes from videos in the wild, (2012); 
Soundarajan S., Clausen D.L., Equal Protection Under the Algorithm: A Legal-Inspired Framework for Identifying Discrimination in Machine Learning, Proceedings of the 35Th International Conference on Machine Learning, (2018); 
Stamper J., Pardos Z.A., The 2010 KDD cup competition dataset: Engaging the machine learning Community in Predictive Learning Analytics, Journal of Learning Analytics, 3, 2, pp. 312-316, (2016); 
Strmic-Pawl H.V., Jackson B.A., Garner S., Race counts: Racial and ethnic data on the U.S. Census and the implications for tracking inequality, Sociology of Race and Ethnicity, 4, 1, pp. 1-13, (2018); 
Suresh H., Guttag J.V., A framework for understanding unintended consequences of machine learning., (2020); 
Sweeney L., Discrimination in online ad delivery, Communications of the ACM, 56, 5, pp. 44-54, (2013); 
Tatman R., Gender and dialect Bias in YouTube’s automatic captions, Proceedings of the First Workshop on Ethics in Natural Language Processing, pp. 53-59, (2017); 
Telford T., Apple Card algorithm sparks gender bias allegations against Goldman Sachs, (2019); 
Tempelaar D., Rienties B., Nguyen Q., Subjective data, objective data and the role of bias in predictive modelling: Lessons from a dispositional learning analytics application, PLoS One, 15, 6, (2020); 
Tipton E., Stratified sampling using cluster analysis: A sample selection strategy for improved generalizations from experiments, Evaluation Review, 37, 2, pp. 109-139, (2014); 
Verma S., Rubin J., Fairness definitions explained, . Fairware ‘18: Proceedings of the International Workshop on Software Fairness, pp. 1-7, (2018); 
Wang Z., Zechner K., Sun Y., Monitoring the performance of human and automated scores for spoken responses, Language Testing, 35, 1, pp. 101-120, (2018); 
Waters A., Miikkulainen R., GRADE: Machine learning support for graduate admissions, AI Magazine, 35, 1, (2014); 
Wolff A., Zdrahal Z., Nikolov A., Pantucek M., Improving retention: Predicting at-risk students by Analysing clicking behaviour in a virtual learning environment, Proceedings of the Third International Conference on Learning Analytics and Knowledge, pp. 145-149, (2013); 
Woolf B.P., Arroyo I., Muldner K., Burleson W., Cooper D.G., Dolan R., Christopherson R.M., The effect of motivational learning companions on low achieving students and students with disabilities, Proceedings of the 10th international conference on intelligent tutoring systems (ITS’10), pp. 327-337, (2010); 
Wu R., Xu G., Chen E., Liu Q., Ng W., Knowledge or Gaming? Cognitive Modelling Based on Multiple-Attempt Response, Proceedings of the 26Th International Conference on World Wide Web Companion, pp. 321-329, (2017); 
Xia M., Asano Y., Williams J.J., Qu H., Ma X., Using information visualization to promote students’ reflection on “gaming the system” in online learning, Proceedings of the Seventh ACM Conference on Learning @ Scale, pp. 37-49, (2020); 
Yu R., Li Q., Fischer C., Doroudi S., Xu D., Towards Accurate and Fair Prediction of College Success: Evaluating Different Sources of Student Data, Proceedings of the 13Th International Conference on Educational Data Mining (EDM 2020), pp. 292-301, (2020); 
Yu R., Lee H., Kizilcec R.F., Should college dropout prediction models include protected attributes?, Proceedings of the Eighth ACM Conference on Learning@ Scale, pp. 91-100, (2021); 
Yudelson M.V., Fancsali S.E., Ritter S., Berman S.R., Nixon T., Joshi A., Better Data Beat Big Data, Proceedings of the 7Th International Conference on Educational Data Mining, pp. 205-208, (2014); 
Zhou T., Sheng H., Howley I., Assessing post-hoc Explainability of the BKT algorithm, Proceedings of the AAAI/ACM Conference on AI, pp. 407-413, (2020)#FRF#
