#ITI#Detecting publication selection bias through excess statistical significance#FTI#
#IRE# We introduce and evaluate three tests for publication selection bias based on excess statistical significance (ESS). The proposed tests incorporate heterogeneity explicitly in the formulas for expected and ESS. We calculate the expected proportion of statistically significant findings in the absence of selective reporting or publication bias based on each study's SE and meta-analysis estimates of the mean and variance of the true-effect distribution. A simple proportion of statistical significance test (PSST) compares the expected to the observed proportion of statistically significant findings. Alternatively, we propose a direct test of excess statistical significance (TESS). We also combine these two tests of excess statistical significance (TESSPSST). Simulations show that these ESS tests often outperform the conventional Egger test for publication selection bias and the three-parameter selection model (3PSM)#FRE#
#IPC# excess statistical significance; meta-analysis; publication selection bias; statistical power#FPC#
#IRF# Sterne J.A., Sutton A.J., Ioannidis J.P.A., Et al., Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials, BMJ, 343, (2011); 
Doucouliagos H., Paldam M., Stanley T.D., Skating on thin evidence: implications for public policy, Eur J Pol Econ, 54, pp. 16-25, (2018); 
Estimating the reproducibility of psychological science, Science, 349, 6251, (2015); 
Stanley T.D., Limitations of PET-PEESE and other meta-analysis methods, Social Psychol Person Sci, 8, pp. 581-591, (2017); 
Klein R.A., Vianello M., Hasselman F., Et al., Many Labs 2: investigating variation in replicability across sample and setting, Adv Methods Pract Psychol Sci, 1, 4, pp. 443-490, (2018); 
Kvarven A., Stromland E., Johannesson M., Comparing meta-analyses and preregistered multiple-laboratory replication projects, Nat Hum Behav, 4, pp. 423-434, (2019); 
Stanley T.D.; 
Stanley T.D., Meta-regression methods for detecting and estimating empirical effect in the presence of publication bias, Oxford Bull Econ Stat, 70, pp. 103-127, (2008); 
Hedges L.V., Estimation of effect size under nonrandom sampling: the effects of censoring studies yielding statistically insignificant mean differences, J Educ Behav Stat., 9, 1, pp. 61-85, (1984); 
Hedges L.V., Vevea J.L., Estimating effect size under publication bias: small sample properties and robustness of a random effects selection model, J Educ Behav Stat, 21, 4, pp. 299-332, (1996); 
Egger M., Smith G.D., Schneider M., Minder C., Bias in meta-analysis detected by a simple, graphical test, Br Med J, 315, pp. 629-634, (1997); 
Stanley T.D., Beyond publication bias, J Econ Surv, 19, pp. 309-347, (2005); 
Ioannidis J.P.A., Trikalinos T.A., An exploratory test for an excess of significant findings, Clin Trials, 4, pp. 245-253, (2007); 
Iyengar S., Greenhouse J.B., Selection models and the file drawer problem, Stat Sci, 3, pp. 109-117, (1988); 
McShane B.B., Bockenholt U., Hansen K.T., Adjusting for publication bias in meta-analysis an evaluation of selection methods and some cautionary notes, Perspect Psychol Sci., 11, 5, pp. 730-749, (2016); 
Carter E.C., Schonbrodt F.D., Gervais W.M., Hilgard J., Correcting for bias in psychology: a comparison of meta-analytic methods, Adv Methods Pract Psychol Sci, 2, 2, pp. 115-144, (2019); 
Pustejovsky J.E., Rodgers M.A., Testing for funnel plot asymmetry of standardized mean differences, Res Synth Methods, 10, pp. 57-71, (2019); 
Moreno S.G., Sutton A.J., Ades A.E., Et al., Assessment of regression-based methods to adjust for publication bias through a comprehensive simulation study, BMC Med Res Methodol, 9, (2009); 
Ioannidis J.P.A., Stanley T.D., Doucouliagos C., The power of bias in economics research, Econ J, 127, pp. F236-F265, (2017); 
Stanley T.D., Carter E.C., Doucouliagos H., What meta-analyses reveal about the replicability of psychological research, Psychol Bull, 144, pp. 1325-1346, (2018); 
Cohen J., Statistical Power Analysis for the Behavioral Sciences, (1988); 
Fraley R.C., Vazire S., The n-pact factor: evaluating the quality of empirical journals with respect to sample size and statistical power, PLoS One, 9, (2014); 
Cohen J., The statistical power of abnormal-social psychological research: a review, J Abnorm Soc Psychol, 65, pp. 145-153, (1962); 
Sedlmeier P., Gigerenzer G., Do studies of statistical power have an effect on the power of studies?, Psychol Bull, 105, pp. 309-316, (1989); 
Rossi J., Statistical power of psychological research: what have we gained in 20 years?, J Consult Clin Psychol, 58, pp. 646-656, (1990); 
Maxwell S.E., The persistence of underpowered studies in psychological research: causes, consequences, and remedies, Psychol Methods, 9, 147, pp. 147-163, (2004); 
Vankov I., Bowers J., Munafo M.R., On the persistence of low power in psychological science, Q J Exp Psychol (Hove), 67, pp. 1037-1040, (2014); 
Tressoldi P.E., Giofre D., The pervasive avoidance of prospective statistical power: major consequences and practical solutions, Front Psychol, 6, (2015); 
Bakker M., Veldkamp C.L.S., van den Akker O.R., Et al., Recommendations in pre-registrations and internal review board proposals promote formal power analyses but do not increase sample size, PLoS ONE, 15, 7, (2020); 
Stanley T.D., Doucouliagos H., Neither fixed nor random: weighted least squares meta-analysis, Stat Med, 34, pp. 2116-2127, (2015); 
Stanley T.D., Doucouliagos H., Jpa I., Finding the power to reduce publication bias, Stat Med, 36, pp. 1580-1598, (2017); 
Ioannidis J.P.A., Clarifications on the application and interpretation of the test for excess significance and its extensions, J Math Psychol, 57, 5, pp. 184-187, (2013); 
Stanley T.D., Doucouliagos H., Neither fixed nor random: weighted least squares meta-regression analysis, Res Synth Methods, 8, pp. 19-42, (2017); 
Carter E.C., Kofler L.E., Forster D.F., McCullough M.E., A series of meta-analytic tests of the depletion effect: self-control does not seem to rely on a limited resource, J Exp Psychol Gen, 144, pp. 796-815, (2015); 
DerSimonian R., Laird N., Meta-analysis in clinical trials, Control Clin Trials, 7, pp. 177-188, (1986); 
Augusteijn H.E.M., van Aert R.C.M., van Assen M.A.L.M., The effect of publication bias on the Q test and assessment of heterogeneity, Psychol Methods, 24, 1, pp. 116-134, (2019); 
Cohen J., Things I learned (so far), Am Psychol, 45, pp. 1304-1312, (1990); 
Serlin R.A., Lapsley D.K., Rational appraisal of psychological research and the good-enough principle, A Handbook for Data Analysis in the Behavioral Sciences: Methodological Issues, (1993); 
Schneck A., Examining publication bias: a simulation-based evaluation of statistical tests on publication bias, PeerJ, 5, (2017); 
Wooldridge J.M., Econometric Analysis of Cross Section and Panel Data, (2002); 
Stanley T.D., Doucouliagos H., Meta-regression approximations to reduce publication selection bias, Res Synth Methods, 5, pp. 60-78, (2014); 
Johnson N., Kotz S., Distributions in Statistics: Continuous Univariate Distribution, (1970); 
Greene W.E., Econometric Analysis, (1990); 
Stanley T.D., Doucouliagos H., Meta-Regression Analysis in Economics and Business, (2012); 
Coburn K.M., Vevea J.L., Publication bias as a function of study characteristics, Psychol Methods, 20, 3, pp. 310-330, (2015); 
Engber D.; 
Bem D.J.,  Annual Convention; August 2–4, 2003; Vancouver, Canada; 
Bem D.J., Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect, J Pers Soc Psychol, 100, pp. 407-425, (2011); 
Bem D.J., Tressoldi P., Rabeyron T., Duggan M., Feeling the future: a meta-analysis of 90 experiments on the anomalous anticipation of random future events, F1000 Res, 4, (2016); 
Galak J., Leboeuf R.A., Nelson L.D., Simmons J.P., Correcting the past: failures to replicate, J Pers Soc Psychol, 103, 6, pp. 933-948, (2012); 
Hagger M.S., Chatzisarantis N.L.D., Alberts H., Et al., A multi-lab preregistered replication of the ego-depletion effect, Perspect Psychol Sci, 11, pp. 546-573, (2016); 
Witte E.H., Zenker F., Extending a multilab preregistered replication of the ego-depletion effect to a research program, Basic Appl Soc Psychol, 39, pp. 74-80, (2017); 
Camerer C.F., Dreber A., Holzmeister F., Et al., Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015, Nat Hum Behav, 2, 9, pp. 637-644, (2018); 
Klein R.A., Ratliff K.A., Vianello M., Et al., Investigating variation in replicability: a “Many Labs” replication project, Soc Psychol, 45, pp. 142-152, (2014); 
Turner E.H., Matthews A.M., Linardatos E., Tell R.A., Rosenthal R., Selective publication of antidepressant trials and its influence on apparent efficacy, N Engl J Med, 358, pp. 252-260, (2008); 
Rhodes K.M., Turner R.M., Higgins J.P.T., Predictive distributions were developed for the extent of heterogeneity in meta-analyses of continuous outcome data, J Clin Epidemiol, 68, pp. 52-60, (2015); 
Jeffreys H., Theory of Probability, (1939); 
Amad A., Jardri R., Rousseau C., Larochelle Y., Ioannidis J.P.A., Naudet F., Excess significance bias in repetitive transcranial magnetic stimulation literature for neuropsychiatric disorders, Psychother Psychosom, 88, 6, pp. 363-370, (2019); 
Ioannidis J.P.A., Excess significance bias in the literature on brain volume abnormalities, Arch Gen Psychiatry, 68, 8, pp. 773-780, (2011); 
Trinquart L., Ioannidis J.P., Chatellier G., Ravaud P., A test for reporting bias in trial networks: simulation and case studies, BMC Med Res Methodol, 14, (2014); 
Sterne J.A., Egger M., Smith G.D., Systematic reviews in healthcare: investigating and dealing with publication and other biases in meta-analysis, BMJ, 23, pp. 101-105, (2001); 
Borenstein M., Hedges L.V., Higgins J., Rothstein H., Introduction to Meta-Analysis, (2009)#FRF#
