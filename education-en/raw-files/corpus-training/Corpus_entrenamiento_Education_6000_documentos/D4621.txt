#ITI#Combining Self-Reported and Observational Measures to Assess University Student Academic Performance in Blended Course Designs#FTI#
#IRE#This study combined the methods from student approaches to learning and learning analytics research by using both self-reported and observational measures to examine the student learning experience. It investigated the extent to which reported approaches and perceptions and observed online interactions are related to each other and how they contribute to variation in academic performance in a blended course design. Correlation analyses showed significant pairwise associations between approaches and frequency of the online interaction. A cluster analysis identified two groupings of students with different reported learning orientations. Based on the reported learning orientations, one-way ANOVAs showed that students with understanding orientation reported deep approaches to and positive perceptions of learning. The students with understanding orientation also interacted more frequently with the online learning tasks and had higher marks than those with reproducing orientation, who reported surface approaches and negative perceptions. Regression analyses found that adding the observational measures increased 36% of the variance in the academic performance in comparison with using self-reported measures alone (6%). The findings suggest using the combined methods to explain studentsâ€™ academic performance in blended course designs not only triangulates the results but also strengthens the acuity of the analysis#FRE#
#IPC#academic performance; blended course designs; learning analytics research; observational measures; self-reported measures; student approaches to learning research#FPC#
#IRF#Baker R., Siemens G., Educational data mining and learning analytics, The Cambridge handbook of the learning sciences, pp. 253-272, (2014); 
Bettinger E., Baker R., The effects of student coaching: An evaluation of a randomized experiment in student advising, Educational Evaluation and Policy Analysis, 36, 1, pp. 3-19, (2013); 
Biggs J., Tang C., Teaching for quality learning at university: What the student does, (2011); 
Bliuc A.-M., Goodyear P., Ellis R. A., Research focus and methodological choices in studies into students' experiences of blended learning in higher education, The Internet and Higher Education, 10, 4, pp. 231-244, (2007); 
Boyd D., Crawford K., Critical questions for big data, Information, Communication & Society, 15, 5, pp. 662-679, (2012); 
Buckingham Shum S., Crick R., Learning dispositions and transferable competencies: Pedagogy, modelling and learning analytics, Proceedings of the 2nd International Conference on Learning Analytics and Knowledge, pp. 92-101, (2012); 
Cohen J., Statistical power analysis for the behavioural sciences, (1988); 
Dawson S., Jovanovic J., Gasevic D., Pardo A., From prediction to impact: Evaluation of a learning analytics retention program, Proceedings of the International Conference on Learning Analytics and Knowledge, pp. 474-478, (2017); 
Ellis R., Bliuc A.-M., An exploration into first-year university students' approaches to inquiry and online learning technologies in blended environments, British Journal of Educational Technology, 47, 5, pp. 970-980, (2016); 
Ellis R., Han F., Pardo A., Improving learning analytics: Combining observational and self-report data on student learning, Educational Technology & Society, 20, 3, pp. 158-169, (2017); 
Entwistle N., Teaching for understanding at university: Deep approaches and distinctive ways of thinking, (2009); 
Ferguson R., Brasher A., Clow D., Cooper A., Hillaire G., Mittlemeier J., Rienties B., Ullmann T., Vuorikari R., Research evidence on the use of learning analytics: Implications for education policy, (2016); 
Han F., Ellis R., Variations in coherence and engagement in students' experience of blended learning, Proceedings of 34th International Conference on Innovation, Practice and Research in the Use of Educational Technologies in Tertiary Education, pp. 268-275, (2017); 
Han F., Ellis R., Initial development and validation of the Perceptions of the Blended Learning Environment Questionnaire, Journal of Psychoeducational Assessment, 38, 2, pp. 168-181, (2020); 
Han F., Ellis R., Personalised learning networks in the university blended learning context, Comunicar, 62, 1, pp. 19-30, (2020); 
Han F., Pardo A., Ellis R., Students' self-report and observed learning orientations in blended university course design: How are they related to each other and to academic performance?, Journal of Computer Assisted Learning, 36, 6, pp. 969-980, (2020); 
Iskander M., Kapila V., Karim M., Technological developments in education and automation, (2010); 
Jovanovic J., Gasevic D., Pardo A., Dawson S., Mirriahi N., Learning analytics to unveil learning strategies in a flipped classroom, The Internet and Higher Education, 23, pp. 74-85, (2017); 
Kaendler C., Wiedmann M., Rummel N., Spada H., Teacher competencies for the implementation of collaborative learning in the classroom: A framework and research review, Educational Psychology Review, 27, 3, pp. 505-536, (2015); 
Krumm A., Waddington R., Teasley S., Lonn S., A learning management system-based early warning system for academic advising in undergraduate engineering, Learning analytics: From research to practice, pp. 103-119, (2014); 
Kurvinen E., Kaila E., Laakso M., Salakoski T., Long term effects on technology enhanced learning: The use of weekly digital lessons in mathematics, Informatics in Education, 19, 1, pp. 51-75, (2020); 
Lizzio A., Wilson K., Simons R., University students' perceptions of the learning environment and academic outcomes: Implications for theory and practice, Studies in Higher Education, 27, pp. 27-52, (2002); 
Lockyer L., Heathcote E., Dawson S., Informing pedagogical action: Aligning learning analytics with learning design, American Behavioral Scientist, 57, 10, pp. 1439-1459, (2013); 
Long P., Siemens G., Penetrating the fog: Analytics in learning and education, EDUCAUSE Review, 46, 5, pp. 31-40, (2011); 
Marton F., Necessary conditions of learning, (2014); 
Mestan K., Create a fine blend: An examination of institutional transition to blended learning, Australasian Journal of Educational Technology, 35, 1, pp. 70-84, (2019); 
Mirriahi N., Jovanovic J., Dawson S., Gasevic D., Pardo A., Identifying engagement patterns with video annotation activities: A case study in professional development, Australasian Journal of Educational Technology, 34, 1, pp. 57-72, (2018); 
Nelson Laird T., Seifert T., Pascarella E., Mayhew M., Blaich C., Deeply affecting first-year students' thinking: Deep approaches to learning and three dimensions of cognitive development, Journal of Higher Education, 85, 3, pp. 402-432, (2014); 
Ocumpaugh J., Baker R., Gowda S., Heffernan N., Heffernan C., Population validity for Educational Data Mining models: A case study in affect detection, British Journal of Educational Technology, 45, 3, pp. 487-501, (2014); 
Ozudogru M., Aksu M., Pre-service teachers' achievement and perceptions of the classroom environment in flipped learning and traditional instruction classes, Australasian Journal of Educational Technology, 36, 4, pp. 27-43, (2020); 
Pardo A., Han F., Ellis R. A., Exploring the relation between self-regulation, online activities, and academic performance: A case study, Proceedings of the Sixth International Conference on Learning Analytics & Knowledge, pp. 422-429, (2016); 
Pardo A., Han F., Ellis R. A., Combining university student self-regulated learning indicators and engagement with online learning events to predict academic performance, IEEE Transactions on Learning Technologies, 10, 1, pp. 82-92, (2017); 
Rienties B., Toetenel L., The impact of learning design on student behaviour, satisfaction and performance: A cross-institutional comparison across 151 modules, Computers in Human Behavior, 60, pp. 333-341, (2016); 
Siemens G., Gasevic D., Learning and knowledge analytics [Editorial], Educational Technology & Society, 15, 3, pp. 1-2, (2012); 
Sonnenberg C., Bannert M., Using process mining to examine the sustainability of instructional support: How stable are the effects of metacognitive prompting on self-regulatory behavior?, Computers in Human Behavior, 96, pp. 259-272, (2019); 
Tanes Z., Arnold K., King A., Remnet M., Using signals for appropriate feedback: Perceptions and practices, Computers & Education, 57, 4, pp. 2414-2422, (2011); 
Tempelaar D., Rienties B., Giesbers B., In search for the most informative data for feedback generation: Learning analytics in a data-rich context, Computers in Human Behavior, 47, pp. 157-167, (2015); 
Trigwell K., Ellis R., Han F., Relations between students' approaches to learning, experienced emotions and outcomes of learning, Studies in Higher Education, 37, 7, pp. 811-824, (2012); 
Trigwell K., Prosser M., Exploring university teaching and learning: Experience and context, (2020); 
Wilson K., Lizzio A., Ramsden P., The development, validation and application of the Course Experience Questionnaire, Studies in Higher Education, 22, 1, pp. 33-53, (1997); 
Winne P., Nesbit J., Popowich F., nStudy: A system for researching information problem solving, Technology, Knowledge and Learning, 22, 3, pp. 369-376, (2017)#FRF#
