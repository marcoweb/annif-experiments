#ITI#The Sensitivity of a Scenario-Based Assessment of Written Argumentation to School Differences in Curriculum and Instruction#FTI#
#IRE# Educators need actionable information about student progress during the school year. This paper explores an approach to this problem in the writing domain that combines three measurement approaches intended for use in interim-assessment fashion: scenario-based assessments (SBAs), to simulate authentic classroom tasks, automated writing evaluation (AWE) features to track changes in performance and writing process traits derived from a keystroke log. Our primary goal is to determine if SBAs designed to measure English Language Arts skills, supplemented by richer measurement of the writing task, function well as interim assessments that are sensitive to differences in performance related to differences in quality of instruction. We calibrated these measures psychometrically using data from a prior study and then applied them to evaluate changes in performance in one suburban and two urban middle schools that taught argument writing. Of the three schools, only School A (the suburban school, with the strongest overall performance) showed significant score increases on an essay task, accompanied by distinctive patterns of improvement. A general, unconditioned growth pattern was also evident. These results demonstrate an approach that can provide richer, more actionable information about student status and changes in student performance over the course of the school year#FRE#
#IPC# AES; Argumentation; Assessment; Automated essay scoring; Automated writing evaluation; AWE; Formative assessment; Interim assessment; Keystroke log; Natural language processing; NLP; SBA; Scenario-based assessment; Writing; Writing process#FPC#
#IRF# Almond R., Deane P., Quinlan T., Wagner M., Sydorenko T., A preliminary analysis of keystroke log data from a timed writing task (ETS RR-12-23), ETS Research Report Series, 2012, 2, pp. I-61, (2012); 
Attali Y., Burstein J., Automated essay scoring with e-rater® V. 2, Journal of Technology, Learning and Assessment, 4, 3, (2006); 
Attali Y., Powers D., Validity of scores for a developmental writing scale based on automated scoring, Educational and Psychological Measurement, 69, 6, pp. 978-993, (2009); 
Au W., High-stakes testing and curricular control: A qualitative metasynthesis, Educational Researcher, 36, 5, pp. 258-267, (2007); 
Beigman Klebanov B., Flor M., Associative texture is lost in translation, Proceedings of the Workshop on Discourse in Machine Translation (Discomt), pp. 27-32, (2013); 
Bennett R.E., Cognitively based assessment of, for, and as learning (CBAL): A preliminary theory of action for summative and formative assessment, Measurement: Interdisciplinary Research and Perspectives, 8, 2-3, pp. 70-91, (2010); 
Bennett R.E., CBAL: Results from piloting innovative K–12 assessments (ETS RR-11-23), ETS Research Report Series, 2011, 1, pp. i-39, (2011); 
Bennett R.E., Deane P., van Rijn P.W., From cognitive-domain theory to assessment practice, Educational Psychologist, 51, 1, pp. 1-26, (2016); 
Bennett R.E., Gitomer D.H., Transforming K-12 assessment: Integrating accountability testing, formative assessment, and professional support, Educational assessment in the 21st century, pp. 43-61, (2009); 
Biber D., Spoken and written textual dimension in English: Resolving the contradictory findings, Language, 62, pp. 394-414, (1986); 
Biber D., Variation across speech and writing, (1988); 
Biber D., Conrad S., Reppen R., Byrd P., Helt M., Clark V., Urzua A., Representing language use in the university: Analysis of the TOEFL 2000 Spoken and Written Academic Language Corpus, TOEFL Monograph Series, (2004); 
Black P., Wiliam D., Assessment and classroom learning, Assessment in Education: Principles, Policy & Practice, 5, 1, pp. 7-74, (1998); 
Burstein J., Marcu D., Knight K., Finding the WRITE stuff: Automatic identification of discourse structure in student essays, IEEE Intelligent Systems, 18, 1, pp. 32-39, (2003); 
Burstein J., Tetreault J., Madnani N., The e-rater automated essay scoring system, Handbook of automated essay evaluation: Current applications and new directions, pp. 55-67, (2013); 
Cauley K.M., McMillan J.H., Formative assessment techniques to support student motivation and achievement, The clearing house: A journal of educational strategies, issues and ideas, 83, 1, pp. 1-6, (2010); 
Chodorow M., Gamon M., Tetreault J., The utility of article and preposition error correction systems for English language learners: Feedback and assessment, Language Testing, 27, 3, pp. 419-436, (2010); 
Chodorow M., Tetreault J., Han N.-R., Detection of grammatical errors involving prepositions, Paper Presented at the Proceedings of the Fourth ACL-SIGSEM Workshop on Prepositions, (2007); 
Corbin J., Strauss A., Strategies for qualitative data analysis, In Basics of Qualitative Research, (2008); 
Coxhead A., A nonparametric method for extraction of candidate phrasal terms, Proceedings of the 43Rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pp. 605-613, (2000); 
Deane P., A nonparametric method for extraction of candidate phrasal terms, Proceedings of the 43Rd Annual Meeting of the Association for Computational Linguistics (ACL’05, pp. 605-613, (2005); 
Deane P., Sheehan K.M., Sabatini J., Futagi Y., Kostin I., Differences in text structure and its implications for assessment of struggling readers, Scientific Studies of Reading, 10, 3, pp. 257-275, (2006); 
Deane P., Writing assessment and cognition (ETS RR-11-14), ETS Research Report Series, 2011, 1, pp. i-60, (2011); 
Deane P., Covering the construct: An approach to automated essay scoring motivated by a socio-cognitive framework for defining literacy skills, Handbook of automated essay evaluation: Current applications and new directions, pp. 298-312, (2013); 
Deane P., Vocabulary features for E-rater, (2014); 
Deane P., Using writing process and product features to assess writing quality and explore how those features relate to other literacy tasks (ETS RR-14-03), ETS Research Report Series, 2014, 1, pp. 1-23, (2014); 
Deane P., Andreyev S., Wong V., Recommendation for adding a sentence variety/ sentence style feature to e-rater, (2011); 
Deane P., Fowles M., Baldwin D., Persky H., The CBAL Summative Writing Assessment: A Draft Eighth-Grade Design (ETS RM-11-01), (2011); 
Deane P., Quinlan T., What automated analyses of corpora can tell us about students' writing skills, Journal of Writing Research, 2, 2, pp. 152-177, (2010); 
Deane P., Quinlan T., Kostin I., Automated scoring within a developmental, cognitive model of writing proficiency (RR-11-16), ETS Research Report Series, 2011, 1, pp. i-93, (2011); 
Deane P., Roth A., Litz A., Goswami V., Steck F., Lewis M., Richter T., Behavioral differences between retyping, drafting, and editing: A writing process analysis (ETS RM-18-06), (2018); 
Deane P., Song Y., A case study in principled assessment design: Designing assessments to measure and support the development of argumentative reading and writing skills, Educativa Psicologia, 20, 2, pp. 99-108, (2014); 
Deane P., Song Y., van Rijn P.W., O'Reilly T., Fowles M., Bennett R., Et al., The case for scenario-based assessment of written argumentation, Reading and Writing, 32, pp. 1575-1606, (2018); 
Deane P., Williams F., Weng V., Trapani C.S., Automated essay scoring in innovative assessments of writing from sources, The Journal of Writing Assessment, 6, 1, pp. 40-56, (2013); 
Deane P., Zhang M., Exploring the feasibility of using writing process features to assess text production skills (ETS RR-15-26), ETS Research Report Series, 2015, 2, pp. 1-16, (2015); 
Deane P., Bennett R.E., Rijn P., Guo H., Zhang M., Li C., Defining a Multidimensional Model for Characterizing Performance on a Scenario-Based Assessment of Argument Reading and Writing, (2019); 
Flor M., Beigman Klebanov B., Associative lexical cohesion as a factor in text complexity, International Journal of Applied Linguistics, 165, 2, (2014); 
Flor M., Beigman Klebanov B., Sheehan K., Lexical tightness and text complexity, Proceedings of the 2Nd Work Shop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pp. 29-38, (2013); 
Fu J., Chung S., Wise M., Dimensionality analyses of CBAL writing tests. (ETS RR-13-10), 2013, 1, pp. i-33, (2013); 
Fu J., Wise M., Statistical report of 2011 CBAL multistate administration of reading and writing tests (ETS RR-12-24), ETS Research Report Series, 2012, 2, pp. i-59, (2012); 
Futagi Y., Deane P., Chodorow M., Tetreault J., A computational approach to detecting collocation errors in the writing of non-native speakers of English, Computer Assisted Language Learning, 21, 4, pp. 353-367, (2008); 
Graesser A.C., McNamara D.S., Kulikowich J.M., Coh-Metrix: Providing multilevel analyses of text characteristics, Educational Researcher, 40, 5, pp. 223-234, (2011); 
Graff D., Cieri C., English Gigaword. LDC2003T05, (2003); 
Haberman S.J., A general program for item-response analysis that employs the stabilized Newton-Raphson algorithm (ETS RR-13-32), ETS Research Report Series, 2013, 2, pp. i-98, (2013); 
Hanushak E.A., Peterson P.E., Talpey L.M., Woessman L., The unwavering SES achievement gap: Trends in US student performance, (2019); 
Hardin J.W., Hilbe J.M., Generalized estimating equations, (2003); 
Heilman M., Cahill A., Madnani N., Lopez M., Mulholland M., Predicting grammaticality on an ordinal scale, Proceedings of the 52Nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pp. 174-180, (2014); 
Leacock C., Chodorow M., Automatic assessment of vocabulary usage without negative evidence, ETS Research Report Series, 2001, 2, (2001); 
Lin D., Automatic retrieval and clustering of similar words, Proceedings of the 17Th International Conference on Computational Linguistics, 2, pp. 768-774, (1998); 
Lipsitz S., Fitzmaurice G., Generalized estimation equations for longitudinal data analysis, pp. 43-78, (2008); 
Marcu D., The theory and practice of discourse parsing and summarization, (2000); 
McNamara D.S., Graesser A.C., Coh-Metrix: An automated tool for theoretical and applied natural language processing, Applied natural language processing: Identification, investigation and resolution, pp. 188-205, (2012); 
Michel J.B., Shen Y.K., Aiden A.P., Veres A., Gray M.K., Pickett J.P., Hoiberg D., Clancy D., Norvig P., Orwant J., Pinker S., Nowak M.A., Aiden E.L., Quantitative analysis of culture using millions of digitized books, Science, 331, pp. 176-182, (2011); 
Medimorec S., Risko E.F., Pauses in written composition: On the importance of where writers pause, Reading and Writing, 30, pp. 1-19, (2017); 
Page E.B., Project Essay Grade: PEG, Automated Essay Scoring: A Cross-disciplinary Perspective. Lawrence Erlbaum, pp. 43-54, (2003); 
Paschall K.W., Gershoff E.T., Kuhfeld M., A two-decade examination of historical race/ethnicity disparities in educational achievement by poverty status, Journal of Youth and Adolescence, 47, pp. 1164-1177, (2018); 
Quinlan T., Higgins D., Wolff S., Evaluating the construct-coverage of the e-rater® scoring engine (ETS RR-09-01), ETS Research Report Series, 2009, 1, pp. i-35, (2009); 
Reilly D., Neumann D.L., Andrews G., Gender differences in reading and writing achievement: Evidence from the National Assessment of educational Progress (NAEP), American Psychologist, 74, 4, pp. 445-458, (2019); 
Sabatini J.P., O'Reilly T., Halderman L.K., Bruce K., Integrating scenario-based and component reading skill measures to understand the reading behavior of struggling readers, Learning Disabilities Research & Practice, 29, 1, pp. 36-43, (2014); 
Sheehan K.M., A review of evidence presented in support of three key claims in the validity argument for the TextEvaluator® text analysis tool (ETS RR-16-12), ETS Research Report Series, 2015, 1, pp. 1-16, (2016); 
Sheehan K.M., Kostin I., Napolitano D., Flor M., The TextEvaluator tool: Helping teachers and test developers select texts for use in instruction and assessment, The Elementary School Journal, 115, 2, pp. 184-209, (2014); 
Sheehan K.M., O'reilly T., The CBAL reading assessment: An approach for balancing measurement and learning goals (ETS RR-11-21), ETS Research Report Series, 2011, 1, pp. i-26, (2011); 
Shermis M.D., Mzumara H.R., Olson J., Harrington S., On-line grading of student essays: PEG goes on the world wide web, Assessment & Evaluation in Higher Education, 26, 3, pp. 247-259, (2001); 
Smarter Balanced Assessment Consortium: 2016–17 technical report, (2017); 
Answers to questions about Smarter Balanced 2017 test results, (2018); 
Smarter Balanced Assessment Consortium: 2017–18 summative technical report, (2018); 
Somasundaran S., Burstein J., Chodorow M., Lexical chaining for measuring discourse coherence in test-taker essays, Proceedings of COLING 2014, the 25Th International Conference on Computational Linguistics: Technical Papers, pp. 950-961, (2014); 
Song Y., Deane P., Fowles M., Examining students' ability to critique arguments and exploring the implications for assessment and instruction (ETS RR-17-16), ETS Research Report Series, 2017, 1, pp. 1-12, (2017); 
van Rijn P.W., Graf E.A., Deane P., Empirical recovery of argumentation learning progressions in scenario-based assessments of English language arts, Psicología Educativa, 20, 2, pp. 109-115, (2014); 
Van Waes L., Leijten M., Wengelin A., Lindgren E., Logging tools to study digital writing processes, Past, present, and future contributions of cognitive writing research to cognitive psychology, pp. 507-536, (2012); 
Wilson J., Roscoe R.D., Automated writing evaluation and feedback: Multiple metrics of efficacy, Journal of Educational Computing Research, 58, 1, pp. 87-125, (2020); 
Zhang M., Deane P., Process features in writing: Internal structure and incremental value over product features (ETS RR-15-27), ETS Research Report Series, 2015, 2, pp. 1-12, (2015); 
Zhang M., Deane P., Feng G., Guo H., Investigating an approach to evaluating keyboarding fluency, Paper Presented at the Society for Text and Discourse, (2019); 
Zhang M., Hao J., Li C., Deane P., Classification of writing patterns using keystroke logs, Paper Presented at the Quantitative Psychology Research. the 80Th Annual Meeting of the Psychometric Society, Beijing. China, (2016); 
Zhang M., van Rijn P.W., Deane P., Bennett R.E., Scenario-based assessments in writing: An experimental study, Educational Assessment, 24, 2, pp. 73-90, (2019); 
Zhang M., Zou D., Wu A.D., Deane P., Li C., An investigation of writing processes employed in scenario-based assessment, Understanding and investigating response processes in validation research, pp. 321-339, (2017); 
Zipf G.K., The Psycho-biology of Language: An Introduction to Dynamic Philology, (1935)#FRF#
