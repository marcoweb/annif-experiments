#ITI#A Multidimensional Item Response Theory Model for Continuous and Graded Responses With Error in Persons and Items#FTI#
#IRE# Item response theory “dual” models (DMs) in which both items and individuals are viewed as sources of differential measurement error so far have been proposed only for unidimensional measures. This article proposes two multidimensional extensions of existing DMs: the M-DTCRM (dual Thurstonian continuous response model), intended for (approximately) continuous responses, and the M-DTGRM (dual Thurstonian graded response model), intended for ordered-categorical responses (including binary). A rationale for the extension to the multiple-content-dimensions case, which is based on the concept of the multidimensional location index, is first proposed and discussed. Then, the models are described using both the factor-analytic and the item response theory parameterizations. Procedures for (a) calibrating the items, (b) scoring individuals, (c) assessing model appropriateness, and (d) assessing measurement precision are finally discussed. The simulation results suggest that the proposal is quite feasible, and an illustrative example based on personality data is also provided. The proposals are submitted to be of particular interest for the case of multidimensional questionnaires in which the number of items per scale would not be enough for arriving at stable estimates if the existing unidimensional DMs were fitted on a separate-scale basis.#FRE#
#IPC# factor analysis; item discrimination; multidimensional item response theory; multidimensional location; person fluctuation; personality measurement#FPC#
#IRF# Baron R.M., Kenny D.A., The moderator–mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations, Journal of Personality and Social Psychology, 51, 6, pp. 1173-1182, (1986); 
Bock R.D., Mislevy R.J., Adaptive EAP estimation of ability in a microcomputer environment, Applied Psychological Measurement, 6, 4, pp. 431-444, (1982); 
Brown A., Croudace T., Scoring and estimating score precision using multidimensional IRT, Handbook of item response theory modeling: Applications to typical performance assessment, pp. 307-333, (2015); 
Cattell R.B., Tsujioka B., The importance of factor-trueness and validity, versus homogeneity and orthogonality, in test scales1, Educational and Psychological Measurement, 24, 1, pp. 3-30, (1964); 
Cronbach L.J., Warrington W.G., Efficiency of multiple-choice tests as a function of spread of item difficulties, Psychometrika, 17, 2, pp. 127-147, (1952); 
Cureton E.E., The upper and lower twenty-seven per cent rule, Psychometrika, 22, 3, pp. 293-296, (1957); 
Edwards A.L., Thurstone L.L., An internal consistency check for scale values determined by the method of successive intervals, Psychometrika, 17, 2, pp. 169-180, (1952); 
Ferrando P.J., Theoretical and empirical comparisons between two models for continuous item responses, Multivariate Behavioral Research, 37, 4, pp. 521-542, (2002); 
Ferrando P.J., Difficulty, discrimination, and information indices in the linear factor analysis model for continuous item responses, Applied Psychological Measurement, 33, 1, pp. 9-24, (2009); 
Ferrando P.J., A general linear framework for modeling continuous responses with error in persons and items, Methodology, 9, 4, pp. 150-161, (2013); 
Ferrando P.J., A comprehensive IRT approach for modeling binary, graded, and continuous responses with error in persons and items, Applied Psychological Measurement, 43, 5, pp. 339-359, (2019); 
Ferrando P.J., Lorenzo-Seva U., An external validity approach for assessing essential unidimensionality in correlated-factor models, Educational and Psychological Measurement, 79, 3, pp. 437-461, (2019); 
Ferrando P.J., Navarro-Gonzalez D., InDisc: An R package for assessing person and item discrimination in typical-response measures, Applied Psychological Measurement, 44, 4, pp. 327-328, (2020); 
Fisher J., The twisted pear and the prediction of behavior, Journal of Consulting Psychology, 23, 5, pp. 400-405, (1959); 
Fiske D.W., Items and persons: Formal duals and psychological differences, Multivariate Behavioral Research, 3, 4, pp. 393-401, (1968); 
Guilford J.P., Personality, (1959); 
Hofstee W.K.B., Ten Berge J.M.F., Hendriks A.A.J., How to score questionnaires, Personality and Individual Differences, 25, 5, pp. 897-909, (1998); 
LaHuis D.M., Barnes T., Hakoyama S., Blackmore C., Hartman M.J., Measuring traitedness with person reliabilities parameters, Personality and Individual Differences, 109, pp. 111-116, (2017); 
Levine M.V., Rubin D.B., Measuring the appropriateness of multiple choice test scores, Journal of Educational Statistics, 4, 4, pp. 269-290, (1979); 
Lorenzo-Seva U., Promin: A method for oblique factor rotation, Multivariate Behavioral Research, 34, 3, pp. 347-356, (1999); 
Lorenzo-Seva U., Ferrando P.J., FACTOR 9.2: A comprehensive program for fitting exploratory and semiconfirmatory factor analysis and IRT models, Applied Psychological Measurement, 37, 6, pp. 497-498, (2013); 
Lorenzo-Seva U., Ferrando P.J., Not positive definite correlation matrices in exploratory item factor analysis: Causes, consequences and a proposed solution, Structural Equation Modeling, (2020); 
Lubbe D., Schuster C., The graded response differential discrimination model accounting for extreme response style, Multivariate Behavioral Research, 52, 5, pp. 616-629, (2017); 
Lumsden J., Variations on a theme by Thurstone, Applied Psychological Measurement, 4, 1, pp. 1-7, (1980); 
McDonald R.P., Factor analysis and related methods, (1985); 
McDonald R.P., A basis for multidimensional item response theory, Applied Psychological Measurement, 24, 2, pp. 99-114, (2000); 
Mellenbergh G.J., A unidimensional latent trait model for continuous item responses, Multivariate Behavioral Research, 29, 3, pp. 223-237, (1994); 
Mosier C.I., Psychophysics and mental test theory II: The constant process, Psychological Review, 48, 3, pp. 235-249, (1942); 
Muthen B., A general structural equation model with dichotomous, ordered, categorical and continuous latent variable indicators, Psychometrika, 49, 1, pp. 115-132, (1984); 
Novick M.R., Jackson P.H., Statistical methods for educational and psychological research, (1974); 
Reckase M.D., Multidimensional item response theory, (2009); 
Reise S.P., Waller N.G., Item response theory and clinical measurement, Annual Review of Clinical Psychology, 5, pp. 27-48, (2009); 
Strandmark N.L., Linn R.L., A generalized logistic item response model parameterizing test score inappropriateness, Applied Psychological Measurement, 11, 4, pp. 355-370, (1987); 
Taylor J.B., Item homogeneity, scale reliability, and the self-concept hypothesis, Educational and Psychological Measurement, 37, 2, pp. 349-361, (1977); 
Thurstone L.L., A law of comparative judgment, Psychological Review, 34, 4, pp. 273-278, (1927); 
Torgerson W., Theory and methods of scaling, (1958); 
Tutz G., Schauberger G., Uncertainty in latent trait models, Applied Psychological Measurement, 44, 6, pp. 467-474, (2020); 
Vigil-Colet A., Lorenzo-Seva U., Condon L., Development and validation of the Statistical Anxiety Scale, Psicothema, 20, 1, pp. 174-180, (2008); 
Weiss D.J., The Stratified Adaptive Computerized Ability Test, (1973); 
Yuan K.H., Chan W., Marcoulides G.A., Bentler P.M., Assessing structural equation models by equivalence testing with adjusted fit indexes, Structural Equation Modeling, 23, 3, pp. 319-330, (2016)#FRF#
