#ITI#Is the Area Under Curve Appropriate for Evaluating the Fit of Psychometric Models?#FTI#
#IRE# In the literature of modern psychometric modeling, mostly related to item response theory (IRT), the fit of model is evaluated through known indices, such as χ2, M2, and root mean square error of approximation (RMSEA) for absolute assessments as well as Akaike information criterion (AIC), consistent AIC (CAIC), and Bayesian information criterion (BIC) for relative comparisons. Recent developments show a merging trend of psychometric and machine learnings, yet there remains a gap in the model fit evaluation, specifically the use of the area under curve (AUC). This study focuses on the behaviors of AUC in fitting IRT models. Rounds of simulations were conducted to investigate AUC’s appropriateness (e.g., power and Type I error rate) under various conditions. The results show that AUC possessed certain advantages under certain conditions such as high-dimensional structure with two-parameter logistic (2PL) and some three-parameter logistic (3PL) models, while disadvantages were also obvious when the true model is unidimensional. It cautions researchers about the dangers of using AUC solely in evaluating psychometric models.#FRE#
#IPC# absolute fit indices; AUC; goodness of fit; item response theory; multidimensional structures#FPC#
#IRF# Akaike H., A new look at the statistical model identification, IEEE Transactions on Automatic Control, 19, 6, pp. 716-723, (1974); 
Asparouhov T., Muthen B., SRMR in Mplus, (2018); 
Bartholomew D.J., Leung S.O., A goodness of fit test for sparse 2p contingency tables, British Journal of Mathematical and Statistical Psychology, 55, pp. 1-15, (2002); 
Bentler P.M., Comparative fit indexes in structural models, Psychological Bulletin, 107, 2, (1990); 
Bergner Y., Droschler S., Kortemeyer G., Rayyan S., Seaton D., Pritchard D.E., Model-based collaborative filtering analysis of student response data: Machine-learning item response theory, (2012); 
Birnbaum A., Some latent trait models and their use in inferring an examinee’s ability, Statistical theories of mental test scores, pp. 397-479, (1968); 
Bock R.D., Estimating item parameters and latent ability when responses are scored in two or more nominal categories, Psychometrika, 37, pp. 29-51, (1972); 
Bowers A.J., Zhou X., Receiver operating characteristic (ROC) area under the curve (AUC): A diagnostic measure for evaluating the accuracy of predictors of education outcomes, Journal of Education for Students Placed at Risk, 24, 1, pp. 20-46, (2019); 
Bozdogan H., Model selection and Akaike s information criterion (AIC): The general theory and its analytical extensions, Psychometrika, 52, pp. 345-370, (1987); 
Cai L., Hansen M., Limited-information goodness-of-fit testing of hierarchical item factor models, British Journal of Mathematical and Statistical Psychology, 66, pp. 245-276, (2013); 
Cai L., Maydeu-Olivares A., Coffman D.L., Thissen D., Limited-information goodness-of-fit testing of item response theory models for sparse 2 tables, British Journal of Mathematical and Statistical Psychology, 59, pp. 173-194, (2006); 
Cai L., Monroe S., A new statistic for evaluating item response theory models for ordinal data, (2014); 
Carlson S.E., Identifying students at risk of dropping out: Indicators and thresholds using ROC analysis, (2018); 
Chalmers R.P., mirt: A multidimensional item response theory package for the R environment, Journal of Statistical Software, 48, 6, pp. 1-29, (2012); 
Chalmers R.P., Ng V., Plausible-value imputation statistics for detecting item misfit, Applied Psychological Measurement, 41, pp. 372-387, (2017); 
Cheng S., Liu Q., Chen E., Huang Z., Huang Z., Chen Y., Ma H., Hu G., Dirt: Deep learning enhanced item response theory for cognitive diagnosis, pp. 2397-2400, (2019); 
Chernyshenko O.S., Stark S., Chan K.Y., Drasgow F., Williams B., Fitting item response theory models to two personality inventories: Issues and insights, Multivariate Behavioral Research, 36, 4, pp. 523-562, (2001); 
DeMars C.E., Partially compensatory multidimensional item response theory models: Two alternate model forms, Educational and Psychological Measurement, 76, 2, pp. 231-257, (2016); 
Drasgow F., Levine M.V., Williams E.A., Appropriateness measurement with polychotomous item response models and standardized indices, British Journal of Mathematical and Statistical Psychology, 38, pp. 67-86, (1985); 
Embretson S.E., Reise S.P., Item response theory for psychologists, (2013); 
Fawcett T., An introduction to ROC analysis, Pattern Recognition Letters, 27, 8, pp. 861-874, (2006); 
Ferri C., Flach P., Hernandez-Orallo J., Senad A., Modifying ROC curves to incorporate predicted probabilities, pp. 33-40, (2005); 
Finlayson K.J., Parker C.N., Miller C., Gibb M., Kapp S., Ogrin R., Edwards H.E., Predicting the likelihood of venous leg ulcer recurrence: The diagnostic accuracy of a newly developed risk assessment tool, International Wound Journal, 15, 5, pp. 686-694, (2018); 
Gonzalez O., Psychometric and machine learning approaches for diagnostic assessment and tests of individual classification, Psychological Methods, 26, 2, pp. 236-254, (2021); 
Hosmer D.W., Lemeshow S., Applied logistic regression, (2000); 
Huang J., Ling C.X., Using AUC and accuracy in evaluating learning algorithms, IEEE Transactions on Knowledge and Data Engineering, 17, 3, pp. 299-310, (2005); 
Huggins-Manley A.C., Han H., Assessing the sensitivity of weighted least squares model fit indexes to local dependence in item response theory models, Structural Equation Modeling: A Multidisciplinary Journal, 24, 3, pp. 331-340, (2017); 
Immekus J.C., Snyder K.E., Ralston P.A., Multidimensional item response theory for factor structure assessment in educational psychology research, Frontiers in Education, 4, (2019); 
Jiang Z., Fitzgerald S.R., Walker K.W., Modeling time-to-trigger in library demand-driven acquisitions via survival analysis, Library & Information Science Research, 41, 3, (2019); 
Jiang Z., Walker K., Shi D., Applying AdaBoost to improve diagnostic accuracy, Methodology, 15, pp. 77-87, (2019); 
Johnson E., Semmelroth C., The predictive validity of the early warning system tool, NASSP Bulletin, 94, 2, pp. 120-134, (2010); 
Kang T., Chen T.T., Performance of the generalized S-X2 Item fit index for polytomous IRT models, Journal of Educational Measurement, 45, 4, pp. 391-406, (2008); 
Kang T., Cohen A.S., IRT model selection methods for dichotomous items, Applied Psychological Measurement, 31, 4, pp. 331-358, (2007); 
Kang T., Cohen A.S., Sung H.J., Model selection indices for polytomous items, Applied Psychological Measurement, 33, 7, pp. 499-518, (2009); 
Khajah M., Lindsey R.V., Mozer M.C., How deep is knowledge tracing?, (2016); 
Koehler K.J., Larntz K., An empirical investigation of goodness-of-fit statistics for sparse multinomials, Journal of the American Statistical Association, 75, 370, pp. 336-344, (1980); 
Kuhn M., caret: Classification and regression training, (2021); 
Le C.V., Pardos Z.A., Meyer S.D., Thorp R., Communication at scale in a MOOC using predictive engagement analytics, Artificial intelligence in education, pp. 239-252, (2018); 
Lee Y., Estimating student ability and problem difficulty using item response theory (IRT) and TrueSkill, Information Discovery and Delivery, 47, 2, pp. 67-75, (2019); 
Lemeshow S., Hosmer D.W., A review of goodness of fit statistics for use in the development of logistic regression models, American Journal of Epidemiology, 115, 1, pp. 92-106, (1982); 
Lin T.H., Dayton C.M., Model selection information criteria for non-nested latent class models, Journal of Educational and Behavioral Statistics, 22, pp. 249-264, (1997); 
Maydeu-Olivares A., Goodness-of-fit assessment of item response theory models, Measurement, 11, pp. 71-101, (2013); 
Maydeu-Olivares A., Joe H., Limited information goodness-of-fit testing in multidimensional contingency tables, Psychometrika, 71, 4, pp. 713-732, (2006); 
Maydeu-Olivares A., Joe H., Assessing approximate fit in categorical data analysis, Multivariate Behavioral Research, 49, 4, pp. 305-328, (2014); 
McKinley R.L., Mills C.N., A comparison of several goodness-of-fit statistics, Applied Psychological Measurement, 9, 1, pp. 49-57, (1985); 
Mersmann O., Trautmann H., Steuer D., Bornkamp B., truncnorm: Truncated normal distribution, (2018); 
Millard S.P., EnvStats: An R package for environmental statistics, (2013); 
Nicholls G., Wolfe H., Besterfield-Sacre M., Shuman L., Predicting stem degree outcomes based on eighth grade data and standard test scores, Journal of Engineering Education, 99, 3, pp. 209-223, (2010); 
Niemeijer K., Feskens R., Krempl G., Koops J., Brinkhuis M.J.S., Constructing and predicting school advice for academic achievement: A comparison of item response theory and machine learning techniques, pp. 462-471, (2020); 
Orlando M., Thissen D., Likelihood-based item-fit indices for dichotomous item response theory models, Applied Psychological Measurement, 24, 1, pp. 50-64, (2000); 
Park J.Y., Cornillie F., van der Maas H.L., Van Den Noortgate W., A multidimensional IRT approach for dynamically monitoring ability growth in computerized practice environments, Frontiers in Psychology, 10, (2019); 
Pham B.T., Luu C., Van Phong T., Trinh P.T., Shirzadi A., Renoud S., Clague J.J., Can deep learning algorithms outperform benchmark machine learning algorithms in flood susceptibility modeling?, Journal of Hydrology, 592, (2021); 
Piech C., Spencer J., Huang J., Ganguli S., Sahami M., Guibas L., Sohl-Dickstein J., Deep knowledge tracing, (2015); 
Pliakos K., Joo S.H., Park J.Y., Cornillie F., Vens C., Van den Noortgate W., Integrating machine learning into item response theory for addressing the cold start problem in adaptive learning systems, Computers & Education, 137, pp. 91-103, (2019); 
Rasch G., Studies in mathematical psychology: I—Probabilistic models for some intelligence and attainment tests, (1960); 
A language and environment for statistical computing, (2021); 
Robin X., Turck N., Hainard A., Tiberti N., Lisacek F., Sanchez J.-C., Muller M., pROC: An open-source package for R and S+ to analyze and compare ROC curves, BMC Bioinformatics, 12, 1, (2011); 
Schwarz G., Estimating the dimension of a model, Annals of Statistics, 6, pp. 461-464, (1978); 
Silva W., Spalenza M., Bourguet J.R., de Oliveira E., Towards a tailored hybrid recommendation-based system for computerized adaptive testing through clustering and IRT, 1, pp. 260-268, (2020); 
Steiger J.H., Lind J.C., (1980); 
Stuit D., O'Cummings M., Norbury H., Heppen J., Dhillon S., Lindsay J., Zhu B., Identifying early warning indicators in three Ohio school Districts, (2016); 
Su Y., Liu Q., Liu Q., Huang Z., Yin Y., Chen E., Hu G., Exercise-enhanced sequential modeling for student performance prediction, 32, 1, (2018); 
Svicher A., Romanazzo S., De Cesaris F., Benemei S., Geppetti P., Cosci F., Mental Pain Questionnaire: An item response theory analysis, Journal of Affective Disorders, 249, pp. 226-233, (2019); 
Thissen D., Steinberg L., Item response theory, The SAGE handbook of quantitative methods in psychology, pp. 148-177, (2009); 
Tucker L.R., Lewis C., A reliability coefficient for maximum likelihood factor analysis, Psychometrika, 38, 1, pp. 1-10, (1973); 
Walker K.W., Jiang Z., Application of adaptive boosting (AdaBoost) in demand-driven acquisition (DDA) prediction: A machine-learning approach, The Journal of Academic Librarianship, 45, 3, pp. 203-212, (2019); 
Windle M., Windle R.C., The measurement of adolescent alcohol problems via item response theory and their 15-year prospective associations with alcohol and other psychiatric disorders, Alcoholism: Clinical and Experimental Research, 41, 2, pp. 399-406, (2017); 
Wright B., Masters G., Rating Scale analysis, (1982); 
Wu R., Xu G., Chen E., Liu Q., Ng W., Knowledge or gaming? Cognitive modelling based on multiple-attempt response, pp. 321-329, (2017); 
Wu Z., Ioannidis N.M., Zou J., Predicting target genes of non-coding regulatory variants with IRT, Bioinformatics, 36, 16, pp. 4440-4448, (2020); 
Xiao Z., Shi Z., Hu L., Gao Y., Zhao J., Liu Y., Xu Q., Huang D., A new nomogram from the seer database for predicting the prognosis of gallbladder cancer patients after surgery, Annals of Translational Medicine, 7, 23, (2019); 
Xu J., Paek I., Xia Y., Investigating the behaviors of M2 and RMSEA2 in fitting a unidimensional model to multidimensional data, Applied Psychological Measurement, 41, 8, pp. 632-644, (2017); 
Yen W.M., Using simulation results to choose a latent trait model, Applied Psychological Measurement, 5, 2, pp. 245-262, (1981)#FRF#
