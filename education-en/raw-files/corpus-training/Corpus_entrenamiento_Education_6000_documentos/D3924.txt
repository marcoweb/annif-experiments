#ITI#An accurate and practical method for assessing science and engineering problem-solving expertise#FTI#
#IRE#The ability to solve authentic real-world problems in science, engineering, and medicine is an important goal in post-secondary education. Despite extensive research on problem solving and expertise, the teaching and assessing of advanced problem-solving skills in post-secondary students remains a challenge. We present a template for creating assessments of advanced problem-solving skills that is applicable across science, engineering, and medical disciplines. It is based on a cognitive model of the problem-solving process that is empirically grounded in the study of skilled practitioners (‘experts’) solving authentic problems in their disciplines. These assessments have three key features that overcome shortcomings of current assessment approaches: 1) a more authentic amount and sequence of information provided, 2) opportunities for students to make decisions, and 3) scoring based on comparison with skilled practitioners. This provides a more complete and accurate assessment of authentic problem-solving skills than currently exists for science, engineering, and medicine. Such assessments will be valuable to instructors and curriculum designers for evaluating and improving the teaching of problem solving in these disciplines. We provide examples of problem-solving assessments that illustrate the use of this template in several disciplines#FRE#
#IPC#assessment; expertise; Problem-solving#FPC#
#IRF#Adams W.K., Wieman C.E., Development and validation of instruments to measure learning of expert-like thinking, International Journal of Science Education, 33, 9, pp. 1289-1312, (2011); 
Adams W.K., Wieman C.E., Analyzing the many skills involved in solving complex physics problems, American Journal of Physics, 83, 5, pp. 459-467, (2015); 
Burkholder E.W., Miles J.K., Layden T.J., Wang K.D., Fritz A.V., Wieman C.E., Template for teaching and assessment of problem solving in introductory physics, Physical Review Physics Education Research, 16, 1, (2020); 
Burkholder E.W., Wieman C., Comparing problem-solving across capstone design courses in chemical engineering, 2020 IEEE Frontiers in Education Conference (FIE), pp. 1-5, (2020); 
Card S.K., Moran T.P., Newell A., The psychology of human-computer interaction, (1983); 
Chi M.T., Children's Thinking: What Develops?, Knowledge Structures and Memory Development, pp. 75-96, (1978); 
Chi M.T., Glaser R., Rees E., Expertise in problem solving, (1981); 
Csapo B., Funke J., The nature of problem solving: Using research to inspire 21st century learning, (2017); 
Dorner D., Funke J., Complex problem solving: What it is and what it is not, Frontiers in Psychology, 8, (2017); 
Duncan T.M., Reimer J.A., Chemical engineering design and analysis: An introduction. Problem 2-7, (2019); 
Duncan T.M., Reimer J.A., Chemical engineering design and analysis: An introduction (2nd ed.), (2019); 
Endsley M.R., Expertise and situation awareness, The cambridge handbook of expertise and expert performance, pp. 714-741, (2018); 
Ennis R.H., Critical thinking assessment, Theory Into Practice, 32, 3, pp. 179-186, (1993); 
Ericsson K.A., The influence of experience and deliberate practice on the development of superior expert performance, The Cambridge handbook of expertise and expert performance, pp. 683-704, (2006); 
Ericsson K.A., Hoffman R.R., Kozbelt A., Williams A.M., The cambridge handbook of expertise and expert performance (2nd ed.), (2018); 
Farrington-Darby T., Wilson J.R., The nature of expertise: A review, Applied Ergonomics, 37, 1, pp. 17-32, (2006); 
Flynn M.P., Assessing expertise in mechanical engineering design, (2020); 
Frensch P.A., Funke J., Complex problem solving: The European perspective, (1995); 
Handelsman J., Ebert-May D., Beichner R., Bruns P., Chang A., DeHaan R., Gentile J., Lauffer S., Stewart J., Tilghman S.M., Wood W.B., Scientific teaching, Science, 304, 5670, pp. 521-522, (2004); 
Harris C.J., Krajcik J.S., Pellegrino J.W., DeBarger A.H., Designing knowledge-In-Use assessments to promote deeper learning, Educational Measurement: Issues and Practice, 38, 2, pp. 53-67, (2019); 
Hatano G., Inagaki K., Two courses of expertise, Child Development and Education in Japan, pp. 262-272, (1986); 
Hegarty M., Knowledge and processes in mechanical problem solving, Complex Problem Solving: Principles and Mechanisms, pp. 253-285, (1991); 
Hoffman R.R., Lintern G., Eliciting and representing the knowledge of experts, The Cambridge Handbook of Expertise and Expert Performance, pp. 203-222, (2006); 
Holmes N.G., Keep B., Wieman C.E., Developing scientific decision making by structuring and supporting student agency, Physical Review Physics Education Research, 16, 1, (2020); 
Jones D.J., Madison K.W., Wieman C.E., Transforming a fourth year modern optics course using a deliberate practice framework, Physical Review Special Topics - Physics Education Research, 11, 2, (2015); 
Kay D.S., Computer interaction: Debugging the problems, Complex Problem Solving: Principles and Mechanisms, pp. 317-340, (1991); 
Kelly R., McLoughlin E., Finlayson O.E., Analysing student written solutions to investigate if problem-solving processes are evident throughout, International Journal of Science Education, 38, 11, pp. 1766-1784, (2016); 
Lane S., Validity of High-Stakes Assessment: Are Students Engaged in Complex Thinking?, Educational Measurement: Issues and Practice, 23, 3, pp. 6-14, (2004); 
Larkin J.H., Reif F., Understanding and teaching problem-solving in physics, European Journal of Science Education, 1, 2, pp. 191-203, (1979); 
Laverty J.T., Underwood S.M., Matz R.L., Posey L.A., Carmel J.H., Caballero M.D., Fata-Hartley C.L., Ebert-May D., Jardeleza S.E., Cooper M.M., Characterizing college science assessments: The three-dimensional learning assessment protocol, PLOS ONE, 11, 9, (2016); 
Lenzer S., Smarsly B., Graulich N., How do students become experts? An in-depth study on the development of domain-specific awareness in a materials chemistry course, International Journal of Science Education, 42, 12, pp. 2032-2054, (2020); 
McCloskey M., Naive theories of motion, Mental Models, pp. 299-324, (1983); 
Mosier K., Fischer U., Hoffman R.R., Klein G., Expert professional judgments and “naturalistic decision making”, The cambridge handbook of expertise and expert performance, pp. 453-475, (2018); 
Knowing what students know: The science and design of educational assessment, (2001); 
Developing assessments for the next generation science standards, (2014); 
(2020); 
Pellegrino J.W., DiBello L.V., Goldman S.R., A framework for conceptualizing and evaluating the validity of instructionally relevant assessments, Educational Psychologist, 51, 1, pp. 59-81, (2016); 
Price A.M., Kim C.J., Burkholder E.W., Fritz A.V., Wieman C.E., A detailed characterization of the expert problem-solving process in science and engineering: Guidance for teaching and assessment, CBE—Life Sciences Education, 20, 3, (2021); 
Ramalingam D., Philpot R., Mccrae B., The PISA 2012 assessment of problem solving, The nature of problem solving: Using research to inspire 21st century learning, pp. 75-91, (2017); 
Randles C.A., Overton T.L., Expert vs. Novice: Approaches used by chemists when solving open-ended problems, Chemistry Education Research and Practice, 16, 4, pp. 811-823, (2015); 
Resnick L.B., Syntax and semantics in learning to subtract, Addition and Subtraction: A Cognitive Perspective (1St, pp. 136-155, (1982); 
Ryoo K., Linn M.C., Designing and validating assessments of complex thinking in science, Theory Into Practice, 54, 3, pp. 238-254, (2015); 
Salehi S., Improving problem-solving through reflection, (2018); 
Schwartz D.L., Arena D., Measuring what matters most: Choice-based assessments for the digital Age, (2013); 
Schwartz D.L., Tsang J.M., Blair K.P., The ABCs of How We learn: 26 scientifically proven approaches, How they work, and when to Use them, (2016); 
Siegler R.S., The origins of scientific reasoning, Children’s Thinking: What Develops?, pp. 109-149, (1978); 
Simon H.A., The structure of ill structured problems, Artificial Intelligence, 4, 3-4, pp. 181-201, (1973); 
Songer N.B., BioKIDS: An animated conversation on the development of curricular activity structures for inquiry science, Cambridge handbook of the learning sciences, pp. 355-369, (2006); 
Sternberg R.J., Expertise in complex problem solving: A comparison of alternative conceptions, Complex Problem Solving: The European Perspective, pp. 295-321, (1995); 
Stowe R.L., Cooper M.M., Practicing what We preach: Assessing “critical thinking” in organic chemistry, Journal of Chemical Education, 94, 12, pp. 1852-1859, (2017); 
Villarroel V., Bloxham S., Bruna D., Bruna C., Herrera-Seda C., Authentic assessment: Creating a blueprint for course design, Assessment & Evaluation in Higher Education, 43, 5, pp. 840-854, (2018); 
Walsh C., Quinn K.N., Wieman C., Holmes N.G., Quantifying critical thinking: Development and validation of the physics lab inventory of critical thinking, Physical Review Physics Education Research, 15, 1, (2019); 
Wieman C.E., Expertise in university teaching & the implications for teaching effectiveness, evaluation & training, Daedalus, 148, 4, pp. 47-78, (2019); 
Winne P.H., Azevedo R., Metacognition, The cambridge handbook of the learning sciences (2nd ed., pp. 63-87, (2014)#FRF#
