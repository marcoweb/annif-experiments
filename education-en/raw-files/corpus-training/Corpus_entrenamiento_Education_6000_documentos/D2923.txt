#ITI#Robust Bayesian meta-analysis: Model-averaging across complementary publication bias adjustment methods#FTI#
#IRE# Publication bias is a ubiquitous threat to the validity of meta-analysis and the accumulation of scientific evidence. In order to estimate and counteract the impact of publication bias, multiple methods have been developed; however, recent simulation studies have shown the methods' performance to depend on the true data generating process, and no method consistently outperforms the others across a wide range of conditions. Unfortunately, when different methods lead to contradicting conclusions, researchers can choose those methods that lead to a desired outcome. To avoid the condition-dependent, all-or-none choice between competing methods and conflicting results, we extend robust Bayesian meta-analysis and model-average across two prominent approaches of adjusting for publication bias: (1) selection models of p-values and (2) models adjusting for small-study effects. The resulting model ensemble weights the estimates and the evidence for the absence/presence of the effect from the competing approaches with the support they receive from the data. Applications, simulations, and comparisons to preregistered, multi-lab replications demonstrate the benefits of Bayesian model-averaging of complementary publication bias adjustment methods#FRE#
#IPC# Bayesian model-averaging; meta-analysis; PET-PEESE; publication bias; selection models#FPC#
#IRF# Borenstein M., Hedges L., Higgins J., Rothstein H., Publication Bias, pp. 277-292, (2009); 
Masicampo E., Lalande D.R., A peculiar prevalence of p-values just below.05, Q J Exp Psychol, 65, 11, pp. 2271-2279, (2012); 
Scheel A.M., Schijen M.R.M.J., Lakens D., An excess of positive results: comparing the standard psychology literature with registered reports, Adv Methods Pract Psychol Sci, 4, 2, (2021); 
Wicherts J.M., The weak spots in contemporary science (and how to fix them), Animals, 7, 12, pp. 90-119, (2017); 
Rothstein H.R., Sutton A.J., Borenstein M., Publication Bias in Meta-Analysis, (2005); 
Rosenthal R., Gaito J., Further evidence for the cliff effect in interpretation of levels of significance, Psychol Rep, 15, 2, (1964); 
Simmons J.P., Nelson L.D., Simonsohn U., False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant, Psychol Sci, 22, 11, pp. 1359-1366, (2011); 
Stefan A., Schonbrodt F.D., Big little lies: a compendium and simulation of p-hacking strategies, PsyArXiv Preprints, (2022); 
John L.K., Loewenstein G., Prelec D., Measuring the prevalence of questionable research practices with incentives for truth telling, Psychol Sci, 23, 5, pp. 524-532, (2012); 
Fiedler K., Schwarz N., Questionable research practices revisited, Soc Psychol Personal Sci, 7, 1, pp. 45-52, (2016); 
Vevea J.L., Hedges L.V., A general linear model for estimating effect size in the presence of publication bias, Psychometrika, 60, 3, pp. 419-435, (1995); 
Iyengar S., Greenhouse J.B., Selection models and the file drawer problem, Stat Sci, 3, 1, pp. 109-117, (1988); 
Maier M., Bartos F., Wagenmakers E.J., Robust Bayesian meta-analysis: addressing publication bias with model-averaging, Psychol Methods, (2022); 
Egger M., Smith G.D., Schneider M., Minder C., Bias in meta-analysis detected by a simple, graphical test, BMJ, 315, 7109, pp. 629-634, (1997); 
Stanley T.D., Doucouliagos H., Neither fixed nor random: weighted least squares meta-regression, Res Synth Methods, 8, 1, pp. 19-42, (2017); 
Stanley T.D., Doucouliagos H., Meta-regression approximations to reduce publication selection bias, Res Synth Methods, 5, 1, pp. 60-78, (2014); 
Duval S., Tweedie R., Trim and fill: a simple funnel-plot-based method of testing and adjusting for publication bias in meta-analysis, Biometrics, 56, 2, pp. 455-463, (2000); 
Simonsohn U., Nelson L.D., Simmons J.P., P-curve: a key to the file-drawer, J Exp Psychol Gen, 143, 2, pp. 534-547, (2014); 
Van Assen M.A., Aert V.R., Wicherts J.M., Meta-analysis using effect size distributions of only statistically significant studies, Psychol Methods, 20, 3, pp. 293-309, (2015); 
Andrews I., Kasy M., Identification of and correction for publication bias, Am Econ Rev, 109, 8, pp. 2766-2794, (2019); 
Bom P.R., Rachinger H., A kinked meta-regression model for publication bias correction, Res Synth Methods, 10, 4, pp. 497-514, (2019); 
Stanley T.D., Doucouliagos H., Ioannidis J.P., Finding the power to reduce publication bias, Stat Med, 36, 10, pp. 1580-1598, (2017); 
Copas J., What works?: selectivity models and meta-analysis, J R Stat Soc A Stat Soc, 162, 1, pp. 95-109, (1999); 
Citkowicz M., Vevea J.L., A parsimonious weight function for modeling publication bias, Psychol Methods, 22, 1, pp. 28-41, (2017); 
Carter E.C., Schonbrodt F.D., Gervais W.M., Hilgard J., Correcting for bias in psychology: a comparison of meta-analytic methods, Adv Methods Pract Psychol Sci, 2, 2, pp. 115-144, (2019); 
Renkewitz F., Keiner M., How to detect publication bias in psychological research, Z Psychol, 227, 4, pp. 261-279, (2019); 
Hong S., Reed W.R., Using Monte Carlo experiments to select meta-analytic estimators, Res Synth Methods, 12, pp. 192-215, (2020); 
Vevea J.L., Woods C.M., Publication bias in research synthesis: sensitivity analysis using a priori weight functions, Psychol Methods, 10, 4, pp. 428-443, (2005); 
Rothstein H.R., Sutton A.J., Borenstein M., Publication bias in meta-analysis, Publication Bias in Meta-Analysis: Prevention, Assessment and Adjustments, pp. 1-7, (2005); 
Mathur M.B., Van der Weele T.J., Sensitivity analysis for publication bias in meta-analyses, J R Stat Soc Ser C Appl Stat, 69, 5, pp. 1091-1119, (2020); 
Oswald M.E., Grosjean S., Confirmation Bias, pp. 79-96, (2004); 
McShane B.B., Bockenholt U., Hansen K.T., Adjusting for publication bias in meta-analysis: an evaluation of selection methods and some cautionary notes, Perspect Psychol Sci, 11, 5, pp. 730-749, (2016); 
Guan M., Vandekerckhove J., A Bayesian approach to mitigation of publication bias, Psychon Bull Rev, 23, 1, pp. 74-86, (2016); 
Kvarven A., Stromland E., Johannesson M., Comparing meta-analyses and preregistered multiple-laboratory replication projects, Nat Hum Behav, 4, 4, pp. 423-434, (2020); 
Bem D.J., Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect, J Pers Soc Psychol, 100, 3, pp. 407-425, (2011); 
Hoeting J.A., Madigan D., Raftery A.E., Volinsky C.T., Bayesian model averaging: a tutorial, Stat Sci, 14, 4, pp. 382-401, (1999); 
Leamer E.E., Specification Searches: Ad Hoc Inference with Nonexperimental Data, 53, (1978); 
Hinne M., Gronau Q.F., van den Bergh D., Wagenmakers E.J., A conceptual introduction to Bayesian model averaging, Adv Methods Pract Psychol Sci, 3, 2, pp. 200-215, (2020); 
Gronau Q.F., Erp V.S., Heck D.W., Cesario J., Jonas K.J., Wagenmakers E.J., A Bayesian model-averaged meta-analysis of the power pose effect with informed and default priors: the case of felt power, Compr Results Soc Psychol, 2, 1, pp. 123-138, (2017); 
Gronau Q.F., Heck D.W., Berkhout S.W., Haaf J.M., Wagenmakers E.J., A primer on Bayesian model-averaged meta-analysis, Adv Methods Pract Psychol Sci, 4, 3, (2021); 
Fragoso T.M., Bertoli W., Louzada F., Bayesian model averaging: a systematic review and conceptual classification, Int Stat Rev, 86, 1, pp. 1-28, (2018); 
Jefferys W.H., Berger J.O., Ockham's razor and Bayesian analysis, Am Sci, 80, pp. 64-72, (1992); 
Etz A., Wagenmakers E.J., J. B. S. Haldane's contribution to the Bayes factor hypothesis test, Stat Sci, 32, pp. 313-329, (2017); 
Kass R.E., Raftery A.E., Bayes factors, J Am Stat Assoc, 90, 430, pp. 773-795, (1995); 
Rouder J.N., Morey R.D., Teaching Bayes' theorem: strength of evidence as predictive accuracy, Am Stat, 73, 2, pp. 186-190, (2019); 
Wrinch D., Jeffreys H., On certain fundamental principles of scientific inquiry, Philos Mag, 42, pp. 369-390, (1921); 
Jeffreys H., Theory of Probability, (1939); 
Lee M.D., Wagenmakers E.J., Bayesian Cognitive Modeling: A Practical Course, (2013); 
Clyde M.A., Ghosh J., Littman M.L., Bayesian adaptive sampling for variable selection and model averaging, J Comput Graph Stat, 20, 1, pp. 80-101, (2011); 
Bartos F., Gronau Q.F., Timmers B., Otte W.M., Ly A., Wagenmakers E.J., Bayesian model-averaged meta-analysis in medicine, Stat Med, 40, pp. 6743-6761, (2021); 
Wagenmakers E.J., Morey R.D., Lee M.D., Bayesian benefits for the pragmatic researcher, Curr Dir Psychol Sci, 25, pp. 169-176, (2016); 
Jeffreys H., Some tests of significance, treated by the theory of probability, Proc Camb Philos Soc, 31, pp. 203-222, (1935); 
Robinson G.K., What properties might statistical inferences reasonably be expected to have? – crisis and resolution in statistical inference, Am Stat, 73, pp. 243-252, (2019); 
Keysers C., Gazzola V., Wagenmakers E.J., Using Bayes factor hypothesis testing in neuroscience to establish evidence of absence, Nat Neurosci, 23, pp. 788-799, (2020); 
Schure T.J., Grunwald P., Accumulation bias in meta-analysis: the need to consider time in error control, F1000Res, 8, (2019); 
Hedges L.V., Modeling publication selection effects in meta-analysis, Stat Sci, 7, 2, pp. 246-255, (1992); 
Maier M., Van der Weele T.J., Mathur M.B., Using selection models to assess sensitivity to publication bias: a tutorial and call for more routine use, Campbell Syst Rev, 18, 3; 
Copas J., Li H., Inference for non-random samples, J R Stat Soc Series B Stat Methodology, 59, 1, pp. 55-95, (1997); 
Copas J., Shi J.Q., A sensitivity analysis for publication bias in systematic reviews, Stat Methods Med Res, 10, 4, pp. 251-265, (2001); 
Bem D.J., Utts J., Johnson W.O., Must psychologists change the way they analyze their data?, J Pers Soc Psychol, 101, 4, pp. 716-719, (2011); 
Bartos F., Maier M., RoBMA: An R Package for Robust Bayesian Meta-Analyses. R package version 2.0.0, (2021); 
Haaf J.M., Rouder J.N., Does every study? Implementing ordinal constraint in meta-analysis, Psychol Methods, (2021); 
Heck W.D., Gronau F.Q., Wagenmakers E.J., metaBMA: Bayesian Model Averaging for Random and Fixed Effects Meta-Analysis, (2019); 
Mathur M.B., Van der Weele T.J., Finding common ground in meta-analysis “wars” on violent video games, Perspect Psychol Sci, 14, 4, pp. 705-708, (2019); 
Carter E.C., McCullough M.E., Publication bias and the limited strength model of self-control: has the evidence for ego depletion been overestimated?, Front Psychol, 5, (2014); 
Moreno S.G., Sutton A.J., Turner E.H., Et al., Novel methods to deal with publication biases: secondary analysis of antidepressant trials in the FDA trial registry database and related journal publications, BMJ, 339, (2009); 
Stanley T.D., Limitations of PET-PEESE and other meta-analysis methods, Soc Psychol Personal Sci, 8, 5, pp. 581-591, (2017); 
Jeffreys H., Theory of Probability, (1961); 
Ritchie S.J., Wiseman R., French C.C., Failing the future: three unsuccessful attempts to replicate Bem's ‘Retroactive Facilitation of Recall’ effect, PLoS One, 7, 3, (2012); 
Galak J., LeBoeuf R.A., Nelson L.D., Simmons J.P., Correcting the past: failures to replicate psi, J Pers Soc Psychol, 103, 6, pp. 933-948, (2012); 
Schlitz M., Bem D.J., Marcusson-Clavertz D., Et al., Two replication studies of a time-reversed (psi) priming task and the role of expectancy in reaction times, J Sci Explor, 35, 1, pp. 65-90, (2021); 
Wagenmakers E.J., Wetzels R., Borsboom D., Maas V., Kievit R.A., An agenda for purely confirmatory research, Perspect Psychol Sci, 7, 6, pp. 632-638, (2012); 
Francis G., Too good to be true: publication bias in two prominent studies from experimental psychology, Psychon Bull Rev, 19, 2, pp. 151-156, (2012); 
Schimmack U., The ironic effect of significant results on the credibility of multiple-study articles, Psychol Methods, 17, 4, pp. 551-566, (2012); 
Alcock J., Back from the future: parapsychology and the Bem affair, Skept Inq, 35, 2, pp. 31-39, (2011); 
Hoogeveen S., Sarafoglou A., Wagenmakers E.J., Laypeople can predict which social-science studies will be replicated successfully, Adv Methods Pract Psychol Sci, 3, 3, pp. 267-285, (2020); 
Wagenmakers E.J., Wetzels R., Borsboom D., Van Der Maas H.L., Why psychologists must change the way they analyze their data: the case of psi: comment on Bem (2011), J Pers Soc Psychol, 100, 3, pp. 426-432, (2011); 
Schimmack U., Why psychologists should not change the way they analyze their data: The devil is in the default prior; 
Schimmack U., My email correspondence with Daryl J. Bem about the data for his 2011 article “Feeling the future”; 
Rouder J.N., Morey R.D., A Bayes factor meta-analysis of Bem's ESP claim, Psychon Bull Rev, 18, 4, pp. 682-689, (2011); 
Aczel B., Palfi B., Szollosi A., Et al., Quantifying support for the null hypothesis in psychology: an empirical investigation, Adv Methods Pract Psychol Sci, 1, 3, pp. 357-366, (2018); 
Goodman S., A dirty dozen: twelve p-value misconceptions, Semin Hematol, 45, pp. 135-140, (2008); 
Maier M., Bartos F., Oh M., Wagenmakers E.J., Shanks D., Harris A., Publication bias in research on construal level theory, PsyArXiv Preprints, (2022); 
Maier M., Bartos F., Stanley T.D., Shanks D.R., Harris J.L.A., Wagenmakers E.J., No evidence for nudging after adjusting for publication bias, Proc Natl Acad Sci, 119, (2022); 
Graham J., Haidt J., Nosek B.A., Liberals and conservatives rely on different sets of moral foundations, J Pers Soc Psychol, 96, 5, pp. 1029-1046, (2009); 
Kivikangas J.M., Fernandez-Castilla B., Jarvela S., Ravaja N., Lonnqvist J.E., Moral foundations and political orientation: systematic review and meta-analysis, Psychol Bull, 147, 1, pp. 55-94, (2021); 
Klein R.A., Vianello M., Hasselman F., Et al., Many labs 2: investigating variation in replicability across samples and settings, Adv Methods Pract Psychol Sci, 1, 4, pp. 443-490, (2018); 
Alinaghi N., Reed W.R., Meta-analysis and publication bias: how well does the FAT-PET-PEESE procedure work?, Res Synth Methods, 9, 2, pp. 285-311, (2018); 
Ioannidis J.P., Baas J., Klavans R., Boyack K.W., A standardized citation metrics author database annotated for scientific field, PLoS Biol, 17, 8, (2019); 
Bartos F., Maier M., Quintana D., Wagenmakers E.J., Adjusting for publication bias in JASP and R-selection models, PET-PEESE, and robust Bayesian meta-analysis, Adv Methods Pract Psychol Sci; 
Gronau Q.F., Ly A., Wagenmakers E.J., Informed Bayesian t-tests, Am Stat, 74, 2, pp. 137-143, (2020); 
JASP (Version 0.15) [Computer software], (2021); 
Ly A., van den Bergh D., Bartos F., Wagenmakers E.J., Bayesian inference with JASP, ISBA Bull, 28, pp. 7-15, (2021)#FRF#
