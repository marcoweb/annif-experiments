#ITI#Leveraging natural language processing to support automated assessment and feedback for student open responses in mathematics#FTI#
#IRE# Background: Teachers often rely on the use of open-ended questions to assess students' conceptual understanding of assigned content. Particularly in the context of mathematics; teachers use these types of questions to gain insight into the processes and strategies adopted by students in solving mathematical problems beyond what is possible through more close-ended problem types. While these types of problems are valuable to teachers, the variation in student responses to these questions makes it difficult, and time-consuming, to evaluate and provide directed feedback. It is a well-studied concept that feedback, both in terms of a numeric score but more importantly in the form of teacher-authored comments, can help guide students as to how to improve, leading to increased learning. It is for this reason that teachers need better support not only for assessing students' work but also in providing meaningful and directed feedback to students. Objectives: In this paper, we seek to develop, evaluate, and examine machine learning models that support automated open response assessment and feedback. Methods: We build upon the prior research in the automatic assessment of student responses to open-ended problems and introduce a novel approach that leverages student log data combined with machine learning and natural language processing methods. Utilizing sentence-level semantic representations of student responses to open-ended questions, we propose a collaborative filtering-based approach to both predict student scores as well as recommend appropriate feedback messages for teachers to send to their students. Results and Conclusion: We find that our method outperforms previously published benchmarks across three different metrics for the task of predicting student performance. Through an error analysis, we identify several areas where future works may be able to improve upon our approach#FRE#
#IPC# automated assessment; feedback recommendation; natural language processing; open responses; sentence embeddings; similarity#FPC#
#IRF# Abou-Assaleh T., Cercone N., Keselj V., Sweidan R., N-gram-based detection of new malicious code. In proceedings of the 28th annual international computer software and applications conference, 2004. COMPSAC 2004, volume 2, p. 41-42, (2004); 
Attali Y., Burstein J., Automated essay scoring with e-rater V.2, The Journal of Technology, Learning and Assessment, 4, 3, pp. 2-29, (2006); 
Baral S., Botelho A., Erickson J., Benachamardi P., Heffernan N., Improving automated scoring of student open responses in mathematics. In proceedings of the fourteenth international conference on educational data mining, Paris, France, (2021); 
Basu S., Jacobs C., Vanderwende L., Powergrading: A clustering approach to amplify human effort for short answer grading, Transactions of the Association for Computational Linguistics, 1, pp. 391-402, (2013); 
Ben-David A., About the relationship between ROC curves and Cohen's kappa, Engineering Applications of Artificial Intelligence, 21, 6, pp. 874-882, (2008); 
Brooks M., Basu S., Jacobs C., Vanderwende L., Divide and correct: using clusters to grade short answers at scale. In proceedings of the first ACM conference on learning@ scale conference, p. 89–98, (2014); 
Buckles S., Siegfried J.J., Using multiple-choice questions to evaluate in-depth learning of economics, The Journal of Economic Education, 37, 1, pp. 48-57, (2006); 
Burrows S., Gurevych I., Stein B., The eras and trends of automatic short answer grading, International Journal of Artificial Intelligence in Education, 25, 1, pp. 60-117, (2015); 
Cavnar W.B., Trenkle J.M., N-gram-based text categorization. In proceedings of SDAIR-94, 3rd annual symposium on document analysis and information retrieval, volume 161175, (1994); 
Cer D., Yang Y., Yi Kong S., Hua N., Limtiaco N., John R.S., Constant N., Guajardo-Cespedes M., Yuan S., Tar C., Universal sentence encoder. arXiv preprint arXiv:1803.11175, (2018); 
Chen T., Guestrin C., Xgboost: a scalable tree boosting system. In proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, p. 785–794, (2016); 
Chi M.T., Leeuw N.D., Chiu M.-H., LaVancher C., Eliciting self-explanations improves understanding, Cognitive Science, 18, 3, pp. 439-477, (1994); 
Corbett A.T., Koedinger K.R., Anderson J.R., Intelligent tutoring systems, (1997); 
Erickson J.A., Botelho A.F., McAteer S., Varatharaj A., Heffernan N.T., The automated grading of student open responses in mathematics. In proceedings of the tenth international conference on learning analytics & amp; knowledge, p. 615–624, (2020); 
Filighera A., Steuer T., Rensing C., Fooling automatic short answer grading systems. In international conference on artificial intelligence in education, p. 177–190, (2020); 
Foltz P.W., Laham D., Landauer T.K., Automated essay scoring: applications to educational technology. In edmedia + innovate learning, p. 939–944, (1999); 
Goularte F.B., Nassar S.M., Fileto R., Saggion H., A text summarization method based on fuzzy rules and applicable to automated assessment, Expert Systems with Applications, 115, pp. 264-275, (2019); 
Graesser A.C., Wiemer-Hastings P., Wiemer-Hastings K., Harter D., Person N., Using latent semantic analysis to evaluate the contributions of students in AutoTutor, Interactive Learning Environments, 8, 2, pp. 129-147, (2000); 
Grenander M., Belfer R., Kochmar E., Serban I.V., St-Hilaire F., Cheung J.C., Deep discourse analysis for generating personalized feedback in intelligent tutor systems. In the 11th symposium on educational advances in artificial intelligence, (2021); 
Grossman J., Lin Z., Sheng H., Wei J.T.Z., Williams J.J., Goel S., Math-bot: transforming online resources for learning math into conversational interactions. AAAI 2019 story-enabled intelligence, (2019); 
Gurung A., Botelho A.F., Thompson R., Sales S., Heffernan N.T., Considerate, unfair, or just fatigued? Examining factors that impact teacher grading. Proceedings of the 30th international conference on computers in education, (2022); 
Hand D.J., Till R.J., A simple generalisation of the area under the ROC curve for multiple class classification problems, Machine Learning, 45, 2, pp. 171-186, (2001); 
Harwath D., Glass J., Deep multimodal semantic embeddings for speech and images. In 2015 IEEE workshop on automatic speech recognition and understanding (ASRU), p. 237–244, (2015); 
Heffernan N.T., Heffernan C.L., The ASSISTments ecosystem: Building a platform that brings scientists and teachers together for minimally invasive research on human learning and teaching, International Journal of Artificial Intelligence in Education, 24, 4, pp. 470-497, (2014); 
Hochreiter S., Schmidhuber J., Long short-term memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); 
Jurman G., Riccadonna S., Visintainer R., Furlanello C., Canberra distance on ranked lists. In proceedings of advances in ranking NIPS 09 workshop, p. 22–27, (2009); 
Kannan A., Kurach K., Ravi S., Kaufmann T., Tomkins A., Miklos B., Corrado G., Lukacs L., Ganea M., Young P., Smart reply: automated response suggestion for email. In proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, p. 955–964, (2016); 
Kehrer P., Kelly K., Heffernan N., Does immediate feedback while doing homework improve learning? In the twenty-sixth international FLAIRS conference, (2013); 
Kramarski B., Zeichner O., Using technology to enhance mathematical reasoning: Effects of feedback and self-regulation learning, Educational Media International, 38, 2-3, pp. 77-82, (2001); 
Ku K.Y., Assessing students' critical thinking performance: Urging for measurements using multi-response format, Thinking Skills and Creativity, 4, 1, pp. 70-76, (2009); 
Lan A.S., Vats D., Waters A.E., Baraniuk R.G., Mathematical language processing: automatic grading and feedback for open response mathematical questions. In proceedings of the second (2015) ACM conference on learning@ scale, p. 167–176, (2015); 
Le Q., Mikolov T., Distributed representations of sentences and documents. In international conference on machine learning, p. 1188–1196, (2014); 
Leacock C., Chodorow M., C-rater: automated scoring of short-answer questions, Computers and the Humanities, 37, 4, pp. 389-405, (2003); 
Manning C.D., Surdeanu M., Bauer J., Finkel J.R., Bethard S., McClosky D., The stanford CoreNLP natural language processing toolkit. In proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations, p. 55–60, (2014); 
Martinez M.E., Cognition and the question of test item format, Educational Psychologist, 34, 4, pp. 207-218, (1999); 
Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, (2013); 
Ocumpaugh J., Baker R., Gowda S., Heffernan N., Heffernan C., Population validity for educational data mining models: A case study in affect detection, British Journal of Educational Technology, 45, 3, pp. 487-501, (2014); 
Pennington J., Socher R., Manning C., Glove: global vectors for word representation. In proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), p. 1532–1543, (2014); 
Ramos J., Using tf-idf to determine word relevance in document queries. In proceedings of the first instructional conference on machine learning, volume 242, p. 133–142, (2003); 
Rasch G., Probabilistic models for some intelligence and attainment tests, (1993); 
Reimers N., Gurevych I., Sentence-bert: sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084, (2019); 
Ringenberg M.A., VanLehn K., Scaffolding problem solving with annotated, worked-out examples to promote deep learning. In international conference on intelligent tutoring systems, p. 625–634, (2006); 
Riordan B., Horbach A., Cahill A., Zesch T., Lee C., Investigating neural architectures for short answer scoring. In proceedings of the 12th workshop on innovative use of NLP for building educational applications, p. 159–168, (2017); 
Roll I., Aleven V., McLaren B.M., Koedinger K.R., Improving students' help-seeking skills using metacognitive feedback in an intelligent tutoring system, Learning and Instruction, 21, 2, pp. 267-280, (2011); 
Roschelle J., Feng M., Murphy R.F., Mason C.A., Online mathematics homework increases student achievement, AERA Open, 2, 4, (2016); 
Sagawa S., Koh P.W., Hashimoto T.B., Liang P., Distributionally robust neural networks for group shifts: on the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, (2019); 
Selent D., Heffernan N., Reducing student hint use by creating buggy messages from machine learned incorrect processes. In international conference on intelligent tutoring systems, p. 674–675, (2014); 
Shen J.T., Yamashita M., Prihar E., Heffernan N., Wu X., Graff B., Lee D., MathBERT: a pre-trained language model for general NLP tasks in mathematics education. arXiv preprint arXiv:2106.07340, (2021); 
Sordoni A., Galley M., Auli M., Brockett C., Ji Y., Mitchell M., Nie J.-Y., Gao J., Dolan B., A neural network approach to context-sensitive generation of conversational responses. arXiv preprint arXiv:1506.06714, (2015); 
Su X., Khoshgoftaar T.M., A survey of collaborative filtering techniques, Advances in Artificial Intelligence, 2009, pp. 1-19, (2009); 
Sultan M.A., Salazar C., Sumner T., Fast and easy short answer grading with high accuracy. In proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies, p. 1070–1075, (2016); 
van Schuur W., Ordinal item response theory: Mokken scale analysis, 169, (2011); 
VanLehn K., The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring systems, Educational Psychologist, 46, 4, pp. 197-221, (2011); 
Zhao S., Zhang Y., Xiong X., Botelho A., Heffernan N., A memory-augmented neural model for automated grading. In proceedings of the fourth (2017) ACM conference on learning@ scale, p. 189–192, (2017)#FRF#
