#ITI#Measuring and classifying students' cognitive load in pen-based mobile learning using handwriting, touch gestural and eye-tracking data#FTI#
#IRE# Abstract: Although the utilization of mobile technologies has recently emerged in various educational settings, limited research has focused on cognitive load detection in the pen-based learning process. This research conducted two experimental studies to investigate what and how multimodal data can be used to measure and classify learners' real-time cognitive load. The results found that it was a promising method to predict learners' cognitive load by analysing their handwriting, touch gestural and eye-tracking data individually and conjunctively. The machine learning approach used in this research achieved a prediction accuracy of 0.86 area under the receiver operating characteristic curve (AUC) and 0.85/0.86 sensitivity/specificity by only using handwriting data, 0.93 AUC and 0.93/0.94 sensitivity/specificity by only using touch gestural data, and 0.94 AUC and 0.94/0.95 sensitivity/specificity by using both the touch gestural and eye-tracking data. The results can contribute to the optimization of cognitive load and the development of adaptive learning systems for pen-based mobile learning. Practitioner notes What is already known about this topic Pen-based mobile learning systems allow natural ways of handwriting and gestural touching, which can facilitate learners' cognitive processes in mobile learning. Behavioural and physiological multimodal data are helpful in detecting learners' real-time cognitive load in mobile learning. The effectiveness of behavioural and physiological multimodal data for measuring cognitive load in pen-based mobile learning is limited investigated. What this paper adds This paper confirms the effectiveness of handwriting and touch gestural multimodal data for measuring pen-based learning cognitive load, in terms of their stroke-, path- and time-based features. This paper explores the potential of eye-tracking data in measuring pen-based learning cognitive load. A combination of behavioural and physiological multimodal data is reported to increase the prediction accuracy for cognitive load measurement. Implications for practice and/or policy Practitioners are suggested to use behavioural and physiological multimodal data individually or conjunctively for measuring cognitive load in pen-based learning. The results provide guides for developing adaptive pen-based learning systems by optimizing the real-time cognitive load#FRE#
#IPC# eye-tracking; handwriting; multimodal learning analytics; pen-based mobile learning; touch gestural#FPC#
#IRF# Agudo-Peregrina A.F., Iglesias-Pradas S., Conde-Gonzalez M.A., Hernandez-Garcia A., Can we predict success from log data in VLEs? Classification of interactions for learning analytics and their relation with performance in VLE-supported F2F and online learning, Computers in Human Behavior, 31, 1, pp. 542-550, (2014); 
Alwahaby H., Cukurova M., Papamitsiou Z., Giannakos M., The evidence of impact and ethical considerations of multimodal learning analytics: A systematic literature review, The multimodal learning analytics handbook, pp. 289-325, (2022); 
Andrade A., Danish J.A., Maltese A.V., A measurement model of gestures in an embodied learning environment: Accounting for temporal dependencies, Journal of Learning Analytics, 4, 3, pp. 18-46, (2017); 
Ashford S.J., Blatt R., VandeWalle D., Reflections on the looking glass: A review of research on feedback-seeking behavior in organizations, Journal of Management, 29, 6, pp. 773-799, (2003); 
Aslan I., Murer M., Fuchsberger V., Fugard A., Tscheligi M., Workload on your fingertips: The influence of workload on touch-based drag and drop, ITS 2013—Proceedings of the 2013 ACM International Conference on Interactive Tabletops and Surfaces, pp. 417-420, (2013); 
Blikstein P., Multimodal learning analytics, Proceedings of the Third International Conference on Learning Analytics and Knowledge, pp. 102-106, (2013); 
Blikstein P., Worsley M., Multimodal learning analytics and education data mining: Using computational technologies to measure complex learning tasks, Journal of Learning Analytics, 3, 2, pp. 220-238, (2016); 
Breiman L., Random forests, Machine Learning, 45, 1, pp. 5-32, (2001); 
Chang C.C., Lin C.J., LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology, 2, 3, pp. 1-27, (2011); 
Chen F., Ruiz N., Choi E., Epps J., Khawaja M.A., Taib R., Yin B., Wang Y., Multimodal behavior and interaction as indicators of cognitive load, ACM Transactions on Interactive Intelligent Systems, 2, 4, pp. 1-36, (2012); 
Chen S., Epps J., Automatic classification of eye activity for cognitive load measurement with emotion interference, Computer Methods and Programs in Biomedicine, 110, 2, pp. 111-124, (2013); 
Chen X.-B., Tablets for informal language learning: Student usage and attitudes, Language Learning & Technology, 17, 1, pp. 20-36, (2013); 
Cortes C., Vapnik V., Support-vector networks, Machine Learning, 20, 3, pp. 273-297, (1995); 
Cukurova M., Zhou Q., Spikol D., Landolfi L., Modelling collaborative problem-solving competence with transparent learning analytics: Is video data enough?, Proceedings of the Tenth International Conference on Learning Analytics & Knowledge, pp. 270-275, (2020); 
Curum B., Khedo K.K., Cognitive load management in mobile learning systems: Principles and theories, Journal of Computers in Education, 8, 1, pp. 109-136, (2021); 
de Greef T., Lafeber H., van Oostendorp H., Lindenberg J., Eye movement as indicators of mental workload to trigger adaptive automation, Foundations of augmented cognition, 5638, (2009); 
Diego-Mas J.A., Garzon-Leal D., Poveda-Bautista R., Alcaide-Marzal J., User-interfaces layout optimization using eye-tracking, mouse movements and genetic algorithms, Applied Ergonomics, 78, pp. 197-209, (2019); 
di Mitri D., Borner D., Scheffel M., Ternier S., Drachsler H., Specht M., Learning pulse: A machine learning approach for predicting performance in self-regulated learning using multimodal data, ACM International Conference Proceeding Series, pp. 188-197, (2017); 
Drigas A.S., Pappas M.A., A review of mobile learning applications for mathematics, International Journal of Interactive Mobile Technologies, 9, 3, pp. 18-23, (2015); 
Ezzahraa F., Bahnasse A., Talea M., Towards a contextual mobile learning deployment: An overview, IJCSNS International Journal of Computer Science and Network Security, 17, 7, pp. 80-88, (2017); 
Freund Y., Schapire R.E., A decision-theoretic generalization of on-line learning and an application to boosting, Journal of Computer and System Sciences, 55, 1, pp. 119-139, (1997); 
Frommel J., Schrader C., Weber M., Towards emotion-based adaptive games: Emotion recognition via input and performance features, CHI PLAY 2018—Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play, pp. 187-199, (2018); 
Giannakos M., Spikol D., di Mitri D., Sharma K., Ochoa X., Hammad R., Introduction to multimodal learning analytics, The multimodal learning analytics handbook, pp. 3-28, (2022); 
Giannakos M.N., Sharma K., Pappas I.O., Kostakos V., Velloso E., Multimodal data as a means to understand the learning experience, International Journal of Information Management, 48, pp. 108-119, (2019); 
Goshima R., Harada F., Shimakawa H., Classifying solving behavior by handwriting on tablets, 2021 13th International Conference on Computer and Automation Engineering, ICCAE 2021, pp. 54-58, (2021); 
Grawemeyer B., Mavrikis M., Holmes W., Gutierrez-Santos S., Wiedmann M., Rummel N., Affective learning: Improving engagement and enhancing learning with affect-aware feedback, User Modeling and User-Adapted Interaction, 27, 1, pp. 119-158, (2017); 
Hoel T., Griffiths D., Chen W., The influence of data protection and privacy frameworks on the design of learning analytics systems, Proceedings of the Seventh International Learning Analytics & Knowledge Conference, pp. 243-252, (2017); 
Hosmer D.W., Lemeshow S., Sturdivant R.X., Applied logistic regression, 398, (2013); 
Hutt S., Krasich K., Mills C., Bosch N., White S., Brockmole J.R., D'Mello S.K., Automated gaze-based mind wandering detection during computerized learning in classrooms, User Modeling and User-Adapted Interaction, 29, 4, pp. 821-867, (2019); 
Iatsun I., Larabi M.-C., Fernandez-Maloigne C., Investigation of visual fatigue/discomfort generated by S3D video using eye-tracking data, Stereoscopic Displays and Applications XXIV, 8648, (2013); 
Kacker R., Maringanti H.B., Personality analysis through handwriting, GSTF Journal on Computing (JoC), 2, 1, pp. 94-97, (2014); 
Kim J.H., Park H., Effects of smartphone-based mobile learning in nursing education: A systematic review and meta-analysis, Asian Nursing Research, 13, 1, pp. 20-29, (2019); 
Klimova B., Impact of mobile learning on students' achievement results, Education Sciences, 9, 2, (2019); 
Larmuseau C., Cornelis J., Lancieri L., Desmet P., Depaepe F., Multimodal learning analytics to investigate cognitive load during online problem solving, British Journal of Educational Technology, 51, 5, pp. 1548-1562, (2020); 
Lee C.B., Hanham J., Kannangara K., Qi J., Exploring user experience of digital pen and tablet technology for learning chemistry: Applying an activity theory lens, Heliyon, 7, 1, (2021); 
Lenskiy A., Paprocki R., Blink rate variability during resting and reading sessions, 2016 IEEE Conference on Norbert Wiener in the 21st Century, 21CW 2016, pp. 90-95, (2016); 
Li Q., Zhang J., Xie X., Luximon Y., How shared online whiteboard supports online collaborative design activities: A social interaction perspective, Lecture Notes in Networks and Systems, 276, pp. 285-293, (2021); 
Lin T., Xie T., Chen Y., Tang N., Automatic cognitive load evaluation using writing features: An exploratory study, International Journal of Industrial Ergonomics, 43, 3, pp. 210-217, (2013); 
Macedonia M., Embodied learning: Why at school the mind needs the body, Frontiers in psychology, 10, (2019); 
Mock P., Gerjets P., Tibus M., Trautwein U., Moller K., Rosenstiel W., Using touchscreen interaction data to predict cognitive workload, ICMI 2016—Proceedings of the 18th ACM International Conference on Multimodal Interaction, pp. 349-356, (2016); 
Motiwalla L.F., Mobile learning: A framework and evaluation, Computers and Education, 49, 3, pp. 581-596, (2007); 
Mulyani M.A., Razzaq A., Lestari S., Ridho Z., Anshari M., Smartphone and mobile learning to support experiential learning, 2019 International Conference on Electrical Engineering and Computer Science (ICECOS), pp. 6-9, (2019); 
Mutlu-Bayraktar D., Cosgun V., Altan T., Cognitive load in multimedia learning environments: A systematic review, Computers and Education, 141, (2019); 
Mutlu-Bayraktar D., Ozel P., Altindis F., Yilmaz B., Relationship between objective and subjective cognitive load measurements in multimedia learning, Interactive Learning Environments, 31, pp. 1322-1334, (2020); 
Nguyen Q., Huptych M., Rienties B., Using temporal analytics to detect inconsistencies between learning design and students' behaviours, Journal of Learning Analytics, 5, 3, pp. 120-135, (2018); 
Oviatt S., Hang K., Zhou J., Yu K., Chen F., Dynamic handwriting signal features predict domain expertise, ACM Transactions on Interactive Intelligent Systems, 8, 3, pp. 1-21, (2018); 
Paas F.G.W.C., Training strategies for attaining transfer of problem-solving skill in statistics: A cognitive-load approach, Journal of Educational Psychology, 84, pp. 429-434, (1992); 
Papamitsiou Z., Economides A.A., Learning analytics for smart learning environments: A meta-analysis of empirical research results from 2009 to 2015, Learning, design, and technology, pp. 1-23, (2016); 
Pei B., Xing W., Wang M., Academic development of multimodal learning analytics: A bibliometric analysis, Interactive Learning Environments, 31, pp. 3543-3561, (2021); 
Prieto L.P., Sharma K., Kidzinski L., Rodriguez-Triana M.J., Dillenbourg P., Multimodal teaching analytics: Automated extraction of orchestration graphs from wearable sensor data, Journal of Computer Assisted Learning, 34, 2, pp. 193-203, (2018); 
Pu P., Pazzani M.J., Andre E., Riecken D., IUI 2011 : Feb. 13-16, 2011, Palo Alto, CA, USA, (2011); 
Rogers J.W., Cox J.R., Integrating a single tablet PC in chemistry, engineering, and physics courses, Journal of College Science Teaching, 37, 3, pp. 34-39, (2008); 
Schrader C., Kalyuga S., Linking students' emotions to engagement and writing performance when learning Japanese letters with a pen-based tablet: An investigation based on individual pen pressure parameters, International Journal of Human-Computer Studies, 135, (2020); 
Sharma K., Giannakos M., Multimodal data capabilities for learning: What can multimodal data tell us about learning?, British Journal of Educational Technology, 51, 5, pp. 1450-1484, (2020); 
Sharma K., Papamitsiou Z., Giannakos M., Building pipelines for educational data using AI and multimodal analytics: A “grey-box” approach, British Journal of Educational Technology, 50, 6, pp. 3004-3031, (2019); 
Souchet A.D., Philippe S., Lourdeaux D., Leroy L., Measuring visual fatigue and cognitive load via eye tracking while learning with virtual reality head-mounted displays: A review, International Journal of Human-Computer Interaction, 38, 9, pp. 801-824, (2022); 
Spikol D., Ruffaldi E., Dabisias G., Cukurova M., Supervised machine learning in multimodal learning analytics for estimating success in project-based learning, Journal of Computer Assisted Learning, 34, 4, pp. 366-377, (2018); 
Sweller J., Element interactivity and intrinsic, extraneous, and germane cognitive load, Educational Psychology Review, 22, 2, pp. 123-138, (2010); 
Sweller J., van Merrienboer J.J.G., Paas3 F.G.W.C., Cognitive architecture and instructional design, Educational Psychology Review, 10, 3, pp. 251-296, (1998); 
Tian F., Fan X., Fan J., Zhu Y., Gao J., Wang D., Bi X., Wang H., What can gestures tell? Detecting motor impairment in early Parkinson's from common touch gestural interactions, Conference on Human Factors in Computing Systems—Proceedings, (2019); 
Traxler J., Current state of mobile learning, Mobile learning: Transforming the delivery of education and training, pp. 9-24, (2009); 
van Schaack A., A review of scientific evidence demonstrating the effectiveness of smartpen technologies for improving teaching and learning, (2009); 
Verbert K., Ochoa X., De Croon R., Dourado R.A., De Laet T., Learning analytics dashboards: The past, the present and the future, Proceedings of the Tenth International Conference on Learning Analytics & Knowledge, pp. 35-40, (2020); 
Verrel J., Lovden M., Schellenbach M., Schaefer S., Lindenberger U., Interacting effects of cognitive load and adult age on the regularity of whole-body motion during treadmill walking, Psychology and Aging, 24, pp. 75-81, (2009); 
Wang J.-Y., Wu H.-K., Chien S.-P., Hwang F.-K., Hsu Y.-S., Designing applications for physics learning: Facilitating high school students' conceptual understanding by using tablet PCS, Journal of Educational Computing Research, 51, 4, pp. 441-458, (2015); 
Woolf B.P., Building intelligent interactive tutors: Student-centered strategies for revolutionizing e-learning, (2009); 
Yu K., Epps J., Chen F., Cognitive load evaluation of handwriting using stroke-level features, International Conference on Intelligent User Interfaces, Proceedings IUI, pp. 423-426, (2011); 
Yu K., Epps J., Chen F., Mental workload classification via online writing features, Proceedings of the International Conference on Document Analysis and Recognition, ICDAR, pp. 1110-1114, (2013); 
Zagermann J., Pfeil U., Reiterer H., Measuring cognitive load using eye tracking technology in visual computing, ACM International Conference Proceeding Series, 24-October-2016, pp. 78-85, (2016); 
Zhou J., Yu K., Chen F., Wang Y., Arshad S.Z., Multimodal behavioral and physiological signals as indicators of cognitive load, The handbook of multimodal-multisensor interfaces: Signal processing, architectures, and detection of emotion and cognition, 2, pp. 287-329, (2018); 
Zu T., Hutson J., Loschky L.C., Rebello N.S., Use of eye-tracking technology to investigate cognitive load theory, arXiv, pp. 472-475, (2018)#FRF#
