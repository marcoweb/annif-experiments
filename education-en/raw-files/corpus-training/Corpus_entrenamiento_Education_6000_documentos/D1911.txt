#ITI#Keep Me in the Loop: Real-Time Feedback with Multimodal Data#FTI#
#IRE# This paper describes the CPR Tutor, a real-time multimodal feedback system for cardiopulmonary resuscitation (CPR) training. The CPR Tutor detects training mistakes using recurrent neural networks. The CPR Tutor automatically recognises and assesses the quality of the chest compressions according to five CPR performance indicators. It detects training mistakes in real-time by analysing a multimodal data stream consisting of kinematic and electromyographic data. Based on this assessment, the CPR Tutor provides audio feedback to correct the most critical mistakes and improve the CPR performance. The mistake detection models of the CPR Tutor were trained using a dataset from 10 experts. Hence, we tested the validity of the CPR Tutor and the impact of its feedback functionality in a user study involving additional 10 participants. The CPR Tutor pushes forward the current state of the art of real-time multimodal tutors by providing: (1) an architecture design, (2) a methodological approach for delivering real-time feedback using multimodal data and (3) a field study on real-time feedback for CPR training. This paper details the results of a field study by quantitatively measuring the impact of the CPR Tutor feedback on the performance indicators and qualitatively analysing the participants’ questionnaire answers#FRE#
#IPC# Cardiopulmonary resuscitation; Intelligent tutoring systems; Multimodal data; Real-time feedback; Recurrent neural networks#FPC#
#IRF# Ahuja K., Agarwal Y., Kim D., Xhakaj F., Varga V., Xie A., Zhang S., Townsend J.E., Harrison C., Ogan A., EduSense: Practical Classroom Sensing at Scale, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 3, 3, pp. 1-26, (2019); 
Alqahtani F., Ramzan N., Comparison and efficacy of synergistic intelligent tutoring systems with human physiological response, Sensors (Switzerland), 19, 3, (2019); 
Arroyo I., Cooper D.G., Burleson W., Woolf B.P., Muldner K., Christopherson R., Emotion sensors go to school, Frontiers in Artificial Intelligence and Applications, 200, 1, pp. 17-24, (2009); 
Blikstein P., Worsley M., Multimodal learning analytics and education data mining: using computational technologies to measure complex learning tasks, Journal of Learning Analytics, 3, 2, pp. 220-238, (2016); 
Bloom B.S., Taxonomy of educational objectives handbook 1: cognitive domain, (1956); 
Chan M.C.E., Ochoa X., Clarke D., Multimodal Learning Analytics in a Laboratory Classroom, Machine Learning Paradigms: Advances in Learning Analytics, Intelligent Systems Reference Library, pp. 131-156, (2020); 
Crescenzi-Lanna L., Multimodal Learning Analytics research with young children: A systematic review, British Journal of Educational Technology, 51, 5, pp. 1485-1504, (2020); 
Cukurova M., Kent C., Luckin R., Artificial intelligence and multimodal data in the service of human decision-making: A case study in debate tutoring, British Journal of Educational Technology Pp Bjet., (2019); 
Cukurova M., Giannakos M., Martinez-Maldonado R., The promise and challenges of multimodal learning analytics, British Journal of Educational Technology, 51, 5, pp. 1441-1449, (2020); 
Davaris M., Wijewickrema S., Zhou Y., Piromchai P., Bailey J., Kennedy G., O'Leary S., The importance of automated real-Time performance feedback in virtual reality temporal bone surgery training, Artificial Intelligence in Education, Springer International Publishing, Cham, Lecture Notes in Computer Science, (2019); 
Di Mitri D., Schneider J., Specht M., Drachsler H., From signals to knowledge: A conceptual model for multimodal learning analytics, Journal of Computer Assisted Learning, 34, 4, pp. 338-349, (2018); 
Di Mitri D., Schneider J., Klemke R., Specht M., Drachsler H., Read Between the Lines: An Annotation Tool for Multimodal Data for Learning, In: Proceedings of the 9Th International Conference on Learning Analytics & Knowledge, pp. 51-60, (2019); 
Di Mitri D., Schneider J., Specht M., Drachsler H., Detecting mistakes in CPR training with multimodal data and neural networks, Sensors (Switzerland), 19, 14, pp. 1-20, (2019); 
Di Mitri D., Schneider J., Specht M., Drachsler H., Multimodal Pipeline: A generic approach for handling multimodal data for supporting learning, . in AIMA4EDU Workshop in IJCAI 2019 Ai-Based Multimodal Analytics for Understanding Human Learning in Real-World Educational Contexts, pp. 2-4, (2019); 
Di Mitri D., Schneider J., Trebing K., Sopka S., Specht M., Drachsler H., Real-Time Multimodal Feedback with the CPR Tutor, Artificial Intelligence in Education (AIED’2020), pp. 141-152, (2020); 
Dick-Smith F., Elliott D., Martinez-Maldonado R., Power T., Comparing Real-Time Feedback Modalities to Support Optimal Cardiopulmonary Resuscitation for Undergraduate Nursing Students: A Quasi-Experimental Cross-Over Simulation Study, Clinical Simulation in Nursing, 44, pp. 59-67, (2020); 
D'Mello S., Kory J., A Review and Meta-Analysis of Multimodal Affect Detection Systems, ACM Computing Surveys, 47, 3, pp. 1-43, (2015); 
D'Mello S., Jackson T., Craig S., Morgan B., Chipman P., White H., Person N., Kort B., El Kaliouby R., Picard R.W., Graesser A., Autotutor detects and responds to learners affective and cognitive states, IEEE Transactions on Education, 48, 4, pp. 612-618, (2008); 
Dumas B., Lalanne D., Oviatt S., Multimodal Interfaces: A Survey of Principles, Models and Frameworks, Human Machine Interaction, 5440, pp. 3-26, (2009); 
Echeverria J., Santos O., KUMITRON: Artificial Intelligence System to Monitor Karate Fights that Synchronize Aerial Images with Physiological and Inertial Signals, 26Th International Conference on Intelligent User Interfaces, Association for Computing Machinery, pp. 37-39, (2021); 
Emerson A., Cloude E.B., Azevedo R., Lester J., Multimodal learning analytics for game-based learning, British Journal of Educational Technology, 51, 5, pp. 1505-1526, (2020); 
Giannakos M.N., Sharma K., Pappas I.O., Kostakos V., Velloso E., Multimodal data as a means to understand the learning experience, International Journal of Information Management, 48, February, pp. 108-119, (2019); 
Hochreiter S., Schmidhuber J., Long Short-Term Memory, Neural Computation, 9, 8, pp. 1735-1780, (1997); 
Hutt S., Krasich K., Mills C., Bosch N., White S., Brockmole J.R., D'Mello S.K., Automated gaze-based mind wandering detection during computerized learning in classrooms, User Modeling and User-Adapted Interaction, 29, 4, pp. 821-867, (2019); 
Juntunen M.L., Embodied Learning Through and for Collaborative Multimodal Composing: A Case in a Finnish Lower Secondary Music Classroom, International Journal of Education & the Arts, 21, 29, (2020); 
Koedinger K., Corbett A., Cognitive Tutors: Technology Bringing Learning Science to the Classroom, (2006); 
Krishnaswamy N., Pustejovsky J., Multimodal Continuation-Style Architectures for Human-Robot Interaction, (2019); 
Levin M., McKechnie T., Khalid S., Grantcharov T.P., Goldenberg M., Automated Methods of Technical Skill Assessment in Surgery: A Systematic Review, Journal of Surgical Education, 76, 6, pp. 1629-1639, (2019); 
Limbu B., Schneider J., Klemke R., Specht M., Augmentation of practice with expert performance data: Presenting a calligraphy use case, In 3Rd International Conference on Smart Learning Ecosystem and Regional Development - the Interplay of Data, Technology, Place and People, pp. 1-13, (2018); 
Limbu B.H., Jarodzka H., Klemke R., Specht M., Using sensors and augmented reality to train apprentices using recorded expert performance: A systematic literature review. Educational Research Review 25, pp. 1-22, (2018); 
Lins C., Eckhoff D., Klausen A., Hellmers S., Hein A., Fudickar S., Cardiopulmonary resuscitation quality parameters from motion capture data using Differential Evolution fitting of sinusoids, Applied Soft Computing Journal, 79, pp. 300-309, (2019); 
Luengo V., Mufti-Alchawafa D., Target the controls during the problem solving activity, a process to produce adapted epistemic feedbacks in ill- defined domains, CEUR Workshop Proceedings, (2013); 
Martinez-Maldonado R., Echeverria V., Santos O.C., Santos A.D.P.D., Yacef K., Physical learning analytics, Proceedings of the 8Th International Conference on Learning Analytics and Knowledge, pp. 375-379, (2018); 
Martinez-Maldonado R., Hernandez-Leo D., Pardo A., Preface to the special issue on learning analytics and personalised support across spaces, User Modeling and User-Adapted Interaction, 29, 4, pp. 751-758, (2019); 
Mat Sanusi K.A., Mitri D.D., Limbu B., Klemke R., Table Tennis Tutor: Forehand Strokes Classification Based on Multimodal Data and Neural Networks, Sensors, 21, 9, (2021); 
Ochoa X., Worsley M., Augmenting Learning Analytics with Multimodal Sensory Data, Journal of Learning Analytics, 3, 2, pp. 213-219, (2016); 
Olsen J.K., Sharma K., Rummel N., Aleven V., Temporal analysis of multimodal data to predict collaborative learning outcomes, British Journal of Educational Technology, 51, 5, pp. 1527-1547, (2020); 
Oviatt S., Schuller B., Cohen P.R., Sonntag D., Potamianos G., Kruger A., The Handbook of Multimodal-Multisensor Interfaces: Foundations, User Modeling, and Common Modality Combinations - Volume 2, (2018); 
Perkins G.D., Handley A.J., Koster R.W., Castren M., Smyth M.A., Olasveengen T., Monsieurs K.G., Raffay V., Grasner J.T.T., Wenzel V., Ristagno G., Soar J., Bossaert L.L., Caballero A., Cassan P., Granja C., Sandroni C., Zideman D.A., Nolan J.P., Greif R., European Resuscitation Council Guidelines for Resuscitation 2015: Section 2. Adult basic life support and automated external defibrillation, Resuscitation, 95, pp. 81-99, (2015); 
Prieto L., Sharma K., Kidzinski L., Rodriguez-Triana M., Dillenbourg P., Multimodal teaching analytics: Automated extraction of orchestration graphs from wearable sensor data, Journal of Computer Assisted Learning, (2018); 
Santos O.C., Training the body: the potential of AIED to support personalized motor skills learning, International Journal of Artificial Intelligence in Education, 26, 2, pp. 730-755, (2016); 
Santos O.C., Artificial Intelligence in Psychomotor Learning: Modeling Human Motion from Inertial Sensor Data, International Journal on Artificial Intelligence Tools, 28, 4, pp. 1940006-1940006, (2019); 
Santos O.C., Corbi A., Can Aikido Help With the Comprehension of Physics? A First Step Towards the Design of Intelligent Psychomotor Systems for STEAM Kinesthetic Learning Scenarios, IEEE Access, 7, pp. 176458-176469, (2019); 
Schneider J., Borner D., van Rosmalen P., Specht M., Presentation Trainer, your Public Speaking Multimodal Coach, (2015); 
Schneider J., Di Mitri D., Limbu B., Drachsler H., Multimodal Learning Hub: A Tool for Capturing Customizable Multimodal Learning Experiences, In Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), pp. 45-58, (2018); 
Soderstrom N.C., Bjork R.A., Learning Versus Performance: An Integrative Review, Perspectives on Psychological Science, 10, 2, pp. 176-199, (2015); 
Spikol D., Ruffaldi E., Dabisias G., Cukurova M., Supervised machine learning in multimodal learning analytics for estimating success in project-based learning, Journal of Computer Assisted Learning, 34, 4, pp. 366-377, (2018); 
Astrom K.J., Murray R.M., Feedback systems: an introduction for scientists and engineers second edition, (2021); 
Taylor R.H., Menciassi A., Fichtinger G., Fiorini P., Dario P., Medical Robotics and Computer-Integrated Surgery. In: Springer Handbook of Robotics, Springer International Publishing, Cham, pp. 1657-1684, (2016); 
Vohra R., Goel K., Sahoo J.K., Modeling temporal dependencies in data using a DBN-LSTM, 2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA), pp. 1-4, (2015); 
Worsley M., Blikstein P., A Multimodal Analysis of Making, International Journal of Artificial Intelligence in Education, 28, 3, pp. 385-419, (2018); 
Zhu G., Xing W., Costa S., Scardamalia M., Pei B., Exploring emotional and cognitive dynamics of Knowledge Building in grades 1 and 2, User Modeling and User-Adapted Interaction, 29, 4, pp. 789-820, (2019)#FRF#
