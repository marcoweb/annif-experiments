#ITI#Incorporating AI and learning analytics to build trustworthy peer assessment systems#FTI#
#IRE# Peer assessment has been recognised as a sustainable and scalable assessment method that promotes higher-order learning and provides students with fast and detailed feedback on their work. Despite these benefits, some common concerns and criticisms are associated with the use of peer assessments (eg, scarcity of high-quality feedback from peer student-assessors and lack of accuracy in assigning a grade to the assessee) that raise questions about their trustworthiness. Consequently, many instructors and educational institutions have been anxious about incorporating peer assessment into their teaching. This paper aims to contribute to the growing literature on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn can increase their trustworthiness and adoption. In particular, we present and evaluate our AI-assisted and analytical approaches that aim to (1) offer guidelines and assistance to student-assessors during individual reviews to provide better feedback, (2) integrate probabilistic and text analysis inference models to improve the accuracy of the assigned grades, (3) develop feedback on reviews strategies that enable peer assessors to review the work of each other, and (4) employ a spot-checking mechanism to assist instructors in optimally overseeing the peer assessment process. Practitioner notes What is already known about this topic Engaging students in peer assessment has been demonstrated to have various benefits. However, there are some common concerns associated with employing peer assessment that raise questions about their trustworthiness as an assessment item. What this paper adds Methods and processes on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn, can increase their trustworthiness and adoption. Implications for practice Presentation of a systematic approach for development, deployment and evaluation of AI and analytics approaches in peer assessment systems#FRE#
#IPC# human centred AI; learning analytics; peer assessment#FPC#
#IRF# Abdi S., Khosravi H., Sadiq S., Modelling learners in crowdsourcing educational systems, International Conference on Artificial Intelligence in Education, pp. 3-9, (2020); 
Abdi S., Khosravi H., Sadiq S., Darvishi A., Open learner models for multi-activity educational systems, Artificial Intelligence in Education, pp. 11-17, (2021); 
Ahmad N., Bull S., Do students trust their open learner models?, International Conference on Adaptive Hypermedia and Adaptive Web-Based Systems, pp. 255-258, (2008); 
Arrieta A.B., Diaz-Rodriguez N., Del Ser J., Bennetot A., Tabik S., Barbado A., Garcia S., Gil-Lopez S., Molina D., Benjamins R., Chatila R., Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI, Information Fusion, 58, pp. 82-115, (2020); 
Ashenafi M.M., Peer-assessment in higher education-twenty-first century practices, challenges and the way forward, Assessment & Evaluation in Higher Education, 42, pp. 226-251, (2017); 
Baars M., Wijnia L., de Bruin A., Paas F., The relation between student's effort and monitoring judgments during learning: A meta-analysis, Educational Psychology Review, 32, pp. 1-24, (2020); 
Baker R.S., Hawn A., Algorithmic bias in education, International Journal of Artificial Intelligence in Education, 31, pp. 1-41, (2021); 
Bodily R., Kay J., Aleven V., Jivet I., Davis D., Xhakaj F., Verbert K., Open learner models and learning analytics dashboards: a systematic review, Proceedings of the 8th international conference on learning analytics and knowledge, pp. 41-50, (2018); 
Carless D., Trust, distrust and their impact on assessment reform, Assessment & Evaluation in Higher Education, 34, pp. 79-89, (2009); 
Carless D., Feedback loops and the longer-term: Towards feedback spirals, Assessment & Evaluation in Higher Education, 44, pp. 705-714, (2019); 
Carless D., From teacher transmission of information to student feedback literacy: Activating the learner role in feedback processes, Active Learning in Higher Education, (2020); 
Carless D., Boud D., The development of student feedback literacy: Enabling uptake of feedback, Assessment & Evaluation in Higher Education, 43, pp. 1315-1325, (2018); 
Cho K., MacArthur C., Learning by reviewing, Journal of Educational Psychology, 103, pp. 73-84, (2011); 
Darvishi A., Khosravi H., Sadiq S., Utilising learner sourcing to inform design loop adaptivity, European Conference on Technology Enhanced Learning, pp. 332-346, (2020); 
Darvishi A., Khosravi H., Sadiq S., Employing peer review to evaluate the quality of student generated content at scale: A trust propagation approach, Proceedings of the Eighth ACM Conference on Learning@ Scale, pp. 139-150, (2021); 
Darvishi A., Khosravi H., Sadiq S., Weber B., Neurophysiological Measurements in Higher Education: A Systematic Literature Review, International Journal of Artificial Intelligence in Education, (2021); 
Darvishi A., Khosravi H., Abdi S., Sadiq S., Gasevic D., Incorporating training, self-monitoring and AI-assistance to improve peer feedback quality, Proceedings of the Ninth ACM Conference on Learning @ Scale (L@S '22), June 1–3, 2022, New York City, NY, USA, (2022); 
De Alfaro L., Shavlovsky M., CrowdGrader: A tool for crowdsourcing the evaluation of homework assignments, Proceedings of the 45th ACM technical symposium on Computer science education, pp. 415-420, (2014); 
Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, arXiv preprint arXiv:1810.04805, (2018); 
Duret D., Christley R., Denny P., Senior A., Collaborative learning with peerwise, Research in Learning Technology, 26, pp. 1-13, (2018); 
El Maarry K., Guntzer U., Balke W.-T., A majority of wrongs doesn't make it right-On crowdsourcing quality for skewed domain tasks, International Conference on Web Information Systems Engineering, pp. 293-308, (2015); 
Er E., Dimitriadis Y., Gasevic D., Collaborative peer feedback and learning analytics: Theory-oriented design for supporting class-wide interventions, Assessment & Evaluation in Higher Education, 46, pp. 169-190, (2021); 
Gardner J., Brooks C., Baker R., Evaluating the fairness of predictive student models through slicing analysis, Proceedings of the 9th international conference on learning analytics & knowledge, pp. 225-234, (2019); 
Gasevic D., Kovanovic V., Joksimovic S., Piecing the learning analytics puzzle: A consolidated model of a field of research and practice, Learning: Research and Practice, 3, pp. 63-78, (2017); 
Gyamfi G., Hanna B.E., Khosravi H., The effects of rubrics on evaluative judgement: A randomised controlled experiment, Assessment & Evaluation in Higher Education, 47, 1, pp. 126-143, (2021); 
Hadwin A., Jarvela S., Miller M., Self-regulation, co-regulation, and shared regulation in collaborative learning environments, Handbook of self-regulation of learning and performance, pp. 83-106, (2017); 
Han Y., Wu W., Yan Y., Zhang L., Human-machine hybrid peer grading in SPOCs, IEEE Access, 8, pp. 220922-220934, (2020); 
Hassan T., Trust and trustworthiness in social recommender systems, Companion Proceedings of The 2019 World Wide Web Conference, pp. 529-532, (2019); 
Henderson M., Phillips M., Ryan T., Boud D., Dawson P., Molloy E., Mahoney P., Conditions that enable effective feedback, Higher Education Research & Development, 38, pp. 1401-1416, (2019); 
Huisman B., Admiraal W., Pilli O., van de Ven M., Saab N., Peer assessment in MOOCs: The relationship between peer reviewers' ability and authors' essay performance, British Journal of Educational Technology, 49, pp. 101-110, (2018); 
Jansen R.S., Van Leeuwen A., Janssen J., Jak S., Kester L., Self-regulated learning partially mediates the effect of self-regulated learning interventions on achievement in higher education: A meta-analysis, Educational Research Review, 28, (2019); 
Joyner D.A., Scaling expert feedback: Two case studies, Proceedings of the Fourth (2017) ACM Conference on Learning@ Scale, pp. 71-80, (2017); 
Kao G.Y.M., Enhancing the quality of peer review by reducing student “free riding”: Peer assessment with positive interdependence, British Journal of Educational Technology, 44, pp. 112-124, (2013); 
Khosravi H., Kitto K., Joseph W., Ripple: A crowdsourced adaptive platform for recommendation of learning activities, Journal of Learning Analytics, 6, pp. 91-105, (2019); 
Khosravi H., Demartini G., Sadiq S., Gasevic D., Charting the design and analytics agenda of learnersourcing systems, LAK21: 11th International Learning Analytics and Knowledge Conference (LAK21), pp. 32-42, (2021); 
Khosravi H., Gyamfi G., Hanna B.E., Lodge J., Abdi S., Bridging the gap between theory and empirical research in evaluative judgment, Journal of Learning Analytics, 8, 3, pp. 117-132, (2021); 
Koenig A., The algorithms know me and i know them: Using student journals to uncover algorithmic literacy awareness, Computers and Composition, 58, (2020); 
Kulkarni C.E., Bernstein M.S., Klemmer S.R., PeerStudio: rapid peer feedback emphasizes revision and improves performance, Proceedings of the second (2015) ACM conference on learning@ scale, pp. 75-84, (2015); 
Lahza H., Khosravi H., Demartini G., Gasevic D., Effects of technological interventions for self-regulation: A control experiment in learnersourcing, LAK22: 12th International Learning Analytics and Knowledge Conference, (2022); 
Lakens D., Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and anovas, Frontiers in Psychology, 4, (2013); 
Lee W., Huang C.H., Chang C.W., Wu M.K.D., Chuang K.T., Yang P.A., Effective quality assurance for data labels through crowdsourcing and domain expert collaboration, 21st International Conference on Extending Database Technology, EDBT 2018, pp. 646-649, (2018); 
Levy H., Robinson M., Stochastic dominance: Investment decision making under uncertainty, 34, (2006); 
Li H., Xiong Y., Hunter C.V., Guo X., Tywoniw R., Does peer assessment promote student learning? A meta-analysis, Assessment & Evaluation in Higher Education, 45, pp. 193-211, (2020); 
Li L., Liu X., Steckelberg A.L., Assessor or assessee: How student learning improves by giving and receiving peer feedback, British Journal of Educational Technology, 41, pp. 525-536, (2010); 
Li Y., Jin X., Hu Q., Jiang Q., Zhao W., Oubibi M., An empirical study on the influence of co-regulation on deep learning under crowdsourcing knowledge construction, 2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD), pp. 526-530, (2021); 
Lin J.-W., Effects of an online team project-based learning environment with group awareness and peer evaluation on socially shared regulation of learning and self-regulated learning, Behaviour & Information Technology, 37, pp. 445-461, (2018); 
Liu N.-F., Carless D., Peer feedback: The learning element of peer assessment, Teaching in Higher Education, 11, pp. 279-290, (2006); 
Lockey S., Gillespie N., Curtis C., Trust in artificial intelligence: Australian insights, (2020); 
Long D., Magerko B., What is AI literacy? Competencies and design considerations, Proceedings of the 2020 CHI conference on human factors in computing systems, pp. 1-16, (2020); 
Lundstrom K., Baker W., To give is better than to receive: The benefits of peer review to the reviewer's own writing, Journal of Second Language Writing, 18, pp. 30-43, (2009); 
Manso-Vazquez M., Llamas-Nistal M., A monitoring system to ease self-regulated learning processes, IEEE Revista Iberoamericana de Tecnologias del Aprendizaje, 10, pp. 52-59, (2015); 
Martinez-Maldonado R., Gasevic D., Echeverria V., Fernandez Nieto G., Swiecki Z., Buckingham Shum S., What do you mean by collaboration analytics? A conceptual model, Journal of Learning Analytics, 8, pp. 126-153, (2021); 
Matcha W., Gasevic D., Pardo A., A systematic review of empirical studies on learning analytics dashboards: A self-regulated learning perspective, IEEE Transactions on Learning Technologies, 13, 2, pp. 226-245, (2019); 
Moon T., The expectation-maximization algorithm, IEEE Signal Processing Magazine, 13, pp. 47-60, (1996); 
Napoles C., Sakaguchi K., Post M., Tetreault J., Ground truth for grammatical error correction metrics, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pp. 588-593, (2015); 
Negi S., Asooja K., Mehrotra S., Buitelaar P., A study of suggestions in opinionated texts and their automatic detection, Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics, pp. 170-178, (2016); 
Nejad A.M., Mahfoodh O.H.A., Assessment of oral presentations: Effectiveness of self-, peer-, and teacher assessments, International Journal of Instruction, 12, pp. 615-632, (2019); 
Nelson M.M., Schunn C.D., The nature of feedback: How different types of peer feedback affect writing performance, Instructional Science, 37, pp. 375-401, (2009); 
Nicol D., Thomson A., Breslin C., Rethinking feedback practices in higher education: A peer review perspective, Assessment & Evaluation in Higher Education, 39, pp. 102-122, (2014); 
Pare D.E., Joordens S., Peering into large lectures: Examining peer and expert mark agreement using peerscholar, an online peer assessment tool, Journal of Computer Assisted Learning, 24, pp. 526-540, (2008); 
Patchan M.M., Schunn C.D., Understanding the benefits of providing peer feedback: How students respond to peers' texts of varying quality, Instructional Science, 43, pp. 591-614, (2015); 
Patchan M.M., Schunn C.D., Clark R.J., Accountability in peer assessment: Examining the effects of reviewing grades on peer ratings and peer feedback, Studies in Higher Education, 43, pp. 2263-2278, (2018); 
Polisda Y., Peer review: A strategy to improve students' academic essay writings, English Franca: Academic Journal of English Language and Education, 1, pp. 45-60, (2017); 
Purchase H., Hamer J., Peer-review in practice: Eight years of Aropä, Assessment & Evaluation in Higher Education, 43, pp. 1146-1165, (2018); 
Ramachandran L., Gehringer E.F., Yadav R.K., Automated assessment of the quality of peer reviews using natural language processing techniques, International Journal of Artificial Intelligence in Education, 27, pp. 534-581, (2017); 
Reimers N., Gurevych I., Sentence-BERT: Sentence embeddings using Siamese BERT-networks, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 3982-3992, (2019); 
Roberts K., Dowell A., Nie J.-B., Attempting rigour and replicability in thematic analysis of qualitative research data; a case study of codebook development, BMC Medical Research Methodology, 19, pp. 1-8, (2019); 
Robinson S.L., Trust and breach of the psychological contract, Administrative Science Quarterly, 41, pp. 574-599, (1996); 
Shin D., User perceptions of algorithmic decisions in the personalized AI system: Perceptual evaluation of fairness, accountability, transparency, and explainability, Journal of Broadcasting & Electronic Media, 64, pp. 541-565, (2020); 
Shnayder V., Agarwal A., Frongillo R., Parkes D.C., Informed truthfulness in multi-task peer prediction, Proceedings of the 2016 ACM Conference on Economics and Computation, pp. 179-196, (2016); 
Shoham N., Pitman A., Open versus blind peer review: Is anonymity better than transparency?, BJPsych Advances, 27, pp. 247-254, (2021); 
Sommers N., Responding to student writing, College Composition and Communication, 33, pp. 148-156, (1982); 
Sridharan B., Tai J., Boud D., Does the use of summative peer assessment in collaborative group work inhibit good judgement?, Higher Education, 77, pp. 853-870, (2019); 
Tai J., Ajjawi R., Boud D., Dawson P., Panadero E., Developing evaluative judgement: Enabling students to make decisions about the quality of work, Higher Education, 76, pp. 467-481, (2018); 
Tao D., Cheng J., Yu Z., Yue K., Wang L., Domain-weighted majority voting for crowdsourcing, IEEE Transactions on Neural Networks and Learning Systems, 30, pp. 163-174, (2018); 
Topping K., Self and peer assessment in school and university: Reliability, validity and utility, Optimising new modes of assessment: In search of qualities and standards, pp. 55-87, (2003); 
Topping K.J., Peer assessment, Theory into Practice, 48, pp. 20-27, (2009); 
Topping K.J., Peers as a source of formative assessment, Handbook of formative assessment, pp. 73-86, (2010); 
Urena R., Kou G., Dong Y., Chiclana F., Herrera-Viedma E., A review on trust propagation and opinion dynamics in social networks and group decision making frameworks, Information Sciences, 478, pp. 461-475, (2019); 
Wang W., An B., Jiang Y., Optimal spot-checking for improving evaluation accuracy of peer grading systems, Proceedings of the AAAI Conference on Artificial Intelligence, 32, 1, (2018); 
Wang W., An B., Jiang Y., Optimal spot-checking for improving the evaluation quality of crowdsourcing: Application to peer grading systems, IEEE Transactions on Computational Social Systems, 7, pp. 940-955, (2020); 
Wind D.K., Jorgensen R.M., Hansen S.L., Peer feedback with peergrade, ICEL 2018 13th International Conference on e-Learning, (2018); 
Wright J.R., Thornton C., Leyton-Brown K., Mechanical TA: Partially automated high-stakes peer grading, Proceedings of the 46th ACM Technical Symposium on Computer Science Education, pp. 96-101, (2015); 
Xiong W., Litman D., Automatically predicting peer-review helpfulness, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pp. 502-507, (2011); 
Yang M., Tai M., Lim C.P., The role of e-portfolios in supporting productive learning, British Journal of Educational Technology, 47, pp. 1276-1286, (2016); 
Yang T.-Y., Baker R.S., Studer C., Heffernan N., Lan A.S., Active learning for student affect detection, Proceedings of the 12th International Conference on Educational Data Mining, EDM 2019, Montréal, Canada, July 2-5, 2019. International Educational Data Mining Society (IEDMS) 2019, pp. 208-217, (2019); 
Yeager D.S., Purdie-Vaughns V., Garcia J., Apfel N., Brzustoski P., Master A., Hessert W.T., Williams M.E., Cohen G.L., Breaking the cycle of mistrust: Wise interventions to provide critical feedback across the racial divide, Journal of Experimental Psychology: General, 143, pp. 804-824, (2014); 
Yu F.-Y., Wu C.-P., Different identity revelation modes in an online peer-assessment learning environment: Effects on perceptions toward assessors, classroom climate and learning activities, Computers & Education, 57, pp. 2167-2177, (2011); 
Zheng L., Huang R., The effects of sentiments and co-regulation on group performance in computer supported collaborative learning, The Internet and Higher Education, 28, pp. 59-67, (2016); 
Zhu Q., Carless D., Dialogue within peer feedback processes: Clarification and negotiation of meaning, Higher Education Research & Development, 37, pp. 883-897, (2018); 
Zimmerman B.J., Bonner S., Kovach R., Developing self-regulated learners: Beyond achievement to self-efficacy, (1996); 
Zong Z., Schunn C.D., Wang Y., What aspects of online peer feedback robustly predict growth in students' task performance?, Computers in Human Behavior, 124, (2021)#FRF#
