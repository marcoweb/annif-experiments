#ITI#How Days Between Tests Impacts Alternate Forms Reliability in Computerized Adaptive Tests#FTI#
#IRE# An essential question when computing test–retest and alternate forms reliability coefficients is how many days there should be between tests. This article uses data from reading and math computerized adaptive tests to explore how the number of days between tests impacts alternate forms reliability coefficients. Results suggest that the highest alternate forms reliability coefficients were obtained when the second test was administered at least 2 to 3 weeks after the first test. Even though reliability coefficients after this amount of time were often similar, results suggested a potential tradeoff in waiting longer to retest as student ability tended to grow with time. These findings indicate that if keeping student ability similar is a concern that the best time to retest is shortly after 3 weeks have passed since the first test. Additional analyses suggested that alternate forms reliability coefficients were lower when tests were shorter and that narrowing the first test ability distribution of examinees also impacted estimates. Results did not appear to be largely impacted by differences in first test average ability, student demographics, or whether the student took the test under standard or extended time. It is suggested that for math and reading tests, like the ones analyzed in this article, the optimal retest interval would be shortly after 3 weeks have passed since the first test.#FRE#
#IPC# alternate forms; computerized adaptive testing; reliability; test–retest; time interval#FPC#
#IRF# Standards for educational and psychological testing, (2014); 
Backhaus J., Junghanns K., Broocks A., Riemann D., Hohagen F., Test-retest reliability and validity of the Pittsburgh Sleep Quality Index in primary insomnia, Journal of Psychosomatic Research, 53, 3, pp. 737-740, (2002); 
Bardhoshi G., Erford B.T., Processes and procedures for estimating score reliability and precision, Measurement and Evaluation in Counseling and Development, 50, 4, pp. 256-263, (2017); 
Capraro R.M., Capraro M.M., Myers-Briggs Type Indicator score reliability across studies: A meta-analytic reliability generalization study, Educational and Psychological Measurement, 62, 4, pp. 590-602, (2002); 
Cattell R.B., The psychometric properties of tests: Consistency, validity, and efficiency, Functional psychological testing, pp. 54-78, (1986); 
Cattell R.B., Eber H.W., Tatsuoka M.M., Handbook for the Sixteen Personality Factor Questionnaire (16PF), (1970); 
Chmielewski M., Watson D., What is being assessed and why it matters: The impact of transient error on trait research, Journal of Personality and Social Psychology, 97, 1, pp. 186-202, (2009); 
Crocker L., Algina J., Introduction to classical and modern test theory, (1986); 
Cronbach L.J., Coefficient alpha and the internal structure of tests, Psychometrika, 16, pp. 297-334, (1951); 
de Ayala R.J., Vonderharr-Carlson D.J., Kim D., Assessing the reliability of the Beck Anxiety Inventory scores, Educational and Psychological Measurement, 65, 5, pp. 742-756, (2005); 
Deyo R.A., Diehr P., Patrick D.L., Reproducibility and responsiveness of health status measures: Statistics and strategies for evaluation, Controlled Clinical Trials, 12, (1991); 
Erford B.T., Johnson E., Bardoshi G., Meta-analysis of the English version of the Beck Depression Inventory–Second Edition, Measurement and Evaluation in Counseling and Development, 49, 1, pp. 3-33, (2016); 
Frisbee D.A., Reliability of scores from teacher-made tests, Educational Measurement: Issues and Practice, 7, 1, pp. 25-33, (1988); 
Gnambs T., A meta-analysis of dependability coefficients (test-retest reliabilities) for measures of the Big Five, Journal of Research in Personality, 52, 1, pp. 20-28, (2014); 
Haertel E.H., Reliability, Educational measurement, pp. 65-110, (2006); 
Haladyna T.M., Rodriguez M.C., Developing and validating test items, (2013); 
Hedges L.V., Olkin I., Statistical methods for meta-analysis, (1985); 
Kieffer K.M., MacDonald G., Exploring factors that affect score reliability and validity in the Ways of Coping questionnaire reliability coefficients: A meta-analytic reliability generalization study, Journal of Individual Differences, 32, 1, pp. 26-38, (2011); 
Kingsbury G.G., Zara A.R., Procedures for selecting items for computerized adaptive tests, Applied Measurement in Education, 2, 4, pp. 359-375, (1989); 
Liao C.-W., Qu Y., Alternate forms test–retest reliability and test score changes for the TOEIC® speaking and writing tests (TOEIC Compendium TC-10-10), (2010); 
Marx R.G., Menezes A., Horovitz L., Jones E.C., Warren R.F., A comparison of two time intervals for test-retest reliability of health status instruments, Journal of Clinical Epidemiology, 56, 8, pp. 730-735, (2003); 
Mehrens W.A., Lehmann I.J., Measurement and evaluation in education and psychology, (1991); 
Nunnally J., Bernstein I.H., Psychometric theory, (1994); 
Popham W.J., Assessment for educational leaders, (2006); 
R: A language and environment for statistical computing, (2020); 
Rasch G., Probabilistic models for some intelligence and attainment tests, (1960); 
Raykov T., Marcoulides G.A., Introduction to psychometric theory, (2011); 
Trajkovic G., Starcevic V., Latas M., Lestarevic M., Ille T., Bukumiric Z., Marinkovic J., Reliability of the Hamilton Rating Scale for Depression: A meta-analysis over a period of 49 years, Psychiatry Research, 189, 1, pp. 1-9, (2011); 
Traub R.E., Rowley G.L., Understanding reliability, Educational Measurement: Issues and Practice, 10, 1, pp. 37-45, (1991); 
Vacha-Haase T., Kogan L.R., Tani C.R., Woodall R.A., Reliability generalization: Exploring variation of reliability coefficients of MMPI clinical scale scores, Educational and Psychological Measurement, 61, 1, pp. 45-59, (2001); 
Viswesvaran C., Ones D., Measurement error in “Big Five Factors” personality assessment: Reliability generalization across studies and measures, Educational and Psychological Measurement, 60, 2, pp. 224-235, (2000); 
Watson D., Stability versus change, dependability versus error: Issues in the assessment of personality over time, Journal of Research in Personality, 38, 4, pp. 319-350, (2004); 
Yeo S., Kim D., Branum-Martin L., Wayman M.M., Espin C.A., Assessing the reliability of curriculum-based measurement: An application of latent growth modeling, Journal of School Psychology, 50, 2, pp. 275-292, (2012); 
Yen W.M., Fitzpatrick A.R., Item Response Theory, Educational measurement, pp. 111-153, (2006); 
Yin P., Fan X., Assessing the reliability of Beck Depression Inventory scores: Reliability generalization across studies, Educational and Psychological Measurement, 60, 2, pp. 201-223, (2000)#FRF#
