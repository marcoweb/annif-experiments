#ITI#Computer-based performance approach for critical thinking assessment in children#FTI#
#IRE# Background: Critical thinking (CT) has been identified as one of the key skills in the modern world. Despite a variety of CT assessment systems for secondary school and higher education, there is a shortage of CT assessments for children. Aims: To fill the gap, we developed a computer-based performance assessment (CPBA) of CT with automatic scoring. In the study, we analysed: (1) To what extent is the internal structure of the critical thinking assessment tool confirmed? (2) What are the patterns of students' behaviour within the CPBA? (3) To what extent is the convergent validity of the CPBA supported?. Sample and Methods: The sample consists of 1689 students, aged 9–11 years. To answer the research questions, the following quantitative data analysis methods were selected. The Bayesian Network was applied to investigate the internal structure. Latent Class Analysis was used to investigate the patterns of students' behaviour. To verify the convergent validity, the students were asked to solve the standardized math and language literacy tests. Results and Conclusions: The theoretically expected internal structure of the CPBA was confirmed: the two-factor structure (the Analysis of information and the Making inferences subskills of CT) describes the data appropriately. Moreover, CT was described not as a list but as a sequence of cognitive operations. Four different strategies that lead to different results of CT were revealed. A weak positive correlation between the results of the CPBA and the achievement tests confirmed the test validity#FRE#
#IPC# computer-based performance assessment; critical thinking#FPC#
#IRF# The Australian Curriculum. Australian Curriculum, Assessment and Reporting Authority (ACARA), (2010); 
Almond R., DiBello L., Jenkins F., Mislevy R., Senturk D., Steinberg L., Yan D., Models for conditional probability tables in educational assessment, Artificial intelligence and statistics 2001, pp. 137-143, (2001); 
Almond R.G., Mislevy R.J., Steinberg L.S., Yan D., Williamson D.M., Bayesian networks in educational assessment, (2015); 
Anthony C.J., Styck K.M., Cooke E., Martel J.R., Frye K.E., Evaluating the impact of rater effects on behavior rating scale score validity and utility, School Psychology Review, 51, 1, pp. 25-39, (2022); 
Bailin S., Critical thinking and science education, Science & Education, 11, 4, pp. 361-375, (2002); 
Bowers L., Huisingh R., LoGiudice C., Test of problem solving 3-elementary (TOPS-3 elementary), (2005); 
Brooks S.P., Gelman A., General methods for monitoring convergence of iterative simulations, Journal of Computational and Graphical Statistics, 7, 4, pp. 434-455, (1998); 
Cannel J., Hopkin J., Kitchen B., Critical Thinking in Practice. Practice guide. Geographical Association, (2008); 
Care E., Griffin P., Wilson M., Assessment and teaching of 21st century skills: Research and applications, (2017); 
Clark S.L., Muthen B., Relating latent class analysis results to variables not included in the analysis, (2009); 
Culbertson M.J., Bayesian networks in educational assessment: The state of the field, Applied Psychological Measurement, 40, 1, pp. 3-21, (2016); 
de Klerk S., Veldkamp B.P., Eggen T.J.H.M., Psychometric analysis of the performance data of simulation-based assessment: A systematic review and a Bayesian network example, Computers & Education, 85, pp. 23-34, (2015); 
DiCerbo K.E., Xu Y., Levy R., Lai E., Holland L., Modeling student cognition in digital and nondigital assessment environments, Educational Assessment, 22, 4, pp. 275-297, (2017); 
Ennis R.H., Critical thinking and subject specificity: Clarification and needed research, Educational Researcher, 18, 3, pp. 4-10, (1989); 
Ennis R.H., Critical thinking assessment, Theory Into Practice, 32, 3, pp. 179-186, (1993); 
Ennis R.H., Chattin G., An annotated list of English-language critical thinking tests, (2018); 
Ennis R.H., Millman J., Tomko T.N., Cornell critical thinking tests level X & Level Z Manual, (revised), (2005); 
Facione P.A., Critical thinking: A statement of expert consensus for purposes of educational assessment and instruction, (1990); 
Gelerstein D., del Rio R., Nussbaum M., Chiuminatto P., Lopez X., Designing and implementing a test for measuring critical thinking in primary school, Thinking Skills and Creativity, 20, pp. 40-49, (2016); 
Greiff S., Niepel C., Scherer R., Martin R., Understanding students' performance in a computer-based assessment of complex problem solving: An analysis of behavioral data from computer-generated log files, Computers in Human Behavior, 61, pp. 36-46, (2016); 
Griffin P., McGaw B., Care E., Assessment and teaching of 21st century skills, (2012); 
Halpern D.F., Assessing the effectiveness of critical thinking instruction, The Journal of General Education, 50, 4, pp. 270-286, (2001); 
He Q., von Davier M., Greiff S., Steinhauer E.W., Borysewicz P.B., Collaborative problem solving measures in the Programme for international student assessment (PISA), Innovative assessment of collaboration, pp. 95-111, (2017); 
Hitchcock D., Critical thinking, The stanford encyclopedia of philosophy (fall 2020), (2020); 
Hoyt W.T., Rater bias in psychological research: When is it a problem and what can we do about it?, Psychological Methods, 5, pp. 64-86, (2000); 
Hyytinen H., Nissinen K., Ursin J., Toom A., Lindblom-Ylanne S., Problematising the equivalence of the test results of performance-based critical thinking tests for undergraduate students, Studies in Educational Evaluation, 44, pp. 1-8, (2015); 
Ku K.Y.L., Assessing students' critical thinking performance: Urging for measurements using multi-response format, Thinking Skills and Creativity, 4, 1, pp. 70-76, (2009); 
Lai E.R., Critical thinking: A literature review, (2011); 
Leach S.M., Immekus J.C., French B.F., Hand B., The factorial validity of the Cornell critical thinking tests: A multi-analytic approach, Thinking Skills and Creativity, 37, (2020); 
Levy R., Xu Y., Yel N., Svetina D., A standardized generalized dimensionality discrepancy measure and a standardized model-based covariance for dimensionality assessment for multidimensional models, Journal of Educational Measurement, 52, 2, pp. 144-158, (2015); 
Lipman M., Critical thinking—What can it Be?, Educational Leadership, 46, 1, pp. 38-43, (1988); 
Liu O.L., Frankel L., Roohr K.C., Assessing critical thinking in higher education: Current state and directions for next-generation assessment, ETS Research Report Series, 2014, 1, pp. 1-23, (2014); 
Mislevy R.J., Almond R.G., Lukas J.F., A brief introduction to evidence-centered design, ETS Research Report Series, 2003, 1, pp. i-29, (2003); 
National counsil of educational research and training, (2005); 
Norris S.P., Synthesis of research on critical thinking, Educational Leadership, 42, 8, pp. 40-45, (1985); 
The NPEC sourcebook on assessment, volume 1: Definitions and assessment methods for critical thinking, problem solving, and writing, (2000); 
Paul R., Elder L., Critical thinking, (1990); 
Ren X., Tong Y., Peng P., Wang T., Critical thinking predicts academic performance beyond general cognitive ability: Evidence from adults and children, Intelligence, 82, (2020); 
Shavelson R.J., Zlatkin-Troitschanskaia O., Beck K., Schmidt S., Marino J.P., Assessment of university Students' critical thinking: Next generation performance assessment, International Journal of Testing, 19, 4, pp. 337-362, (2019); 
Sinharay S., Model diagnostics for Bayesian networks, Journal of Educational and Behavioral Statistics, 31, 1, pp. 1-33, (2006); 
Sternberg R.J., Critical thinking: Its nature, measurement, and improvement, ERIC Document Reproduction Service No. ED, 272, (1986); 
Sturtz S., Ligges U., Gelman A., R2WinBUGS: A package for running WinBUGS from R, Journal of Statistical Software, 12, pp. 1-16, (2005); 
Uglanova I., Model criticism of Bayesian networks in educational assessment: A systematic review, Practical Assessment, Research, and Evaluation, 26, 1, (2021); 
Wang D., Liu H., Hau K.T., Automated and interactive game-based assessment of critical thinking, Education and Information Technologies, 27, 4, pp. 4553-4575, (2022); 
Yen W.M., Scaling performance assessments: Strategies for managing local item dependence, Journal of Educational Measurement, 30, 3, pp. 187-213, (1993)#FRF#
