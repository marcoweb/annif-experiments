#ITI#A comparison of machine learning methods to find clinical trials for inclusion in new systematic reviews from their PROSPERO registrations prior to searching and screening#FTI#
#IRE# Searching for trials is a key task in systematic reviews and a focus of automation. Previous approaches required knowing examples of relevant trials in advance, and most methods are focused on published trial articles. To complement existing tools, we compared methods for finding relevant trial registrations given a International Prospective Register of Systematic Reviews (PROSPERO) entry and where no relevant trials have been screened for inclusion in advance. We compared SciBERT-based (extension of Bidirectional Encoder Representations from Transformers) PICO extraction, MetaMap, and term-based representations using an imperfect dataset mined from 3632 PROSPERO entries connected to a subset of 65,662 trial registrations and 65,834 trial articles known to be included in systematic reviews. Performance was measured by the median rank and recall by rank of trials that were eventually included in the published systematic reviews. When ranking trial registrations relative to PROSPERO entries, 296 trial registrations needed to be screened to identify half of the relevant trials, and the best performing approach used a basic term-based representation. When ranking trial articles relative to PROSPERO entries, 162 trial articles needed to be screened to identify half of the relevant trials, and the best-performing approach used a term-based representation. The results show that MetaMap and term-based representations outperformed approaches that included PICO extraction for this use case. The results suggest that when starting with a PROSPERO entry and where no trials have been screened for inclusion, automated methods can reduce workload, but additional processes are still needed to efficiently identify trial registrations or trial articles that meet the inclusion criteria of a systematic review#FRE#
#IPC# clinical trials; information retrieval; systematic reviews#FPC#
#IRF# Pham B., Bagheri E., Rios P., Et al., Improving the conduct of systematic reviews: a process mining perspective, J Clin Epidemiol, 103, pp. 101-111, (2018); 
Page M.J., Moher D., Mass production of systematic reviews and meta-analyses: an exercise in mega-silliness?: commentary: mass production of systematic reviews and meta-analyses, Milbank Q, 94, 3, pp. 515-519, (2016); 
Dunn A.G., Bourgeois F.T., Is it time for computable evidence synthesis?, J Am Med Inform Assoc, 27, 6, pp. 972-975, (2020); 
Pieper D., Antoine S.L., Neugebauer E.A.M., Eikermann M., Up-to-dateness of reviews is often neglected in overviews: a systematic review, J Clin Epidemiol, 67, 12, pp. 1302-1308, (2014); 
Zarin D.A., Tse T., Sharing Individual Participant Data (IPD) within the context of the Trial Reporting System (TRS), PLoS Med, 13, 1, (2016); 
Mortensen M.L., Adam G.P., Trikalinos T.A., Kraska T., Wallace B.C., An exploration of crowdsourcing citation screening for systematic reviews, Res Syn Meth, 8, 3, pp. 366-386, (2017); 
Pianta M.J., Makrai E., Verspoor K.M., Cohn T.A., Downie L.E., Crowdsourcing critical appraisal of research evidence (CrowdCARE) was found to be a valid approach to assessing clinical research quality, J Clin Epidemiol, 104, pp. 8-14, (2018); 
Ouzzani M., Hammady H., Fedorowicz Z., Elmagarmid A., Rayyan—a web and mobile app for systematic reviews, Syst Rev, 5, 1, (2016); 
Wallace B.C., Small K., Brodley C.E., Lau J., Trikalinos T.A., Deploying an interactive machine learning system in an evidence-based practice center: abstrackr. In: Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium [Internet]. ACM; 2012:819-824; 
Smalheiser N.R., Swanson D.R., Using ARROWSMITH: a computer-assisted approach to formulating and assessing scientific hypotheses, Comput Methods Programs Biomed, 57, 3, pp. 149-153, (1998); 
Shekelle P.G., Shetty K., Newberry S., Maglione M., Motala A., Machine learning versus standard techniques for updating searches for systematic reviews: a diagnostic accuracy study, Ann Intern Med, 167, 3, pp. 213-215, (2017); 
Tsafnat G., Glasziou P., Choong M.K., Dunn A., Galgani F., Coiera E., Systematic review automation technologies, Syst Rev, 3, 1, (2014); 
Beller E., Clark J., Tsafnat G., Et al., Making progress with the automation of systematic reviews: principles of the International Collaboration for the Automation of Systematic Reviews (ICASR), Syst Rev, 7, 1, (2018); 
O'Connor A.M., Tsafnat G., Gilbert S.B., Et al., Still moving toward automation of the systematic review process: a summary of discussions at the third meeting of the International Collaboration for Automation of Systematic Reviews (ICASR), Syst Rev, 8, 1, (2019); 
Arno A., Thomas J., Wallace B., Marshall I.J., McKenzie J.E., Elliott J.H., Accuracy and efficiency of machine learning–assisted risk-of-bias assessments in “real-world” systematic reviews: a noninferiority randomized controlled trial, Ann Intern Med, 175, 7, pp. 1001-1009, (2022); 
Adam G.P., Wallace B.C., Trikalinos T.A., Semi-automated tools for systematic searches, Meta-Research [Internet], pp. 17-40, (2022); 
de Bruijn B., Carini S., Kiritchenko S., Martin J., Sim I., Automated information extraction of key trial design elements from clinical trial publications, AMIA Annu Symp Proc, 6, 2008, pp. 141-145, (2008); 
Kiritchenko S., de Bruijn B., Carini S., Martin J., Sim I., ExaCT: automatic extraction of clinical trial characteristics from journal publications, BMC Med Inform Decis Mak, 10, 1, (2010); 
Marshall I.J., Wallace B.C., Toward systematic review automation: a practical guide to using machine learning tools in research synthesis, Syst Rev, 8, 1, (2019); 
Jonnalagadda S.R., Goyal P., Huffman M.D., Automating data extraction in systematic reviews: a systematic review, Syst Rev, 4, 1, (2015); 
Nakagawa S., Dunn A.G., Lagisz M., Et al., A new ecosystem for evidence synthesis, Nat Ecol Evol, 4, 4, pp. 498-501, (2020); 
Elliott J.H., Turner T., Clavisi O., Et al., Living systematic reviews: an emerging opportunity to narrow the evidence-practice gap, PLoS Med, 11, 2, (2014); 
Millard T., Synnot A., Elliott J., Green S., McDonald S., Turner T., Feasibility and acceptability of living systematic reviews: results from a mixed-methods evaluation, Syst Rev, 8, 1, (2019); 
Thomas J., Noel-Storr A., Marshall I., Et al., Living systematic reviews: 2. Combining human and machine effort, J Clin Epidemiol, 91, pp. 31-37, (2017); 
Martin P., Surian D., Bashir R., Bourgeois F.T., Dunn A.G., Trial2rev: combining machine learning and crowd-sourcing to create a shared space for updating systematic reviews, JAMIA Open, 2, 1, pp. 15-22, (2019); 
O'Mara-Eves A., Thomas J., McNaught J., Miwa M., Ananiadou S., Using text mining for study identification in systematic reviews: a systematic review of current approaches, Syst Rev, 4, 1, (2015); 
Wallace B.C., Trikalinos T.A., Lau J., Brodley C., Schmid C.H., Semi-automated screening of biomedical citations for systematic reviews, BMC Bioinformatics, 11, 1, (2010); 
Pradhan R., Hoaglin D.C., Cornell M., Liu W., Wang V., Yu H., Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses, J Clin Epidemiol, 105, pp. 92-100, (2019); 
Huser V., Cimino J.J., Linking ClinicalTrials.gov and PubMed to track results of interventional human clinical trials, PloS One, 8, 7, (2013); 
Surian D., Dunn A.G., Orenstein L., Bashir R., Coiera E., Bourgeois F.T., A shared latent space matrix factorisation method for recommending new trial evidence for systematic review updates, J Biomed Inform, 79, pp. 32-40, (2018); 
Wallace B.C., Kuiper J., Sharma A., Zhu M.B., Marshall I.J., Extracting PICO sentences from clinical trial reports using supervised distant supervision, J Mach Learn Res, 17, (2016); 
Liu S., Replication data for: a comparison of machine learning methods for recommending clinical trials for inclusion in new systematic reviews [Internet]. Harvard Dataverse; 2022; 
Liu S., Clinical trial recommendation for systematic reviews [Internet]. Zenodo; 2022; 
Chen K.Y., Borglund E.M., Postema E.C., Dunn A.G., Bourgeois F.T., Reporting of clinical trial safety results in ClinicalTrials.gov for FDA-approved drugs: a cross-sectional analysis, Clin Trials, 19, 4, pp. 442-451, (2022); 
Liu S., Bourgeois F.T., Dunn A.G., Identifying unreported links between ClinicalTrials.Gov trial registrations and their published results. Research synthesis, Methods, 13, 3, pp. 342-352, (2022); 
Surian D., Bourgeois F.T., Dunn A.G., The automation of relevant trial registration screening for systematic review updates: an evaluation study on a large dataset of ClinicalTrials.Gov registrations, BMC Med Res Methodol, 21, 1, (2021); 
Liu S., Sun Y., Li B., Wang W., Bourgeois F.T., Dunn A.G., Sent2Span: span detection for PICO extraction in the biomedical text without span annotations. In: Findings of the Association for Computational Linguistics: EMNLP 2021 [Internet]. Association for Computational Linguistics; 2021; 
Aronson A.R., Lang F.M., An overview of MetaMap: historical perspective and recent advances, J Am Med Inform Assoc, 17, 3, pp. 229-236, (2010); 
Bui D.D.A., Jonnalagadda S., Del Fiol G., Automatically finding relevant citations for clinical guideline development, J Biomed Inform, 57, pp. 436-445, (2015); 
Wang S., Scells H., Mourad A., Zuccon G., Seed-driven document ranking for systematic reviews: a reproducibility study, Advances in Information Retrieval [Internet], pp. 686-700, (2022); 
Tsafnat G., Dunn A., Glasziou P., Coiera E., The automation of systematic reviews, BMJ, 10, 346, (2013)#FRF#
