#ITI#Position of Correct Option and Distractors Impacts Responses to Multiple-Choice Items: Evidence From a National Test#FTI#
#IRE# Even though the impact of the position of response options on answers to multiple-choice items has been investigated for decades, it remains debated. Research on this topic is inconclusive, perhaps because too few studies have obtained experimental data from large-sized samples in a real-world context and have manipulated the position of both correct response and distractors. Since multiple-choice tests’ outcomes can be strikingly consequential and option position effects constitute a potential source of measurement error, these effects should be clarified. In this study, two experiments in which the position of correct response and distractors was carefully manipulated were performed within a Chilean national high-stakes standardized test, responded by 195,715 examinees. Results show small but clear and systematic effects of options position on examinees’ responses in both experiments. They consistently indicate that a five-option item is slightly easier when the correct response is in A rather than E and when the most attractive distractor is after and far away from the correct response. They clarify and extend previous findings, showing that the appeal of all options is influenced by position. The existence and nature of a potential interference phenomenon between the options’ processing are discussed, and implications for test development are considered.#FRE#
#IPC# academic achievement; distractors; educational measurement; multiple choice; response order; tests#FPC#
#IRF# Ace M.C., Dawis R.V., Item structure as a determinant of item difficulty in verbal analogies, Educational and Psychological Measurement, 33, 1, pp. 143-149, (1973); 
Ambu-Saidi A., Khamis A., An investigation into fixed response questions in science at secondary and tertiary levels, (2000); 
Anderson M.C., Bjork R.A., Bjork E.L., Remembering can cause forgetting: Retrieval dynamics in long-term memory, Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 5, pp. 1063-1087, (1994); 
Attali Y., Bar-Hillel M., Guess where: The position of correct answers in multiple-choice test items as a psychometric variable, Journal of Educational Measurement, 40, 2, pp. 109-128, (2003); 
Bar-Hillel M., Position effects in choice from simultaneous displays: A conundrum solved, Perspectives on Psychological Science, 10, 4, pp. 419-433, (2015); 
Bar-Hillel M., Attali Y., Seek whence: Answer sequences and their consequences in key-balanced multiple-choice tests, The American Statistician, 56, 4, pp. 299-303, (2002); 
Bar-Hillel M., Budescu D., Attali Y., Scoring and keying multiple choice tests: A case study in irrationality, Mind & Society, 4, 1, pp. 3-12, (2005); 
Bolt D.M., Kim N., Wollack J., Pan Y., Eckerly C., Sowles J., A psychometric model for discrete-option multiple-choice items, Applied Psychological Measurement, 44, 1, pp. 33-48, (2020); 
Bresnock A.E., Graves P.E., White N., Multiple-choice testing: Question and response position, The Journal of Economic Education, 20, 3, pp. 239-245, (1989); 
Carnegie J.A., Does correct answer distribution influence student choices when writing multiple choice examinations?, Canadian Journal for the Scholarship of Teaching and Learning, 8, 1, (2017); 
Cizek G.J., The effect of altering the position of options in a multiple-choice examination, Educational and Psychological Measurement, 54, 1, pp. 8-20, (1994); 
Clark E.L., General response patterns to five-choice items, Journal of Educational Psychology, 47, 2, pp. 110-117, (1956); 
Cohen J., Statistical power analysis for the behavioral sciences, (2013); 
Cronbach L.J., Further evidence on response sets and test design, Educational and Psychological Measurement, 10, 1, pp. 3-31, (1950); 
DeVore S., Stewart J., Stewart G., Examining the effects of testwiseness in conceptual physics evaluations, Physical Review Physics Education Research, 12, 2, (2016); 
Fagley N.S., Positional response bias in multiple-choice tests of learning: Its relation to testwiseness and guessing strategy, Journal of Educational Psychology, 79, 1, pp. 95-97, (1987); 
Friel S., Johnstone A.H., Does the position matter?, Education in Chemistry, 16, (1979); 
Gierl M.J., Bulut O., Guo Q., Zhang X., Developing, analyzing, and using distractors for multiple-choice tests in education: A comprehensive review, Review of Educational Research, 87, 6, pp. 1082-1116, (2017); 
Hagenmuller B., On the impact of the response options’ position on item difficulty in multiple-choice-items, European Journal of Psychological Assessment, 37, 4, pp. 290-299, (2021); 
Haladyna T.M., Downing S.M., Construct-irrelevant variance in high-stakes testing, Educational Measurement: Issues and Practice, 23, 1, pp. 17-27, (2004); 
Haladyna T.M., Rodriguez M.C., Guidelines for writing selected-response items, Developing and validating test items, pp. 89-110, (2013); 
Hodson D., Some effects of changes in question structure and sequence on performance in a multiple choice chemistry test, Research in Science & Technological Education, 2, 2, pp. 177-185, (1984); 
Hohensinn C., Baghaei P., Does the position of response options in multiple-choice tests matter?, Psicológica, 38, 1, pp. 93-109, (2017); 
Holzknecht F., McCray G., Eberharter K., Kremmel B., Zehentner M., Spiby R., Dunlea J., The effect of response order on candidate viewing behaviour and item difficulty in a multiple-choice listening test, Language Testing, 38, pp. 41-61, (2020); 
Kiat J.E., Ong A.R., Ganesan A., The influence of distractor strength and response order on MCQ responding, Educational Psychology, 38, 3, pp. 368-380, (2018); 
Kim N., Bolt D.M., Wollack J., Pan Y., Eckerly C., Sowles J., Modeling examinee heterogeneity in discrete option multiple choice items, The annual meeting of the psychometric society, pp. 383-392, (2017); 
Krosnick J.A., Response strategies for coping with the cognitive demands of attitude measures in surveys, Applied Cognitive Psychology, 5, 3, pp. 213-236, (1991); 
Lee C.J., The test taker’s fallacy: How students guess answers on multiple-choice tests, Journal of Behavioral Decision Making, 32, 2, pp. 140-151, (2019); 
Lions S., Monsalve C., Dartnell P., Godoy M.I., Cordova N., Jimenez D., Blanco M.P., Ortega G., Lemarie J., The position of distractors in multiple-choice test items: The strongest precede the weakest, Frontiers in Education, 6, (2021); 
Lions S., Monsalve C., Dartnell P., Blanco M.P., Ortega G., Lemarie J., Does the response options placement provide clues to the correct answers in multiple-choice tests?, A systematic review, Applied Measurement in Education, 35, 2, pp. 133-152, (2022); 
Mentzer T.L., Response biases in multiple-choice test item files, Educational and Psychological Measurement, 42, 2, pp. 437-448, (1982); 
Metfessel N.S., Sax G., Systematic biases in the keying of correct responses on certain standardized tests, Educational and Psychological Measurement, 18, 4, pp. 787-790, (1958); 
Paul S.T., Monda S., Olausson S.M., Reed-Daley B., Effects of apophenia on multiple-choice exam performance, SAGE Open, 4, 4, pp. 1-7, (2014); 
Schroeder J., Murphy K.L., Holme T.A., Investigating factors that influence item performance on ACS exams, Journal of Chemical Education, 89, 3, pp. 346-350, (2012); 
Shin J., Bulut O., Gierl M.J., The effect of the most-attractive-distractor location on multiple-choice item difficulty, The Journal of Experimental Education, 88, pp. 643-659, (2020); 
Simon H.A., Rational choice and the structure of the environment, Psychological Review, 63, 2, pp. 129-138, (1956); 
Sonnleitner P., Guill K., Hohensinn C., Effects of correct answer position on multiple-choice item difficulty in educational settings: Where would you go?, (2016); 
Taylor A.K., Violating conventional wisdom in multiple choice test construction, College Student Journal, 39, pp. 141-153, (2005); 
Tellinghuisen J., Sulikowski M.M., Does the answer order matter on multiple-choice exams?, Journal of Chemical Education, 85, 4, pp. 572-575, (2008); 
Wang L., Does rearranging multiple-choice item response options affect item and test performance?, ETS Research Report Series, 2019, 1, pp. 1-14, (2019); 
Wilbur P.H., Positional response set among high school students on multiple-choice tests, Journal of Educational Measurement, 7, 3, pp. 161-163, (1970); 
Willing S., Discrete-option multiple-choice: Evaluating the psychometric properties of a new method of knowledge assessment, (2013)#FRF#
