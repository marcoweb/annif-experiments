#ITI#Sensitivity analysis for the interactive effects of internal bias and publication bias in meta-analyses#FTI#
#IRE# Meta-analyses can be compromised by studies' internal biases (e.g., confounding in nonrandomized studies) as well as publication bias. These biases often operate nonadditively: publication bias that favors significant, positive results selects indirectly for studies with more internal bias. We propose sensitivity analyses that address two questions: (1) “For a given severity of internal bias across studies and of publication bias, how much could the results change?”; and (2) “For a given severity of publication bias, how severe would internal bias have to be, hypothetically, to attenuate the results to the null or by a given amount?” These methods consider the average internal bias across studies, obviating specifying the bias in each study individually. The analyst can assume that internal bias affects all studies, or alternatively that it only affects a known subset (e.g., nonrandomized studies). The internal bias can be of unknown origin or, for certain types of bias in causal estimates, can be bounded analytically. The analyst can specify the severity of publication bias or, alternatively, consider a “worst-case” form of publication bias. Robust estimation methods accommodate non-normal effects, small meta-analyses, and clustered estimates. As we illustrate by re-analyzing published meta-analyses, the methods can provide insights that are not captured by simply considering each bias in turn. An R package implementing the methods is available (multibiasmeta)#FRE#
#IPC# bias analysis; file drawer; internal validity; selective reporting#FPC#
#IRF# Grossman D.C., Bibbins-Domingo K., Curry S.J., Et al., Screening for obesity in children and adolescents: US preventive services task force recommendation statement, JAMA, 317, 23, pp. 2417-2426, (2017); 
Shaneyfelt T., Pyramids are guides not rules: the evolution of the evidence pyramid, BMJ Evid Based Med, 21, 4, pp. 121-122, (2016); 
Button K.S., Ioannidis J.P.A., Mokrysz C., Et al., Power failure: why small sample size undermines the reliability of neuroscience, Nat Rev Neurosci, 14, 5, (2013); 
de Vrieze J., The metawars, Science, 361, pp. 1184-1188, (2018); 
Nelson L.D., Simmons J., Simonsohn U., Psychology's renaissance, Annu Rev Psychol, 69, pp. 511-534, (2018); 
Jin Z.-C., Zhou X.-H., He J., Statistical methods for dealing with publication bias in meta-analysis, Stat Med, 34, 2, pp. 343-360, (2015); 
Marks-Anglin A., Chen Y., A historical review of publication bias, Res Synth Methods, 11, 6, pp. 725-742, (2020); 
Duval S., Tweedie R., Trim and fill: a simple funnel-plot–based method of testing and adjusting for publication bias in meta-analysis, Biometrics, 56, 2, pp. 455-463, (2000); 
Egger M., Smith G.D., Schneider M., Minder C., Bias in meta-analysis detected by a simple, graphical test, BMJ, 315, 7109, pp. 629-634, (1997); 
Citkowicz M., Vevea J.L., A parsimonious weight function for modeling publication bias, Psychol Methods, pp. 28-41, (2017); 
Dear K.B.G., Begg C.B., An approach for assessing publication bias prior to performing a meta-analysis, Stat Sci, 7, pp. 237-245, (1992); 
Hedges L.V., Modeling publication selection effects in meta-analysis, Stat Sci, 7, pp. 246-255, (1992); 
Vevea J.L., Hedges L.V., A general linear model for estimating effect size in the presence of publication bias, Psychometrika, 60, 3, pp. 419-435, (1995); 
Mathur M.B., VanderWeele T.J., Sensitivity analysis for publication bias in meta-analyses, J R Stat Soc Ser C Appl Stat, 69, 5, pp. 1091-1119, (2020); 
Mathur M.B., VanderWeele T.J., Estimating publication bias in meta-analyses of peer-reviewed studies: a meta-meta-analysis across disciplines and journal tiers, Res Synth Methods, 12, 2, pp. 176-191, (2021); 
Goto A., Arah O.A., Goto M., Terauchi Y., Noda M., Severe hypoglycaemia and cardiovascular disease: systematic review and meta-analysis with bias analysis, BMJ, 347, (2013); 
Greenland S., O'Rourke K., Meta-analysis, Modern epidemiology, (2008); 
Turner R.M., Spiegelhalter D.J., Smith G., Thompson S.G., Bias modelling in evidence synthesis, J R Stat Soc A Stat Soc, 172, 1, pp. 21-47, (2009); 
Mathur M.B., VanderWeele T.J., Robust metrics and sensitivity analyses for meta-analyses of heterogeneous effects, Epidemiology, 31, 3, pp. 356-358, (2020); 
Mathur M.B., VanderWeele T.J., Sensitivity analysis for unmeasured confounding in meta-analyses, J Am Stat Assoc, 115, 529, pp. 163-172, (2020); 
Mathur M.B., VanderWeele T.J., Methods to address confounding and other biases in meta-analyses: review and recommendations, Annu Rev Public Health, 43, 1, pp. 19-35, (2021); 
McCandless L.C., Meta-analysis of observational studies with unmeasured confounders, Int J Biostat, 8, 2, pp. 331-368, (2012); 
Ding P., VanderWeele T.J., Sensitivity analysis without assumptions, Epidemiology, 27, 3, pp. 368-377, (2016); 
Hernan M.A., Robins J.M., Letter to the editor of Biometrics, Biometrics, 55, 4, pp. 1316-1317, (1999); 
VanderWeele T.J., Sensitivity analysis: distributional assumptions and confounding assumptions, Biometrics, 64, 2, pp. 645-649, (2008); 
Mathur M.B., Smith L.H., Yoshida K., Ding P., VanderWeele T.J., E-values for effect heterogeneity and approximations for causal interaction, Int J Epidemiol, 51, 4, pp. 1268-1275, (2022); 
Smith L.H., Mathur M.B., VanderWeele T.J., Multiple-bias sensitivity analysis using bounds, Epidemiology, 32, 5, pp. 625-634, (2021); 
Smith L.H., VanderWeele T.J., Bounding bias due to selection, Epidemiology, 30, 4, pp. 509-516, (2019); 
VanderWeele T.J., Li Y., Simple sensitivity analysis for differential measurement error, Am J Epidemiol, 188, 10, pp. 1823-1829, (2019); 
Brodeur A., Le M., Sangnier M., Zylberberg Y., Star wars: the empirics strike back, Am Econ J Appl Econ, 8, 1, pp. 1-32, (2016); 
Jager L.R., Leek J.T., An estimate of the science-wise false discovery rate and application to the top medical literature, Biostatistics, 15, 1, pp. 1-12, (2014); 
John L.K., Loewenstein G., Prelec D., Measuring the prevalence of questionable research practices with incentives for truth telling, Psychol Sci, 23, 5, pp. 524-532, (2012); 
Mathur M., p-hacking in meta-analyses: a formalization and new meta-analytic methods, (2022); 
Head M.L., Holman L., Lanfear R., Kahn A.T., Jennions M.D., The extent and consequences of p-hacking in science, PLoS Biol, 13, 3, (2015); 
Masicampo E.J., Lalande D.R., A peculiar prevalence of p values just below.05, Q J Exp Psychol, 65, 11, pp. 2271-2279, (2012); 
McShane B.B., Gal D., Statistical significance and the dichotomization of evidence, J Am Stat Assoc, 112, 519, pp. 885-895, (2017); 
Resche-Rigon M., White I.R., Bartlett J.W., Peters S.A.E., Thompson S.G., Multiple imputation for handling systematically missing confounders in meta-analysis of individual participant data, Stat Med, 32, 28, pp. 4890-4905, (2013); 
Brockwell S.E., Gordon I.R., A comparison of statistical methods for meta-analysis, Stat Med, 20, 6, pp. 825-840, (2001); 
Dwan K., Gamble C., Williamson P.R., Kirkham J.J., Systematic review of the empirical evidence of study publication bias and outcome reporting bias – an updated review, PLoS One, 8, 7, (2013); 
Franco A., Malhotra N., Simonovits G., Publication bias in the social sciences: unlocking the file drawer, Science, 345, 6203, pp. 1502-1505, (2014); 
Hedges L.V., Plausibility and influence in selection models: a comment on Citkowicz and Vevea (2017), Psychol Methods, 22, 1, pp. 42-46, (2017); 
McShane B.B., Bockenholt U., Hansen K.T., Adjusting for publication bias in meta-analysis: an evaluation of selection methods and some cautionary notes, Perspect Psychol Sci, 11, 5, pp. 730-749, (2016); 
Hong S., Robert Reed W., Using Monte Carlo experiments to select meta-analytic estimators, Res Synth Methods, 12, 2, pp. 192-215, (2021); 
Andrews I., Kasy M., Identification of and correction for publication bias, Am Econ Rev, 109, 8, pp. 2766-2794, (2019); 
Stanley T.D., Doucouliagos H., Ioannidis J.P.A., Carter E.C., Detecting publication selection bias through excess statistical significance, Res Synth Methods, 12, 6, pp. 776-795, (2021); 
Moreno S.G., Sutton A.J., Ades A.E., Et al., Assessment of regression-based methods to adjust for publication bias through a comprehensive simulation study, BMC Med Res Methodol, 9, pp. 1-17, (2009); 
Rodgers M.A., Pustejovsky J.E., Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes, Psychol Methods, 26, 2, pp. 141-160, (2021); 
Turner R.M., Omar R.Z., Yang M., Goldstein H., Thompson S.G., A multilevel model framework for meta-analysis of clinical trials with binary outcomes, Stat Med, 19, 24, pp. 3417-3432, (2000); 
Viechtbauer W., Bias and efficiency of meta-analytic variance estimators in the random-effects model, J Educ Behav Stat, 30, 3, pp. 261-293, (2005); 
Hedges L.V., Tipton E., Johnson M.C., Robust variance estimation in meta-regression with dependent effect size estimates, Res Synth Methods, 1, 1, pp. 39-65, (2010); 
Tipton E., Small-sample adjustments for robust variance estimation with meta-regression, Psychol Methods, 20, 3, pp. 375-393, (2015); 
Fisher Z., Tipton E., Robumeta: an R-package for robust variance estimation in meta-analysis. arXiv Preprint arXiv:1503.02220, (2015); 
Roberts B., MacLeod C.M., Fernandes M., The enactment effect: a systematic review and meta-analysis of behavioral, neuroimaging, and patient studies, Psychol Bull, 132, pp. 29-32, (2022); 
Carter E.C., Schonbrodt F.D., Gervais W.M., Hilgard J., Correcting for bias in psychology: a comparison of meta-analytic methods, Adv Methods Pract Psychol Sci, 2, 2, pp. 115-144, (2019); 
Terrin N., Schmid C.H., Lau J., Olkin I., Adjusting for publication bias in the presence of heterogeneity, Stat Med, 22, 13, pp. 2113-2126, (2003); 
Bartos F., Maier M., Wagenmakers E.-J., Et al., Footprint of publication selection bias on meta-analyses in medicine, economics, and psychology. arXiv:2208.12334, (2022); 
Schwab S., Kreiliger G., Held L., Assessing treatment effects and publication bias across different specialties in medicine: a meta-epidemiological study, BMJ Open, 11, 9, (2021); 
Lash T.L., VanderWeele T.J., Haneuse S., Rothman K.J., Modern Epidemiology, (2021); 
Manski C.F., Nonparametric bounds on treatment effects, Am Econ Rev, 80, 2, pp. 319-323, (1990); 
Mathur M.B., VanderWeele T.J., Finding common ground in meta-analysis “wars” on violent video games, Perspect Psychol Sci, 14, 4, pp. 705-708, (2019); 
Sterne J.A.C., Hernan M.A., Reeves B.C., Et al., ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions, BMJ, 355, (2016); 
VanderWeele T.J., Chapter 25, causal inference with time-varying exposures, Modern Epidemiology, pp. 605-618, (2021); 
Baumeister S.E., Leitzmann M.F., Linseisen J., Schlesinger S., Physical activity and the risk of liver cancer: a systematic review and meta-analysis of prospective studies and a bias analysis, J Natl Cancer Inst, 111, 11, pp. 1142-1151, (2019); 
Rui F., Sekercioglu N., Mathur M.B., Couban R., Coyte P.C., Dialysis initiation and all-cause mortality among incident adult patients with advanced ckd: a meta-analysis with bias analysis, Kidney Med, 3, pp. 64-75.e1, (2020); 
Ling S., Brown K., Miksza J.K., Et al., Association of type 2 diabetes with cancer: a meta-analysis with bias analysis for unmeasured confounding in 151 cohorts comprising 32 million people, Diabetes Care, 43, 9, pp. 2313-2322, (2020); 
Higgins J.P.T., Thomas J., Chandler J., Et al., Cochrane Handbook for Systematic Reviews of Interventions, (2019); 
VanderWeele T.J., Ding P., Sensitivity analysis in observational research: introducing the E-value, Ann Intern Med, 167, 4, pp. 268-274, (2017); 
Greenland S., Pearl J., Robins J.M., Causal diagrams for epidemiologic research, Epidemiology, 10, pp. 37-48, (1999); 
Pearl J., Causal diagrams for empirical research, Biometrika, 82, 4, pp. 669-688, (1995); 
Pearl J., Causality, (2009); 
Mathur M.B., Shpitser I., VanderWeele T.J., A common-cause principle for eliminating selection bias in causal estimands through covariate adjustment, (2023); 
Mathur M.B., Peacock J., Reichling D.B., Et al., Interventions to reduce meat consumption by appealing to animal welfare: meta-analysis and evidence-based recommendations, Appetite, 164, (2021); 
Kalantarian S., Stern T.A., Mansour M., Ruskin J.N., Cognitive impairment associated with atrial fibrillation: a meta-analysis, Ann Intern Med, 158, 5, pp. 338-346, (2013); 
Bruns S.B., Ioannidis J.P.A., P-curve and p-hacking in observational research, PLoS One, 11, 2, (2016); 
Stefan A.M., Schonbrodt F.D., Big little lies: a compendium and simulation of p-hacking strategies, R Soc Open Sci, 10, 2, (2023); 
Coburn K.M., Vevea J.L., Coburn M.K.M., weightr: Estimating weight-function models for publication bias. R package version 2.0.2, (2019); 
Viechtbauer W., Conducting meta-analyses in R with the metafor package, J Stat Softw, 36, 3, pp. 1-48, (2010); 
Mathur M.B., VanderWeele T.J., Meta-regression methods to characterize evidence strength using meaningful-effect percentages conditional on study characteristics, Res Synth Methods, 12, 6, pp. 731-749, (2021); 
Mathur M.B., VanderWeele T.J., New metrics for meta-analyses of heterogeneous effects, Stat Med, 38, 8, pp. 1336-1342, (2019); 
Greenland S., Commentary: an argument against E-values for assessing the plausibility that an association could be explained away by residual confounding, Int J Epidemiol, 49, 5, pp. 1501-1503, (2020); 
Ioannidis J.P.A., Tan Y.J., Blum M.R., Limitations and misinterpretations of E-values for sensitivity analyses of observational studies, Ann Intern Med, 170, 2, pp. 108-111, (2019); 
Poole C., Commentary: continuing the E-value's post-publication peer review, Int J Epidemiol, 49, 5, pp. 1497-1500, (2020); 
Sjolander A., Greenland S., Are E-values too optimistic or too pessimistic? Both and neither!, Int J Epidemiol, 51, 2, pp. 355-363, (2022); 
VanderWeele T.J., Mathur M.B., Ding P., Correcting misinterpretations of the E-value, Ann Intern Med, 170, 2, pp. 131-132, (2019); 
VanderWeele T.J., Are Greenland, Ioannidis, and Poole opposed to the Cornfield conditions? A defense of the E-value, Int J Epidemiol, 51, pp. 364-371, (2021)#FRF#
