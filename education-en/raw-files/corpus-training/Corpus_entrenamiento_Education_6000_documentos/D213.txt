#ITI#Fidelity, Rigor, and Relevance: How SEAs are Approaching the ESSA Evidence Requirements#FTI#
#IRE# The Every Student Succeeds Act’s evidence requirements mandate the use of research in the selection of school improvement interventions, with the aim of ensuring that schools and districts invest their efforts and funding more wisely. This study of eight states presents three different approaches to the evidence requirements: using lists of pre-sanctioned evidence-based interventions, training schools and districts to evaluate the research supporting potential interventions, and building local evidence of effectiveness. Through interviews with state administrators, I show how each approach relied on different understandings and prioritizations of research rigor and local relevance.#FRE#
#IPC# educational policy; evidence; federal policy; policy adaptation; policy implementation; state policies#FPC#
#IRF# Adams C.M., Miskell R.C., Teacher trust in district administration, Educational Administration Quarterly, 52, 4, pp. 675-706, (2016); 
Birkeland S., Murphy-Graham E., Weiss C.H., Good reasons for ignoring good evaluation: The case of the drug abuse resistance education (DARE) program, Evaluation and Program Planning, 28, 3, pp. 247-256, (2005); 
Boudett K.P., City E.A., Murnane R.J., Data wise: A step-by-step guide to using assessment results to improve teaching and learning, (2013); 
Bryk A.S., Schneider B., Trust in schools: A core resource for improvement, (2002); 
Coburn C.E., Beyond decoupling: Rethinking the relationship between the institutional environment and the classroom, Sociology of Education, 77, 3, pp. 211-244, (2004); 
Coburn C.E., The partnership for district change: Challenges of evidence use in a major urban district, Research and practice in education, pp. 167-182, (2010); 
Coburn C.E., Honig M.I., Stein M.K., What’s the evidence on districts’ use of evidence, The role of research in educational improvement, pp. 67-87, (2009); 
Coburn C.E., Talbert J.E., Conceptions of evidence use in school districts: Mapping the terrain, American Journal of Education, 112, 4, pp. 469-495, (2006); 
Coburn C.E., Toure J., Yamashita M., Evidence, interpretation, and persuasion: Instructional decision making at the district central office, Teachers College Record, 111, 4, pp. 1115-1161, (2009); 
Cohen D.K., Hill H.C., Learning policy: When state education reform works, (2008); 
Davidson K.L., Farrell C.C., Penuel W.R., What types of research do education leaders find useful, and for what purposes, (2019); 
(2015); 
Farley-Ripple E., Research use in school district central office decision making: A case study, Educational Management Administration & Leadership, 40, 6, pp. 786-806, (2012); 
Farley-Ripple E., May H., Karpyn A., Tilley K., McDonough K., Rethinking connections between research and practice in education: A conceptual framework, Educational Researcher, 47, 4, pp. 235-245, (2018); 
Farrell C.C., Coburn C.E., What is the conceptual use of research, and why is it important? William T, Grant Foundation, (2016); 
Goertz M.E., Barnes C., Massell D., Fink R., Francis A.T., State education agencies’ acquisition and use of research knowledge in school improvement strategies, (2013); 
Hamann E.T., Lane B., The roles of state departments of education as policy intermediaries: Two cases, Educational Policy, 18, 3, pp. 426-455, (2004); 
Herlihy C., Kemple J., Bloom H., Zhu P., Berlin G., Understanding reading first: What we know, what we don’t, and what’s next, MDRC Policy Brief, (2009); 
Hill H.C., Policy is not enough: Language and the interpretation of state standards, American Educational Research Journal, 38, 2, pp. 289-318, (2001); 
Hill H.C., Understanding implementation: Street-level bureaucrats’ resources for reform, Journal of Public Administration Research and Theory, 13, 3, pp. 265-282, (2003); 
Honig M.I., Coburn C.E., Evidence-based decision making in school district central offices: Toward a policy and research agenda, Educational Policy, 22, 4, pp. 578-608, (2008); 
Kane T.J., Making evidence locally, Education Next, 17, 2, pp. 52-58, (2017); 
Levinson B.A.U., Sutton M., Winstead T., Education policy as a practice of power: Theoretical tools, ethnographic methods, democratic options, Educational Policy, 23, 6, pp. 767-795, (2009); 
Lewis C., Perry R., Hurd J., A deeper look at lesson study, Educational Leadership, 61, 5, pp. 18-22, (2004); 
Louis K.S., Thomas E., Gordon M.F., Febey K.S., State leadership for school improvement: An analysis of three states, Educational Administration Quarterly, 44, 4, pp. 562-592, (2008); 
Lytle S., Cochran-Smith M., Teacher research as a way of knowing, Harvard Educational Review, 62, 4, pp. 447-475, (1992); 
Miles M.B., Huberman A.M., Saldana J., Qualitative data analysis: A methods sourcebook, (2014); 
Nelson S.R., Leffler J.C., Hansen B.A., Toward a research agenda for understanding and improving the use of research evidence, (2009); 
Penuel W.R., What will research use look like under the Every Student Succeeds Act?, (2015); 
Penuel W.R., Briggs D.C., Davidson K.L., Herlihy C., Sherer D., Hill H.C., Farrell C.C., Allen A.-R., Findings from a national study on research use among school and district leaders, (2016); 
Penuel W.R., Farrell C.C., Research-practice partnerships and ESSA: A learning agenda for the coming decade, Teaching in context: The social side of education reform, pp. 181-200, (2016); 
Penuel W.R., Farrell C.C., Allen A.-R., Toyama Y., Coburn C.E., What research district leaders find useful, Educational Policy, 32, 4, pp. 540-568, (2016); 
Leverage points: Thirteen opportunities for state education agencies to use their ESSA state plans to build and use evidence to improve student outcomes, (2017); 
Evidence-building opportunities under ESSA: How states can and should generate evidence to drive better outcomes for students, (2018); 
Slavin R.E., Evidence and the ESSA, Huffington Post, (2017); 
Slavin R.E., Superman and statistics [Blog post], (2019); 
Spillane J.P., Reiser B.J., Reimer T., Policy implementation and cognition: Reframing and refocusing implementation research, Review of Educational research, 72, 3, pp. 387-431, (2002); 
Tseng V., The uses of research in policy and practice, Social Policy Report, 26, 2, pp. 3-16, (2012); 
Tseng V., Easton J.Q., Supplee L.H., Research-practice partnerships: Building two-way streets of engagement, Social Policy Report, 30, 4, pp. 3-15, (2017); 
Weiss C.H., Research for policy’s sake: The enlightenment function of social research, Policy Analysis, 3, 4, pp. 531-545, (1977); 
Weiss C.H., Knowledge creep and decision accretion, Science Communication, 1, 3, pp. 381-404, (1980); 
Weiss C.H., Murphy-Graham E., Birkeland S., An alternate route to policy influence: How evaluations affect DARE, American Journal of Evaluation, 26, 1, pp. 12-30, (2005); 
Weiss C.H., Murphy-Graham E., Petrosino A., Gandhi A.G., The fairy godmother—and her warts: Making the dream of evidence-based policy come true, American Journal of Evaluation, 29, 1, pp. 29-47, (2008); 
West M.R., From evidence-based programs to an evidence-based system: Opportunities under the Every Student Succeeds Act, (2016); 
Zeehandelaar D., Griffith D., Smith J., Thier M., Anderson R., Pitts C., Gasparian H., Schools of thought: A taxonomy of American education governance, (2015)#FRF#
