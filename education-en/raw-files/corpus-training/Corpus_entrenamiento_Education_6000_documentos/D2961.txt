#ITI#Footprint of publication selection bias on meta-analyses in medicine, environmental sciences, psychology, and economics#FTI#
#IRE# Publication selection bias undermines the systematic accumulation of evidence. To assess the extent of this problem, we survey over 68,000 meta-analyses containing over 700,000 effect size estimates from medicine (67,386/597,699), environmental sciences (199/12,707), psychology (605/23,563), and economics (327/91,421). Our results indicate that meta-analyses in economics are the most severely contaminated by publication selection bias, closely followed by meta-analyses in environmental sciences and psychology, whereas meta-analyses in medicine are contaminated the least. After adjusting for publication selection bias, the median probability of the presence of an effect decreased from 99.9% to 29.7% in economics, from 98.9% to 55.7% in psychology, from 99.8% to 70.7% in environmental sciences, and from 38.0% to 29.7% in medicine. The median absolute effect sizes (in terms of standardized mean differences) decreased from d = 0.20 to d = 0.07 in economics, from d = 0.37 to d = 0.26 in psychology, from d = 0.62 to d = 0.43 in environmental sciences, and from d = 0.24 to d = 0.13 in medicine#FRE#
#IPC# Bayesian; effect sizes; evidence; meta-analysis; model-averaging; publication bias; RoBMA#FPC#
#IRF# Chavalarias D., Ioannidis J.P., Science mapping analysis characterizes 235 biases in biomedical research, J Clin Epidemiol, 63, 11, pp. 1205-1215, (2010); 
Dwan K., Altman D.G., Arnaiz J.A., Et al., Systematic review of the empirical evidence of study publication bias and outcome reporting bias, PloS One, 3, 8, (2008); 
Rosenthal R., Gaito J., Further evidence for the cliff effect in interpretation of levels of significance, Psychol Rep, 15, 2, (1964); 
Wicherts J.M., The weak spots in contemporary science (and how to fix them), Animals, 7, 12, pp. 90-119, (2017); 
Otte W.M., Vinkers C.H., Habets P.C., IJzendoorn V., Tijdink J.K., Analysis of 567,758 randomized controlled trials published over 30 years reveals trends in phrases used to discuss results that do not reach statistical significance, PLoS Biol, 20, 2, (2022); 
John L.K., Loewenstein G., Prelec D., Measuring the prevalence of questionable research practices with incentives for truth telling, Psychol Sci, 23, 5, pp. 524-532, (2012); 
Fiedler K., Schwarz N., Questionable research practices revisited, Soc Psychol Personal Sci, 7, 1, pp. 45-52, (2016); 
De Winter J.C., Dodou D., A surge of p-values between 0.041 and 0.049 in recent decades (but negative results are increasing rapidly too), PeerJ, 3, (2015); 
Fanelli D., Costas R., Ioannidis J.P., Meta-assessment of bias in science, Proc Natl Acad Sci, 114, 14, pp. 3714-3719, (2017); 
Ioannidis J.P., Stanley T., Doucouliagos H., The power of bias in economics research, Econ J, 127, 605, pp. F236-F265, (2017); 
Mathur V.W., Finding common ground in meta-analysis “wars” on violent video games, Perspect Psychol Sci, 14, 4, pp. 705-708, (2019); 
Stanley T.D., Carter E.C., Doucouliagos H., What meta-analyses reveal about the replicability of psychological research, Psychol Bull, 144, 12, pp. 1325-1346, (2018); 
Van Aert R.C., Wicherts J.M., Van Assen M.A., Publication bias examined in meta-analyses from psychology and medicine: a meta-meta-analysis, PloS One, 14, 4, (2019); 
Schwab S., Kreiliger G., Held L., Assessing treatment effects and publication bias across different specialties in medicine: a meta-epidemiological study, BMJ Open, 11, 9, (2021); 
Kuhberger A., Fritz A., Scherndl T., Publication bias in psychology: a diagnosis based on the correlation between effect size and sample size, PloS One, 9, 9, (2014); 
Fanelli D., Positive” results increase down the hierarchy of the sciences, PloS One, 5, 4, (2010); 
Ioannidis J.P., Excess significance bias in the literature on brain volume abnormalities, Arch Gen Psychiatry, 68, 8, pp. 773-780, (2011); 
Scheel A.M., Schijen M.R., Lakens D., An excess of positive results: comparing the standard psychology literature with registered reports, Adv Methods Pract Psychol Sci, 4, 2, pp. 1-12, (2021); 
Sterling T.D., Publication decisions and their possible effects on inferences drawn from tests of significance—or vice versa, J Am Stat Assoc, 54, 285, pp. 30-34, (1959); 
Fanelli D., Negative results are disappearing from most disciplines and countries, Scientometrics, 90, 3, pp. 891-904, (2012); 
Deressa T.K., Stern D.I., Vangronsveld J., Et al., More than half of statistically significant research findings in the environmental sciences are actually not, (2022); 
Sladekova M., Webb L.E., Field A.P., Estimating the change in meta-analytic effect size estimates after the application of publication bias adjustment methods, Psychol Methods, 28, pp. 664-686, (2022); 
Viechtbauer W., Conducting meta-analyses in R with the metafor package, J Stat Softw, 36, 3, pp. 1-48, (2010); 
Borenstein M., Hedges L.V., Higgins J.P., Rothstein H.R., Introduction to Meta-Analysis, (2009); 
Maier M., Bartos F., Wagenmakers E.J., Robust Bayesian meta-analysis: addressing publication bias with model-averaging, Psychol Methods, 28, pp. 107-122, (2022); 
Bartos F., Maier M., Wagenmakers E.J., Doucouliagos H., Stanley T.D., Robust Bayesian meta-analysis: model-averaging across complementary publication bias adjustment methods, Research Synthesis Methods, 14, 1, (2022); 
Hoeting J.A., Madigan D., Raftery A.E., Volinsky C.T., Bayesian model averaging: a tutorial, Stat Sci, 14, 4, pp. 382-401, (1999); 
Fragoso T.M., Bertoli W., Louzada F., Bayesian model averaging: a systematic review and conceptual classification, Int Stat Rev, 86, 1, pp. 1-28, (2018); 
Vevea J.L., Hedges L.V., A general linear model for estimating effect size in the presence of publication bias, Psychometrika, 60, 3, pp. 419-435, (1995); 
Stanley T.D., Doucouliagos H., Ioannidis J.P., Finding the power to reduce publication bias, Stat Med, 36, 10, pp. 1580-1598, (2017); 
Erp V.S., Verhagen J., Grasman R.P., Wagenmakers E.J., Estimates of between-study heterogeneity for 705 meta-analyses reported in Psychological Bulletin from 1990–2013, J Open Psychol Data, 5, 1, (2017); 
Wrinch D., Jeffreys H., On certain fundamental principles of scientific inquiry, Phil Mag, 42, pp. 369-390, (1921); 
Kass R.E., Raftery A.E., Bayes factors, J Am Stat Assoc, 90, 430, pp. 773-795, (1995); 
Jeffreys H., Theory of Probability, (1939); 
Lee M.D., Wagenmakers E.J., Bayesian Cognitive Modeling: A Practical Course, (2013); 
Wagenmakers E.J., Morey R.D., Lee M.D., Bayesian benefits for the pragmatic researcher, Curr Dir Psychol Sci, 25, 3, pp. 169-176, (2016); 
Wasserstein R.L., Lazar N.A., The ASA statement on p-values: context, process, and purpose, Am Stat, 70, 2, pp. 129-133, (2016); 
Ioannidis J.P., Cappelleri J.C., Lau J., Issues in comparisons between meta-analyses and large trials, Jama, 279, 14, pp. 1089-1093, (1998); 
Laine C., Horton R., DeAngelis C.D., Et al., Clinical trial registration—looking back and moving ahead, N Engl J Med, 356, 26, pp. 2734-2736, (2007); 
Chambers C.D., Registered reports: a new publishing initiative at cortex, Cortex, 49, 3, pp. 609-610, (2013); 
Chambers C.D., Dienes Z., McIntosh R.D., Rotshtein P., Willmes K., Registered reports: realigning incentives in scientific publishing, Cortex, 66, pp. A1-A2, (2015); 
Akker v D., Weston S., Campbell L., Et al., Preregistration of secondary data analysis: a template and tutorial, Meta-Psychology, 5, (2021)#FRF#
