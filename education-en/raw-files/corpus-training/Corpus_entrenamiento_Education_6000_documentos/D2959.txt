#ITI#A study of search strategy availability statements and sharing practices for systematic reviews: Ask and you might receive#FTI#
#IRE# The literature search underpins data collection for all systematic reviews (SRs). The SR reporting guideline PRISMA, and its extensions, aim to facilitate research transparency and reproducibility, and ultimately improve the quality of research, by instructing authors to provide specific research materials and data upon publication of the manuscript. Search strategies are one item of data that are explicitly included in PRISMA and the critical appraisal tool AMSTAR2. Yet some authors use search availability statements implying that the search strategies are available upon request instead of providing strategies up front. We sought out reviews with search availability statements, characterized them, and requested the search strategies from authors via email. Over half of the included reviews cited PRISMA but less than a third included any search strategies. After requesting the strategies via email as instructed, we received replies from 46% of authors, and eventually received at least one search strategy from 36% of authors. Requesting search strategies via email has a low chance of success. Ask and you might receive—but you probably will not. SRs that do not make search strategies available are low quality at best according to AMSTAR2; Journal editors can and should enforce the requirement for authors to include their search strategies alongside their SR manuscripts#FRE#
#IPC# data availability; PRISMA; search reporting; search strategy availability; systematic reviews#FPC#
#IRF# Gong K., Open science: the science paradigm of the new era, Cult Sci, 5, 1, pp. 3-9, (2022); 
SPARC. Open Data. Cited August 4, 2023; 
Recommendation on Open Science, (2021); 
Jiao C., Li K., Fang Z., Data sharing practices across knowledge domains: a dynamic examination of data availability statements in PLOS ONE publications, J Inf Sci, 29, (2022); 
McGuinness L.A., Sheppard A.L., A descriptive analysis of the data availability statements accompanying medRxiv preprints and a comparison with their published counterparts, PloS One, 16, 5, (2021); 
Bergeat D., Lombard N., Gasmi A., Le Floch B., Naudet F., Data sharing and reanalyses among randomized clinical trials published in surgical journals before and after adoption of a data availability and reproducibility policy, JAMA Netw Open, 5, 6, (2022); 
Gabelica M., Bojcic R., Puljak L., Many researchers were not compliant with their published data sharing statement: a mixed-methods study, J Clin Epidemiol, 150, pp. 33-41, (2022); 
Tedersoo L., Kungas R., Oras E., Et al., Data sharing practices and data availability upon request differ across scientific disciplines, Sci Data, 8, 1, (2021); 
Page M.J., Nguyen P.Y., Hamilton D.G., Et al., Data and code availability statements in systematic reviews of interventions were often missing or inaccurate: a content analysis, J Clin Epidemiol, 157, pp. 1-10, (2022); 
Moher D., Liberati A., Tetzlaff J., Altman D.G., Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement, BMJ, 339, (2009); 
Page M.J., Moher D., Bossuyt P.M., Et al., PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews, BMJ, 372, (2021); 
Rethlefsen M.L., Kirtley S., Waffenschmidt S., Et al., PRISMA-S: an extension to the PRISMA statement for reporting literature searches in systematic reviews, Syst Rev, 10, 1, (2021); 
Shea B.J., Reeves B.C., Wells G., Et al., AMSTAR 2: a critical appraisal tool for systematic reviews that include randomised or non-randomised studies of healthcare interventions, or both, BMJ, 358, (2017); 
Nguyen P.Y., Kanukula R., McKenzie J.E., Et al., Changing patterns in reporting and sharing of review data in systematic reviews with meta-analysis of the effects of interventions: cross sectional meta-research study, BMJ, 379, (2022); 
Krawczyk M., Reuben E., (Un)available upon request: field experiment on researchers' willingness to share supplementary materials, Account Res, 19, 3, pp. 175-186, (2012); 
Wicherts J.M., Bakker M., Molenaar D., Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results, PloS One, 6, 11, (2011); 
DeBlanc J., Kay B., Lehrich J., Et al., Availability of statistical code from studies using Medicare data in general medical journals, JAMA Intern Med, 180, 6, pp. 905-907, (2020); 
Harzing A.W., Publish or Perish [Internet]; 2007; 
SJR—SCImago Journal & Country Rank [Portal]; n.d. Retrieved July–December, 2022; 
Pussegoda K., Turner L., Garritty C., Et al., Systematic review adherence to methodological or reporting quality, Syst Rev, 6, 1, (2017); 
Dal Santo T., Rice D.B., Amiri L.S.N., Et al., Methods and results of studies on reporting guideline adherence are poorly reported: a meta-research study, J Clin Epidemiol, 159, pp. 225-234, (2023); 
Bradley S.H., Data availability statements: a little credit, but not much, BMJ, 380, (2023)#FRF#
