#ITI#Prediction With Mixed Effects Models: A Monte Carlo Simulation Study#FTI#
#IRE# Oftentimes in many fields of the social and natural sciences, data are obtained within a nested structure (e.g., students within schools). To effectively analyze data with such a structure, multilevel models are frequently employed. The present study utilizes a Monte Carlo simulation to compare several novel multilevel classification algorithms across several varied data conditions for the purpose of prediction. Among these models, the panel neural network and Bayesian generalized mixed effects model (multilevel Bayes) consistently yielded the highest prediction accuracy in test data across nearly all data conditions.#FRE#
#IPC# classification; multilevel modeling; predictive modeling#FPC#
#IRF# Bagiella E., Sloan R.P., Heitjan D.F., Mixed-effects models in psychophysiology, Psychophysiology, 37, 1, pp. 13-20, (2000); 
Bolin J.E., Finch H., Supervised classification in the presence of misclassified training data: A Monte Carlo simulation study in the three group case, Frontiers in Psychology, 5, (2014); 
Capitaine L., Genuer R., Thiebaut R., Random forests for high-dimensional longitudinal data, (2019); 
Cohen J., Statistical power analysis for the behavioural sciences, (1988); 
Crane-Droesch A., Semiparametric panel data models using neural networks, (2017); 
Demichelis F., Magni P., Piergiorgi P., Rubin M.A., Bellazzi R., A hierarchical naive bayes model for handling sample heterogeneity in classification problems: An application to tissue microarrays, BMC Bioinformatics, 7, 1, (2006); 
Fawcett T., An introduction to ROC analysis, Pattern Recognition Letters, 27, 8, pp. 861-874, (2006); 
Finch H., Recursive partitioning in the presence of multilevel data, General Linear Model Journal, 41, 2, pp. 30-44, (2015); 
Finch W.H., French B.F., A comparison of methods for estimating confidence intervals for omega-squared effect size, Educational and Psychological Measurement, 72, 1, pp. 68-77, (2012); 
Fletcher J.M., Stuebing K.K., Barth A.E., Miciak J., Francis D.J., Denton C.A., Agreement and coverage of indicators of response to intervention: A multi-method comparison and simulation, Topics in Language Disorders, 34, 1, pp. 74-89, (2014); 
Friedman J.H., Greedy function approximation: A gradient boosting machine, Annals of Statistics, 29, 5, pp. 1189-1232, (2001); 
Gelman A., Carlin J.B., Stern H.S., Dunson D.B., Vehtari A., Rubin D.B., Bayesian data analysis, (2013); 
Hadfield J.D., MCMC methods for multi-response generalized linear mixed models: The MCMCglmm R package, Journal of Statistical Software, 33, 2, pp. 1-22, (2010); 
Hajjem A., Bellavance F., Larocque D., Mixed-effects random forest for clustered data, Journal of Statistical Computation and Simulation, 84, 6, pp. 1313-1328, (2014); 
Hajjem A., Larocque D., Bellavance F., Generalized mixed effects regression trees, Statistics & Probability Letters, 126, pp. 114-118, (2017); 
Hammersley J., Monte Carlo methods, (2013); 
Hastie T., Tibshirani R., Friedman J., The elements of statistical learning: Data mining, inference, and prediction, (2009); 
Hedegaard H., Curtin S.C., Warner M., Suicide mortality in the United States, 1999â€“2017, (2018); 
Ho T.K., Basu M., Complexity measures of supervised classification problems, IEEE Transactions on Pattern Analysis & Machine Intelligence, 24, 3, pp. 289-300, (2002); 
Holden J.E., Finch W.H., Kelley K., A comparison of two-group classification methods, Educational and Psychological Measurement, 71, 5, pp. 870-901, (2011); 
James G., Witten D., Hastie T., Tibshirani R., An introduction to statistical learning, 112, (2013); 
Kessler R., Barker P., Colpe L., Epstein J., Gfroerer J., Hiripi E., Howes M., Normand S., Manderscheid R., Walters E., Zaslavsky A., Screening for serious mental illness in the general population, Archives of General Psychiatry, 60, 2, pp. 184-189, (2003); 
Kilham P., Hartebrodt C., Kandler G., Generating tree-level harvest predictions from forest inventories with random forests, Forests, 10, 1, pp. 20-45, (2019); 
Knight A.P., Humphrey S.E., The handbook of multilevel theory, measurement, and analysis, pp. 423-447, (2019); 
Kruschke J., Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, (2014); 
LeBreton J.M., Senter J.L., Answers to 20 questions about interrater reliability and interrater agreement, Organizational Research Methods, 11, 4, pp. 815-852, (2008); 
Lei P.W., Koehly L.M., Linear discriminant analysis versus logistic regression: A comparison of classification errors in the two-group case, Journal of Experimental Education, 72, 1, pp. 25-49, (2003); 
Luengo J., Herrera F., Shared domains of competence of approximate learning models using measures of separability of classes, Information Sciences, 185, 1, pp. 43-65, (2012); 
Maas C.J., Hox J.J., Sufficient sample sizes for multilevel modeling, Methodology, 1, 3, pp. 86-92, (2005); 
Mahalanobis P., On the generalised distance in statistics, Proceedings of the National Institute of Science of India, 2, 1, pp. 49-55, (1936); 
Mann J.J., Ellis S.P., Waternaux C.M., Liu X., Oquendo M.A., Malone K.M., Brodsky B.S., Haas G.L., Currier D., Classification trees distinguish suicide attempters in major psychiatric disorders: A model of clinical decision making, Journal of Clinical Psychiatry, 69, 1, pp. 23-31, (2008); 
McNeish D., Kelley K., Fixed effects models versus mixed effects models for clustered data: Reviewing the approaches, disentangling the differences, and making recommendations, Psychological Methods, 24, 1, pp. 20-35, (2019); 
Meuleman B., Billiet J., A Monte Carlo sample size study: How many countries are needed for accurate multilevel SEM?, Survey Research Methods, 3, 1, pp. 45-58, (2009); 
Meyer D., Dimitriadou E., Hornik K., Weingessel A., Leisch F., Chang C.-C., Lin C.-C., Package e1071, (2020); 
Milliren C.E., Evans C.R., Richmond T.K., Dunn E.C., Does an uneven sample size distribution across settings matter in cross-classified multilevel modeling? Results of a simulation study, Health & Place, 52, pp. 121-126, (2018); 
Morris L.V., Wu S.S., Finnegan C.L., Predicting retention in online general education courses, American Journal of Distance Education, 19, 1, pp. 23-36, (2005); 
Mental illness, (2019); 
Ngufor C., Vira: Virtual inteligent robot assistant, (2019); 
Ngufor C., Van Houten H., Caffo B.S., Shah N.D., McCoy R.G., Mixed effect machine learning: A framework for predicting longitudinal change in hemoglobin A1c, Journal of Biomedical Informatics, 89, pp. 56-67, (2019); 
Okada K., Is omega squared less biased? A comparison of three major effect size indices in one-way ANOVA, Behaviormetrika, 40, 2, pp. 129-147, (2013); 
Pohar M., Blas M., Turk S., Comparison of logistic regression and linear discriminant analysis: A simulation study, Metodoloski Zvezki, 1, 1, pp. 143-161, (2004); 
R: A language and environment for statistical computing, (2019); 
Raudenbush S.W., Bryk A.S., Hierarchical linear models: Applications and data analysis methods, 1, (2002); 
Revelle W.R., psych: Procedures for personality and psychological research, (2017); 
Ribeiro J.D., Franklin J.C., Fox K.R., Bentley K.H., Kleiman E.M., Chang B.P., Nock M.K., Suicide as a complex classification problem: Machine learning and related techniques can advance suicide prediction-a reply to Roaldset (2016), Psychological medicine, 46, 9, pp. 2009-2010, (2016); 
Richard M.D., Lippmann R.P., Neural network classifiers estimate Bayesian a posteriori probabilities, Neural Computation, 3, 4, pp. 461-483, (1991); 
Rosen B.L., DeMaria A.L., Statistical significance vs. practical significance: An exploration through health education, American Journal of Health Education, 43, 4, pp. 235-241, (2012); 
Sela R.J., Simonoff J.S., RE-EM trees: A data mining approach for longitudinal and clustered data, Machine Learning, 86, 2, pp. 169-207, (2012); 
Speiser J.L., Wolf B.J., Chung D., Karvellas C.J., Koch D.G., Durkalski V.L., BiMM forest: A random forest method for modeling clustered and longitudinal binary outcomes, Chemometrics and Intelligent Laboratory Systems, 185, pp. 122-134, (2019); 
Speiser J.L., Wolf B.J., Chung D., Karvellas C.J., Koch D.G., Durkalski V.L., BiMM tree: A decision tree method for modeling clustered and longitudinal binary outcomes, Communications in Statistics-Simulation and Computation, 49, 4, pp. 1004-1023, (2020); 
Steyerberg E.W., Clinical prediction models, (2019); 
Stuebing K.K., Fletcher J.M., Branum-Martin L., Francis D.J., Evaluation of the technical adequacy of three methods for identifying specific learning disabilities based on cognitive discrepancies, School Psychology Review, 41, 1, pp. 3-22, (2012); 
The condition of education 2018, (2018); 
VanDerHeyden A.M., Universal screening may not be for everyone: Using a threshold model as a smarter way to determine risk, School Psychology Review, 42, 4, pp. 402-414, (2013); 
Xiong Y., Kim H.J., Singh V., Mixed Effects Neural Networks (MeNets) with applications to gaze estimation, pp. 7743-7752, (2019); 
Zhang N., Wu L., Yang J., Guan Y., Naive Bayes bearing fault diagnosis based on enhanced independence of data, Sensors (Basel, Switzerland), 18, 2, (2018); 
Zigler E., Phillips L., Psychiatric diagnosis: A critique, Journal of Abnormal and Social Psychology, 63, 3, pp. 607-618, (1961)#FRF#
