#ITI#Data extraction for evidence synthesis using a large language model: A proof-of-concept study#FTI#
#IRE# Data extraction is a crucial, yet labor-intensive and error-prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof-of-concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English-language, open-access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high testâ€“retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors (n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero-shot learning). Based on findings of our proof-of-concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses#FRE#
#IPC# accuracy; artificial intelligence; data extraction; evidence synthesis; large language models; proof of concept#FPC#
#IRF# Finding What Works in Health Care: Standards for Systematic Reviews, (2011); 
Higgins J., Thomas J., Chandler J., Et al., Cochrane Handbook For Systematic Reviews of Interventions Version 6.4, (2023); 
Nussbaumer-Streit B., Ellen M., Klerings I., Et al., Resource use during systematic review production varies widely: a scoping review, J Clin Epidemiol, 139, pp. 287-296, (2021); 
Li T., Saldanha I.J., Jap J., Et al., A randomized trial provided new evidence on the accuracy and efficiency of traditional vs. electronically annotated abstraction approaches in systematic reviews, J Clin Epidemiol, 115, pp. 77-89, (2019); 
Mathes T., Klassen P., Pieper D., Frequency of data extraction errors and methods to increase data extraction quality: a methodological review, BMC Med Res Methodol, 17, 1, (2017); 
Jonnalagadda S.R., Goyal P., Huffman M.D., Automating data extraction in systematic reviews: a systematic review, Syst Rev, 4, (2015); 
Marshall I.J., Wallace B.C., Toward systematic review automation: a practical guide to using machine learning tools in research synthesis, Syst Rev, 8, pp. 1-10, (2019); 
Blaizot A., Veettil S.K., Saidoung P., Et al., Using artificial intelligence methods for systematic review in health sciences: a systematic review, Res Synth Methods, 13, 3, pp. 353-362, (2022); 
Schmidt L., Finnerty Mutlu A.N., Elmore R., Olorisade B.K., Thomas J., Higgins J.P.T., Data extraction methods for systematic review (semi)automation: update of a living systematic review, F1000Res, 10, (2021); 
Bonin F., Gleize M., Hou Y., Et al., Knowledge extraction and prediction from behavior science randomized controlled trials: a case study in smoking cessation, AMIA Annual Symposium Proceedings, (2020); 
GPT-4 Technical Report, (2023); 
Claude 2; 
Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Advances in Neural Information Processing Systems, (2017); 
Liu P., Yuan W., Fu J., Jiang Z., Hayashi H., Neubig G., Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing, ACM Comput Surv, 55, 9, pp. 1-35, (2023); 
Brown T., Mann B., Ryder N., Et al., Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020); 
Wei J., Bosma M., Zhao V.Y., Et al., Finetuned language models are zero-shot learners, (2021); 
Ouyang L., Wu J., Jiang X., Et al., Training language models to follow instructions with human feedback, Advances in Neural Information Processing Systems, 35, pp. 27730-27744, (2022); 
Liang P., Bommasani R., Lee T., Et al., Holistic evaluation of language models, (2022); 
Zheng L., Chiang W.-L., Sheng Y., Et al., Judging LLM-as-a-judge with MT-bench and Chatbot arena, (2023); 
Chen H., Jiao F., Li X., Et al., ChatGPT's one-year anniversary: are open-source large language models catching up?, arXiv Preprint arXiv:231116989, (2023); 
Blauvelt A., Papp K., Gottlieb A., Et al., A head-to-head comparison of ixekizumab vs. guselkumab in patients with moderate-to-severe plaque psoriasis: 12-week efficacy, safety and speed of response from a randomized, double-blinded trial, Br J Dermatol, 182, 6, pp. 1348-1358, (2020); 
Lebwohl M., Blauvelt A., Paul C., Et al., Certolizumab pegol for the treatment of chronic plaque psoriasis: results through 48 weeks of a phase 3, multicenter, randomized, double-blind, etanercept- and placebo-controlled study (CIMPACT), J Am Acad Dermatol, 79, 2, pp. 266-276.e5, (2018); 
Reich K., Pinter A., Lacour J.P., Et al., Comparison of ixekizumab with ustekinumab in moderate-to-severe psoriasis: 24-week results from IXORA-S, a phase III study, Br J Dermatol, 177, 4, pp. 1014-1023, (2017); 
Papp K.A., Merola J.F., Gottlieb A.B., Et al., Dual neutralization of both interleukin 17A and interleukin 17F with bimekizumab in patients with psoriasis: results from BE ABLE 1, a 12-week randomized, double-blinded, placebo-controlled phase 2b trial, J Am Acad Dermatol, 79, 2, pp. 277-286.e10, (2018); 
Reich K., Armstrong A.W., Foley P., Et al., Efficacy and safety of guselkumab, an anti-interleukin-23 monoclonal antibody, compared with adalimumab for the treatment of patients with moderate to severe psoriasis with randomized withdrawal and retreatment: results from the phase III, double-blind, placebo- and active comparator-controlled VOYAGE 2 trial, J Am Acad Dermatol, 76, 3, pp. 418-431, (2017); 
Warren R.B., Blauvelt A., Poulin Y., Et al., Efficacy and safety of risankizumab vs. secukinumab in patients with moderate-to-severe plaque psoriasis (IMMerge): results from a phase III, randomized, open-label, efficacy-assessor-blinded clinical trial, Br J Dermatol, 184, 1, pp. 50-59, (2021); 
Glatt S., Helmer E., Haier B., Et al., First-in-human randomized study of bimekizumab, a humanized monoclonal antibody and selective dual inhibitor of IL-17A and IL-17F, in mild psoriasis, Br J Clin Pharmacol, 83, 5, pp. 991-1001, (2017); 
Bagel J., Nia J., Hashim P.W., Et al., Secukinumab is superior to ustekinumab in clearing skin in patients with moderate to severe plaque psoriasis (16-week CLARITY results), Dermatol Ther, 8, 4, pp. 571-579, (2018); 
Thaci D., Blauvelt A., Reich K., Et al., Secukinumab is superior to ustekinumab in clearing skin of subjects with moderate to severe plaque psoriasis: CLEAR, a randomized controlled trial, J Am Acad Dermatol, 73, 3, pp. 400-409, (2015); 
Reich K., Gooderham M., Green L., Et al., The efficacy and safety of apremilast, etanercept and placebo in patients with moderate-to-severe plaque psoriasis: 52-week results from a phase IIIb, randomized, placebo-controlled trial (LIBERATE), J Eur Acad Dermatol Venereol, 31, 3, pp. 507-517, (2017); 
Trikalinos T.A., Balion C.M., Chapter 9: options for summarizing medical test performance in the absence of a "gold standard, J Gen Intern Med, 27, pp. S67-S75, (2012); 
Restificar A., Ananiadou S., Inferring appropriate eligibility criteria in clinical trial protocols without labeled data, Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics, (2012)#FRF#
