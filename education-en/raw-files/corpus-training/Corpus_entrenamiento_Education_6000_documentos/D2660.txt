#ITI#Early prediction of student knowledge in game-based learning with distributed representations of assessment questions#FTI#
#IRE# Game-based learning environments hold significant promise for facilitating learning experiences that are both effective and engaging. To support individualised learning and support proactive scaffolding when students are struggling, game-based learning environments should be able to accurately predict student knowledge at early points in students' gameplay. Student knowledge is traditionally assessed prior to and after each student interacts with the learning environment with conventional methods, such as multiple choice content knowledge assessments. While previous student modelling approaches have leveraged machine learning to automatically infer students' knowledge, there is limited work that incorporates the fine-grained content from each question in these types of tests into student models that predict student performance at early junctures in gameplay episodes. This work investigates a predictive student modelling approach that leverages the natural language text of the post-gameplay content knowledge questions and the text of the possible answer choices for early prediction of fine-grained individual student performance in game-based learning environments. With data from a study involving 66 undergraduate students from a large public university interacting with a game-based learning environment for microbiology, Crystal Island, we investigate the accuracy and early prediction capacity of student models that use a combination of gameplay features extracted from student log files as well as distributed representations of post-test content assessment questions. The results demonstrate that by incorporating knowledge about assessment questions, early prediction models are able to outperform competing baselines that only use student game trace data with no question-related information. Furthermore, this approach achieves high generalisation, including predicting the performance of students on unseen questions. Practitioner notes What is already known about this topic A distinctive characteristic of game-based learning environments is their capacity to enable fine-grained student assessment. Adaptive game-based learning environments offer individualisation based on specific student needs and should be able to assess student competencies using early prediction models of those competencies. Word embedding approaches from the field of natural language processing show great promise in the ability to encode semantic information that can be leveraged by predictive student models. What this paper adds Investigates word embeddings of assessment question content for reliable early prediction of student performance. Demonstrates the efficacy of distributed word embeddings of assessment questions when used by early prediction models compared to models that use either no assessment information or discrete representations of the questions. Demonstrates the efficacy and generalisability of word embeddings of assessment questions for predicting the performance of both new students on existing questions and existing students on new questions. Implications for practice and/or policy Word embeddings of assessment questions can enhance early prediction models of student knowledge, which can drive adaptive feedback to students who interact with game-based learning environments. Practitioners should determine if new assessment questions will be developed for their game-based learning environment, and if so, consider using our student modelling framework that incorporates early prediction models pretrained with existing student responses to previous assessment questions and is generalisable to the new assessment questions by leveraging distributed word embedding techniques. Researchers should consider the most appropriate way to encode the assessment questions in ways that early prediction models are able to infer relationships between the questions and gameplay behaviour to make accurate predictions of student competencies#FRE#
#IPC# game-based learning; natural language processing; predictive student modelling#FPC#
#IRF# Abdi H., Williams L.J., Principal component analysis, Wiley Interdisciplinary Reviews: Computational Statistics, 2, 4, pp. 433-459, (2010); 
Alonso-Fernandez C., Martinez-Ortiz I., Caballero R., Freire M., Fernandez-Manjon B., Predicting students' knowledge after playing a serious game based on learning analytics data: A case study, Journal of Computer Assisted Learning, 36, 3, pp. 350-358, (2020); 
Benedetto L., Cappelli A., Turrin R., Cremonesi P., R2DE: A NLP approach to estimating IRT parameters of newly generated questions,  International Conference on Learning Analytics & Knowledge, pp. 412-421, (2020); 
Bingel J., Sogaard A., Identifying beneficial task relations for multi-task learning in deep neural networks,  conference of the European chapter of the Association for Computational Linguistics, pp. 164-169, (2017); 
Blaylock N., Allen J., Corpus-based, statistical goal recognition,  international joint conference on artificial intelligence, pp. 1303-1308, (2003); 
Condor A., Litster M., Pardos Z., Automatic short answer grading with SBERT on out-of-sample questions,  international conference on educational data mining, pp. 345-352, (2021); 
Corbett A.T., Anderson J.R., Knowledge tracing: Modeling the acquisition of procedural knowledge, User Modeling and User-Adapted Interaction, 4, 4, pp. 253-278, (1994); 
Dever D.A., Amon M.J., Vrzakova H., Wiedbusch M.D., Cloude E.B., Azevedo R., Capturing sequences of learners' self-regulatory interactions with instructional material during game-based learning using auto-recurrence quantification analysis, Frontiers in Psychology, 13, (2022); 
Dever D.A., Wiedbusch M., Cloude E.B., Lester J., Azevedo R., Scientific text comprehension during game-based learning: The impact of prior knowledge and emotions, Discourse Processes, 59, pp. 1-22, (2021); 
Embretson S.E., Reise S.P., Item response theory, (2013); 
Emerson A., Cloude E.B., Azevedo R., Lester J., Multimodal learning analytics for game-based learning, British Journal of Educational Technology, 51, 5, pp. 1505-1526, (2020); 
Emerson A., Sawyer R., Azevedo R., Lester J., Gaze-enhanced student modeling for game-based learning,  Conference on User Modeling, Adaptation, and Personalization, pp. 63-72, (2018); 
Emerson A., Smith A., Smith C., Rodriguez F., Min W., Wiebe E., Mott B., Boyer K.E., Lester J., Predicting early and often: Predictive student modeling for block-based programming environments,  international conference on educational data mining, pp. 39-48, (2019); 
Gasevic D., Greiff S., Shaffer D.W., Towards strengthening links between learning analytics and assessment: Challenges and potentials of a promising new bond, Computers in Human Behavior, 134, (2022); 
Geden M., Emerson A., Carpenter D., Rowe J., Azevedo R., Lester J., Predictive student modeling in game-based learning environments with word embedding representations of reflection, International Journal of Artificial Intelligence in Education, 31, 1, pp. 1-23, (2021); 
Geden M., Emerson A., Rowe J., Azevedo R., Lester J., Predictive student modeling in educational games with multi-task learning,  AAAI Conference on Artificial Intelligence, 34, 1, pp. 654-661, (2020); 
Henderson N., Kumaran V., Min W., Mott B., Wu Z., Boulden D., Lord T., Reichsman F., Dorsey C., Wiebe E., Lester J., Enhancing student competency models for game-based learning with a hybrid stealth assessment framework,  international conference on educational data mining, pp. 92-103, (2020); 
Henderson N., Min W., Emerson A., Rowe J., Lee S., Minogue J., Lester J., Early prediction of museum visitor engagement with multimodal adversarial domain adaptation,  international conference on educational data mining, pp. 93-104, (2021); 
Huang Z., Liu Q., Chen E., Zhao H., Gao M., Wei S., Su Y., Hu G., Question difficulty prediction for reading problems in standard tests,  AAAI conference on artificial intelligence, 31, pp. 1352-1359, (2017); 
Huang Z., Yin Y., Chen E., Xiong H., Su Y., Hu G., Ekt: Exercise-aware knowledge tracing for student performance prediction, IEEE Transactions on Knowledge and Data Engineering, 33, 1, pp. 100-115, (2019); 
Kim Y.J., Almond R.G., Shute V.J., Applying evidence-centered design for the development of game-based assessments in physics playground, International Journal of Testing, 16, 2, pp. 142-163, (2016); 
Liu M., Kitto K., Shum S.B., Combining factor analysis with writing analytics for the formative assessment of written reflection, Computers in Human Behavior, 120, (2021); 
Mayer R.E., Computer games in education, Annual Review of Psychology, 70, pp. 531-549, (2019); 
Min W., Baikadi A., Mott B., Rowe J., Liu B., Ha E.Y., Lester J., A generalized multidimensional evaluation framework for player goal recognition,  artificial intelligence and interactive digital entertainment conference, pp. 197-203, (2016); 
Min W., Frankosky M.H., Mott B.W., Rowe J.P., Smith A., Wiebe E., Boyer K.E., Lester J.C., DeepStealth: Game-based learning stealth assessment with deep neural networks, IEEE Transactions on Learning Technologies, 13, 2, pp. 312-325, (2019); 
Moon J., Ke F., Sokolikj Z., Automatic assessment of cognitive and emotional states in virtual reality-based flexibility training for four adolescents with autism, British Journal of Educational Technology, 51, 5, pp. 1766-1784, (2020); 
Nietfeld J.L., Predicting transfer from a game-based learning environment, Computers & Education, 146, (2020); 
Nietfeld J.L., Shores L.R., Hoffmann K.F., Self-regulation and gender within a game-based learning environment, Journal of Educational Psychology, 106, 4, pp. 961-973, (2014); 
Pedregosa F., Varoquaux G., Gramfort A., Michel V., Thirion B., Grisel O., Blondel M., Prettenhofer P., Weiss R., Dubourg V., Vanderplas J., Scikit-learn: Machine learning in python, Journal of Machine Learning Research, 12, pp. 2825-2830, (2011); 
Pennington J., Socher R., Manning C., GloVe: Global vectors for word representation, Proceedings of the 2014 conference on empirical methods in natural language processing, pp. 1532-1543, (2014); 
Peters H., Kyngdon A., Stillwell D., Construction and validation of a game-based intelligence assessment in Minecraft, Computers in Human Behavior, 119, (2021); 
Peters M., Neumann M., Iyyer M., Gardner M., Clark C., Lee K., Zettlemoyer L., Deep contextualized word representations, Proceedings of the 2018 conference of the north American chapter of the Association for Computational Linguistics: Human language technologies, pp. 2227-2237, (2018); 
Piech C., Bassen J., Huang J., Ganguli S., Sahami M., Guibas L.J., Sohl-Dickstein J., Deep knowledge tracing, Advances in neural information processing systems, pp. 505-513, (2015); 
Plass J., Mayer R., Homer B., Handbook of game-based learning, (2019); 
Robinson C., Yeomans M., Reich J., Hulleman C., Gehlbach H., Forecasting student achievement in MOOCs with natural language processing,  international conference on Learning Analytics & Knowledge, pp. 383-387, (2016); 
Rowe E., Almeda M.V., Asbell-Clarke J., Scruggs R., Baker R., Bardar E., Gasca S., Assessing implicit computational thinking in Zoombinis puzzle gameplay, Computers in Human Behavior, 120, (2021); 
Sharma K., Papamitsiou Z., Giannakos M., Building pipelines for educational data using AI and multimodal analytics: A “grey-box” approach, British Journal of Educational Technology, 50, 6, pp. 3004-3031, (2019); 
Shute V.J., Rahimi S., Stealth assessment of creativity in a physics video game, Computers in Human Behavior, 116, (2021); 
Shute V.J., Wang L., Greiff S., Zhao W., Moore G., Measuring problem solving skills via stealth assessment in an engaging video game, Computers in Human Behavior, 63, pp. 106-117, (2016); 
Su Y., Liu Q., Liu Q., Huang Z., Yin Y., Chen E., Ding C., Wei S., Hu G., Exercise-enhanced sequential modeling for student performance prediction,  AAAI conference on artificial intelligence, pp. 2435-2443, (2018); 
Sullivan F.R., Keith P.K., Exploring the potential of natural language processing to support microgenetic analysis of collaborative learning discussions, British Journal of Educational Technology, 50, 6, pp. 3047-3063, (2019); 
Taub M., Mudrick N.V., Azevedo R., Millar G.C., Rowe J., Lester J., Using multi-channel data with multi-level modeling to assess in-game performance during gameplay with Crystal Island, Computers in Human Behavior, 76, pp. 641-655, (2017); 
Taub M., Sawyer R., Lester J., Azevedo R., The impact of contextualized emotions on self-regulated learning and scientific reasoning during learning with a game-based learning environment, International Journal of Artificial Intelligence in Education, 30, pp. 97-120, (2020); 
Taub M., Sawyer R., Smith A., Rowe J., Azevedo R., Lester J., The agency effect: The impact of student agency on learning, emotions, and problem-solving behaviors in a game-based learning environment, Computers & Education, 147, pp. 1-19, (2020); 
Thaker K., Zhang L., He D., Brusilovsky P., Recommending remedial readings using student knowledge state,  International Conference on Educational Data Mining, pp. 233-244, (2020); 
Wu M., Mosse M., Goodman N., Piech C., Zero shot learning for code education: Rubric sampling with deep learning inference, Proceedings of the AAAI Conference on Artificial Intelligence, 33, 1, pp. 782-790, (2019); 
Xue K., Yaneva V., Runyon C., Baldwin P., Predicting the difficulty and response time of multiple choice questions using transfer learning,  workshop on innovative use of NLP for building educational applications, pp. 193-197, (2020); 
Yeung C.K., Deep-IRT: Make deep learning based knowledge tracing explainable using item response theory, arXiv preprint arXiv, (2019); 
Zhang H., Magooda A., Litman D., Correnti R., Wang E., Matsmura L.C., Howe E., Quintana R., eRevise: Using natural language processing to provide formative feedback on text evidence usage in student writing,  AAAI Conference on Innovative Applications of Artificial Intelligence, 33, pp. 9619-9625, (2019)#FRF#
