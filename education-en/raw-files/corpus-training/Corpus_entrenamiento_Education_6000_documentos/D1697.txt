#ITI#What predicts variation in reliability and validity of online peer assessment? A large-scale cross-context study#FTI#
#IRE# Background: For peer assessment, reliability (i.e., consistency in ratings across peers) and validity (i.e., consistency of peer ratings with instructors or experts) are frequently examined in the research literature to address a central concern of instructors and students. Although the average levels are generally promising, both reliability and validity can vary substantially from context to context. Meta-analyses have identified a few moderators that are related to peer assessment reliability/validity, but they have lacked statistical power to systematically investigate many moderators or disentangle correlated moderators. Objectives: The current study fills this gap by addressing what variables influence peer assessment reliability/validity using a large-scale, cross-context dataset from a shared online peer assessment platform. Methods: Using multi-level structural equation models, we examined three categories of variables: (1) variables related to the context of peer assessment; (2) variables related to the peer assessment task itself; and (3) variables related to rating rubrics of peer assessment. Results and Conclusions: We found that the extent to which assessment documents varied in quality on the given rubric played a central role in mediating the effect from different predictors to peer assessment reliability/validity. Other variables that are significantly associated with reliability and validity included: Education Level, Language, Discipline, Average Ability of Peer Raters, Draft Number, Assignment Number, Class Size, Average Number of Raters, and Length of Rubric Description. The results provide information to guide practitioners on how to improve reliability and validity of peer assessments#FRE#
#IPC# peer assessment; reliability; validity#FPC#
#IRF# Standards for educational and psychological testing, (2014); 
Babcock P., Betts J.R., Reduced-class distinctions: Effort, ability, and the education production function, Journal of Urban Economics, 65, pp. 314-322, (2009); 
Birjandi P., Hadidi Tamjid N., The role of self-, peer and teacher assessment in promoting Iranian EFL learners' writing performance, Assessment & Evaluation in Higher Education, 37, 5, pp. 513-533, (2012); 
Bouzidi L., Jaillet A., Can online peer assessment be trusted?, Educational Technology & Society, 12, 4, pp. 257-268, (2009); 
Brennan R.L., Generalizability theory, Educational Measurement: Issues and Practice, 11, 4, pp. 27-34, (2005); 
Chang C.-C., Tseng K.-H., Chou P.-N., Chen Y.-H., Reliability and validity of Web-based portfolio peer assessment: A case study for a senior high school's students taking computer course, Computers & Education, 57, 1, pp. 1306-1316, (2011); 
Cho K., Schunn C.D., Scaffolded writing and rewriting in the discipline: A web-based reciprocal peer review system, Computers & Education, 48, 3, pp. 409-426, (2007); 
Cho K., Schunn C.D., Finding an optimal balance between agreement and performance in an online reciprocal peer evaluation system, Studies in Educational Evaluation, 56, pp. 94-101, (2018); 
Cho K., Schunn C.D., Wilson R.W., Validity and reliability of scaffolded peer assessment of writing from instructor and student perspectives, Journal of Educational Psychology, 98, 4, pp. 891-901, (2006); 
Cortina J.M., Apples and oranges (and pears, oh my!): The search for moderators in meta-analysis, Organizational Research Methods, 6, 4, pp. 415-439, (2016); 
de Alfaro L., Shavlovsky M., Dynamics of peer grading: An empirical study, The 9th International Conference on Educational Data Mining, pp. 62-69, (2016); 
Double K.S., McGrane J.A., Hopfenbeck T.N., The impact of peer assessment on academic performance: A meta-analysis of control group studies, Educational Psychology Review, 32, 2, pp. 481-509, (2019); 
Dynarski S., Hyman J., Schanzenbach D.W., Experimental evidence on the effect of childhood investment on postsecondary attainment and degree completion, Journal of Policy Analysis and Management, 32, 4, pp. 692-717, (2013); 
Ericsson K.A., Deliberate practice and acquisition of expert performance: A general overview, Academic Emergency Medicine, 15, 11, pp. 988-994, (2008); 
Falchikov N., Goldfinch J., Student peer assessment in higher education: A meta-analysis comparing peer and teacher marks, Review of Educational Research, 70, 3, pp. 287-322, (2000); 
Language difficulty ranking: Effective language learning, (2017); 
Gao Y., Schunn C.D., Yu Q., The alignment of written peer feedback with draft problems and its impact on revision in peer assessment, Assessment & Evaluation in Higher Education, 44, 2, pp. 294-308, (2019); 
Garcia-Loro F., Martin S., Ruiperez-Valiente J.A., San C.E., Castro M., Reviewing and analyzing peer review inter-rater reliability in a MOOC platform, Computers & Education, 154, 4, pp. 1-35, (2020); 
Gielen M., De Wever B., Structuring peer assessment: Comparing the impact of the degree of structure on peer feedback content, Computers in Human Behavior, 52, pp. 315-325, (2015); 
Gielen S., Dochy F., Onghena P., An inventory of peer assessment diversity, Assessment & Evaluation in Higher Education, 36, 2, pp. 137-155, (2011); 
Glass G.V., Meta-analysis at 25, (2000); 
Hu L., Bentler P.M., Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives, Structural Equation Modeling: A Multidisciplinary Journal, 6, 1, pp. 1-55, (1999); 
Jeffery D., Krassimir Y., Alison C., Kerry R., How to achieve accurate peer assessment for high value written assignments in a senior undergraduate course, Assessment & Evaluation in Higher Education, 41, 1, pp. 127-140, (2016); 
Jonsson A., Svingby G., The use of scoring rubrics: Reliability, validity and educational consequences, Educational Research Review, 2, 2, pp. 130-144, (2007); 
Klein S.P., Stecher B.M., Shavelson R.J., McCaffrey D., Ormseth T., Bell R.M., Othman A.R., Analytic versus holistic scoring of science performance tasks, Applied Measurement in Education, 11, 2, pp. 121-137, (1998); 
Li H., Bialo J.A., Xiong Y., Hunter C.V., Guo X., The effect of peer assessment on non-cognitive outcomes: A meta-analysis, Applied Measurement in Education, 34, 3, pp. 179-203, (2021); 
Li H., Xiong Y., Hunter C.V., Guo X., Tywoniw R., Does peer assessment promote student learning? A meta-analysis, Assessment & Evaluation in Higher Education, 45, 2, pp. 193-211, (2020); 
Li H., Xiong Y., Zang X., Kornhaber M.L., Lyu Y., Chung K.S., Suen H.K., Peer assessment in the digital age: A meta-analysis comparing peer and teacher ratings, Assessment & Evaluation in Higher Education, 41, 2, pp. 245-264, (2016); 
Li H., Zhao C., Long T., Huang Y., Shu F., Exploring the reliability and its influencing factors of peer assessment in massive open online courses, British Journal of Educational Technology, 52, pp. 2263-2277, (2021); 
Luxton-Reilly A., A systematic review of tools that support peer assessment, Computer Science Education, 19, 4, pp. 209-232, (2009); 
Magin D., Helmore P., Peer and teacher assessments of oral presentation skills: How reliable are they?, Studies in Higher Education, 26, 3, pp. 287-298, (2001); 
Markland D., The golden rule is that there are no golden rules: A commentary on Paul Barrett's recommendations for reporting model fit in structural equation modelling, Personality and Individual Differences, 42, 5, pp. 851-858, (2007); 
Marty M.C., Henning J.M., Willse J.T., Accuracy and reliability of peer assessment of athletic training psychomotor laboratory skills, Journal of Athletic Training, 45, 6, pp. 609-614, (2010); 
Matsuno S., Self-, peer-, and teacher-assessments in Japanese university EFL writing classrooms, Language Testing, 26, 1, pp. 75-100, (2009); 
Meek S.E.M., Blakemore L., Marks L., Is peer review an appropriate form of assessment in a MOOC? Student participation and performance in formative peer review, Assessment and Evaluation in Higher Education, 42, 6, pp. 1000-1013, (2017); 
Miller P.J., The effect of scoring criteria specificity on peer and self-assessment, Assessment & Evaluation in Higher Education, 28, 4, pp. 383-394, (2003); 
Muthen L.K., Muthen B.O., Mplus User's Guide, (2017); 
Panadero E., Romero M., Strijbos J.W., The impact of a rubric and friendship on construct validity of peer assessment, perceived fairness and comfort, and performance, Studies in Educational Evaluation, 39, 4, pp. 195-203, (2013); 
Patchan M.M., Schunn C.D., Clark R.J., Accountability in peer assessment: Examining the effects of reviewing grades on peer ratings and peer feedback, Studies in Higher Education, 43, pp. 2263-2278, (2017); 
Piech C., Huang J., Chen Z., Do C., Ng A., Koller D., Tuned models of peer assessment in MOOCs, Proceedings of the 6th International Conference on Educational Data Mining, pp. 153-160, (2013); 
Rasouli S., Esfandiari R., Severity differences across proficiency levels among peer-assessors, Journal of Modern Research in English Language Studies, 9, 2, pp. 173-196, (2022); 
Russell J., Van Horne S., Ward A.S., Bettis E.A., Gikonyo J., Variability in students' evaluating processes in peer assessment with calibrated peer review, Journal of Computer Assisted Learning, 33, pp. 178-190, (2017); 
Sadler P., Good E., The impact of self- and peer-grading on student learning, Educational Assessment, 11, 1, pp. 1-31, (2006); 
Saito H., EFL classroom peer assessment: Training effects on rating and commenting, Language Testing, 25, 4, pp. 553-581, (2008); 
Sanchez C.E., Atkinson K.M., Koenka A.C., Moshontz H., Cooper H., Self-grading and peer-grading for formative and summative assessments in 3rd through 12th grade classrooms: A meta-analysis, Journal of Educational Psychology, 109, 8, pp. 1049-1066, (2017); 
Schunn C.D., Writing to learn and learning to write through SWoRD, Adaptive educational technologies for literacy instruction, (2016); 
Schunn C.D., Godley A., DeMartino S., The reliability and validity of peer review of writing in high school AP English classes, Journal of Adolescent & Adult Literacy, 60, 1, pp. 13-23, (2016); 
Sung Y.-T., Chang K.-E., Chang T.-H., Yu W.-C., How many heads are better than one? The reliability and validity of teenagers' self- and peer assessments, Journal of Adolescence, 33, 1, pp. 135-145, (2010); 
Topping K.J., Peer assessment between students in colleges and universities, Review of Educational Research, 68, 3, pp. 249-276, (1998); 
Tseng S.C., Tsai C.C., On-line peer assessment and the role of the peer feedback: A study of high school computer course, Computers & Education, 49, 4, pp. 1161-1174, (2007); 
van Zundert M., Sluijsmans D., van Merrienboer J., Effective peer assessment processes: Research findings and future directions, Learning and Instruction, 20, 4, pp. 270-279, (2010); 
Weiner I.B., Freedheim D.K., Schinka J.A., Velicer W.F., Handbook of psychology, research methods in psychology, (2003); 
Wu Y., Schunn C.D., From feedback to revisions: Effects of feedback features and perceptions, Contemporary Educational Psychology, 60, (2020); 
Wu Y., Schunn C.D., The effects of providing and receiving peer feedback on writing performance and learning of secondary school students, American Educational Research Journal, 58, 3, pp. 492-526, (2020); 
Wu Y., Schunn C.D., When peers agree, do students listen? The central role of feedback quality and feedback frequency in determining uptake of feedback, Contemporary Educational Psychology, 62, (2020); 
Wu Y., Schunn C.D., From plans to actions: A process model for why feedback features influence feedback implementation, Instructional Science, 49, pp. 365-394, (2021); 
Xiao Y., Lucking R., The impact of two types of peer assessment on students' performance and satisfaction within a Wiki environment, Internet and Higher Education, 11, pp. 186-193, (2008); 
Zhang F., Schunn C., Li W., Long M., Changes in the reliability and validity of peer assessment across the college years, Assessment & Evaluation in Higher Education, 45, 8, pp. 1073-1087, (2020); 
Zheng L., Zhang X., Cui P., The role of technology-facilitated peer assessment and supporting strategies: A meta-analysis, Assessment & Evaluation in Higher Education, 45, 3, pp. 372-386, (2019); 
Zong Z., Schunn C.D., Wang Y., What aspects of online peer feedback robustly predict growth in students' task performance?, Computers in Human Behavior, 124, (2021)#FRF#
