#ITI#Learning analytics application to examine validity and generalizability of game-based assessment for spatial reasoning#FTI#
#IRE# Game-based assessment (GBA), a specific application of games for learning, has been recognized as an alternative form of assessment. While there is a substantive body of literature that supports the educational benefits of GBA, limited work investigates the validity and generalizability of such systems. In this paper, we describe applications of learning analytics methods to provide evidence for psychometric qualities of a digital GBA called Shadowspect, particularly to what extent Shadowspect is a robust assessment tool for middle school students' spatial reasoning skills. Our findings indicate that Shadowspect is a valid assessment for spatial reasoning skills, and it has comparable precision for both male and female students. In addition, students' enjoyment of the game is positively related to their overall competency as measured by the game regardless of the level of their existing spatial reasoning skills. Practitioner notes What is already known about this topic: Digital games can be a powerful context to support and assess student learning. Games as assessments need to meet certain psychometric qualities such as validity and generalizability. Learning analytics provide useful ways to establish assessment models for educational games, as well as to investigate their psychometric qualities. What this paper adds: How a digital game can be coupled with learning analytics practices to assess spatial reasoning skills. How to evaluate psychometric qualities of game-based assessment using learning analytics techniques. Investigation of validity and generalizability of game-based assessment for spatial reasoning skills and the interplay of the game-based assessment with enjoyment. Implications for practice and/or policy: Game-based assessments that incorporate learning analytics can be used as an alternative to pencil-and-paper tests to measure cognitive skills such as spatial reasoning. More training and assessment of spatial reasoning embedded in games can motivate students who might not be on the STEM tracks, thus broadening participation in STEM. Game-based learning and assessment researchers should consider possible factors that affect how certain populations of students enjoy educational games, so it does not further marginalize specific student populations#FRE#
#IPC# enjoyment; game-based assessment; generalizability; learning analytics; spatial reasoning; validity#FPC#
#IRF# Standards for Educational and Psychological Testing: National Council on Measurement in Education, (2014); 
Anderson M., Jiang J., Teens, social media & technology 2018, Pew Research Center, 31, 2018, pp. 1673-1689, (2018); 
Auer E.M., Mersy G., Marin S., Blaik J., Landers R.N., Using machine learning to model trace behavioral data from a game-based assessment, International Journal of Selection and Assessment, 30, 1, pp. 82-102, (2022); 
Baker R.S., Corbett A.T., Wagner A.Z., Human classification of low-fidelity replays of student actions, Proceedings of the educational data mining workshop at the 8th international conference on intelligent tutoring systems, 2002, pp. 29-36, (2006); 
Basu S., Disalvo B., Rutstein D., Xu Y., Roschelle J., Holbert N., The role of evidence centered design and participatory design in a playful assessment for computational thinking about data, Proceedings of the 51st ACM Technical Symposium on Computer Science Education, pp. 985-991, (2020); 
Bellotti F., Berta R., De Gloria A., Designing effective serious games: Opportunities and challenges for research, International Journal of Emerging Technologies in Learning, 5, 2010, pp. 22-35, (2010); 
Breiman L., Random forests, Machine Learning, 45, 1, pp. 5-32, (2001); 
Chen F., Cui Y., Chu M.-W., Utilizing game analytics to inform and validate digital game-based assessment with evidence-centered game design: A case study, International Journal of Artificial Intelligence in Education, 30, 3, pp. 481-503, (2020); 
Clements D.H., Battista M.T., Geometry and spatial reasoning, Handbook of research on mathematics teaching and learning, pp. 420-464, (1992); 
Cohen C.A., Hegarty M., Inferring cross sections of 3d objects: A new spatial thinking test, Learning and Individual Differences, 22, 6, pp. 868-874, (2012); 
Courtney L., Graham S., ‘It's like having a test but in a fun way’ young learners' perceptions of a digital game-based assessment of early language learning, Language Teaching for Young Learners, 1, pp. 161-186, (2019); 
De Freitas S., Are games effective learning tools? a review of educational games, Journal of Educational Technology & Society, 21, 2, pp. 74-84, (2018); 
DiCerbo K.E., Game-based assessment of persistence, Journal of Educational Technology & Society, 17, 1, pp. 17-28, (2014); 
DiCerbo K.E., Shute V., Kim Y.J., The future of assessment in technology rich environments: Psychometric considerations, Learning, design, and technology: An international compendium of theory, research, practice, and policy, pp. 1-21, (2017); 
Eyupoglu T.F., Nietfeld J.L., Intrinsic motivation in game-based learning environments, Game-based assessment revisited, pp. 85-102, (2019); 
Ferla J., Valcke M., Cai Y., Academic self-efficacy and academic selfconcept: Reconsidering structural relationships, Learning and Individual Differences, 19, 4, pp. 499-505, (2009); 
Freire M., Serrano-Laguna A., Manero B., Martinez-Ortiz I., Moreno-Ger P., Fernandez-Manjon B., Game learning analytics: Learning analytics for serious games, Learning, design, and technology, pp. 1-29, (2016); 
Fu F.L., Su R.C., Yu S.C., EGameFlow: A scale to measure learners' enjoyment of e-learning games, Computers & Education, 52, 1, pp. 101-112, (2009); 
Ganley C.M., Vasilyeva M., Dulaney A., Spatial ability mediates the gender difference in middle school students' science performance, Child Development, 85, 4, pp. 1419-1432, (2014); 
Gasevic D., Greiff S., Shaffer D.W., Towards Strengthening Links between Learning Analytics and Assessment: Challenges and Potentials of a Promising New Bond, Computers in Human Behavior, (2022); 
Gee J.P., Video games, learning, and “content”, Games: Purpose and potential in education, pp. 43-53, (2009); 
Genuer R., Poggi J.-M., Tuleau-Malot C., Variable selection using random forests, Pattern Recognition Letters, 31, 14, pp. 2225-2236, (2010); 
Harris D., Lowrie T., Logan T., Hegarty M., Spatial reasoning, mathematics, and gender: Do spatial constructs differ in their contribution to performance?, British Journal of Educational Psychology, 91, 1, pp. 409-441, (2021); 
Hartmann T., Klimmt C., Gender and computer games: Exploring females' dislikes, Journal of Computer-Mediated Communication, 11, 4, pp. 910-931, (2006); 
Hou X., Nguyen H.A., Richey J.E., McLaren B.M., Exploring how gender and enjoyment impact learning in a digital learning game, International Conference on Artificial Intelligence in Education, pp. 255-268, (2020); 
Ibrahim R., Jaafar A., Educational games (eg) design framework: Combination of game design, pedagogy and content modeling, 2009 international conference on electrical engineering and informatics, 1, pp. 293-298, (2009); 
Kim Y.J., Almond R.G., Shute V.J., Applying evidence-centered design for the development of game-based assessments in physics playground, International Journal of Testing, 16, 2, pp. 142-163, (2016); 
Kim Y.J., Ifenthaler D., Game-based assessment: The past ten years and moving forward, Game-based assessment revisited, pp. 3-11, (2019); 
Kim Y.J., Ruiperez-Valiente J.A., Tan P., Rosenheck L., Klopfer E., Towards a process to integrate learning analytics and evidence-centered design for game-based assessment, Companion Proceedings of the 9th International Learning Analytics and Knowledge Conference, pp. 204-205, (2019); 
Kim Y.J., Shute V.J., The interplay of game elements with psychometric qualities, learning, and enjoyment in game-based assessment, Computers & Education, 87, pp. 340-356, (2015); 
Law D.J., Pellegrino J.W., Hunt E.B., Comparing the tortoise and the hare: Gender differences and experience in dynamic spatial reasoning tasks, Psychological Science, 4, 1, pp. 35-40, (1993); 
Linn M.C., Petersen A.C., Emergence and characterization of sex differences in spatial ability: A meta-analysis, Child Development, 56, 6, pp. 1479-1498, (1985); 
Loecher M., Unbiased variable importance for random forests, Communications in Statistics-Theory and Methods, 51, pp. 1-13, (2020); 
Lowrie T., Jorgensen R., Equity and spatial reasoning: Reducing the mathematical achievement gap in gender and social disadvantage, Mathematics Education Research Journal, 30, 1, pp. 65-75, (2018); 
Mavridis A., Tsiatsos T., Game-based assessment: Investigating the impact on test anxiety and exam performance, Journal of Computer Assisted Learning, 33, 2, pp. 137-150, (2017); 
McClurg P.A., Chaille C., Computer games: Environments for developing spatial cognition?, Journal of Educational Computing Research, 3, 1, pp. 95-111, (1987); 
Mislevy R.J., Almond R.G., Lukas J.F., A brief introduction to evidence-centered design, ETS Research Report Series, 2003, 1, pp. 1-29, (2003); 
Mislevy R.J., Behrens J.T., Dicerbo K.E., Levy R., Design and discovery in educational assessment: Evidence-centered design, psychometrics, and educational data mining, Journal of Educational Data Mining, 4, 1, pp. 11-48, (2012); 
Mislevy R.J., Corrigan S., Oranje A., DiCerbo K., Bauer M.I., von Davier A., John M., Psychometrics and game-based assessment, Technology and testing: Improving educational and psychological measurement, pp. 23-48, (2016); 
Mulligan J., Woolcott G., Mitchelmore M., Davis B., Connecting mathematics learning through spatial reasoning, Mathematics Education Research Journal, 30, 1, pp. 77-87, (2018); 
Nuttall R.L., Casey M.B., Pezaris E., Spatial ability as a mediator of gender differences on mathematics tests: A biological-environmental framework, Gender differences in mathematics: An integrative psychological approach, pp. 121-142, (2005); 
Olkun S., Altun A., Smith G., Computers and 2d geometric learning of Turkish fourth and fifth graders, British Journal of Educational Technology, 36, 2, pp. 317-326, (2005); 
Owen V.E., Baker R.S., Fueling prediction of player decisions: Foundations of feature engineering for optimized behavior modeling in serious games, Technology, Knowledge and Learning, 25, 2, pp. 225-250, (2020); 
Papic M.M., Mulligan J.T., Mitchelmore M.C., Assessing the development of preschoolers' mathematical patterning, Journal for Research in Mathematics Education, 42, 3, pp. 237-268, (2011); 
Pellicone A., Holbert N., Disalvo B., Kumar V., Berland M., Who played the game correctly? data signatures of interaction in playful assessment, Proceedings of the 2019 connected learning summit, pp. 138-146, (2019); 
Prensky M., Digital game-based learning, Computers in Entertainment (CIE), 1, 1, (2003); 
Ramful A., Lowrie T., Logan T., Measurement of spatial ability: Construction and validation of the spatial reasoning instrument for middle school students, Journal of Psychoeducational Assessment, 35, 7, pp. 709-727, (2017); 
Reilly D., Neumann D.L., Andrews G., Gender differences in spatial ability: Implications for stem education and approaches to reducing the gender gap for parents and educators, Visual-spatial ability in stem education, pp. 195-224, (2017); 
Rizvi S., Gauthier A., Cukurova M., Mavrikis M., Examining Gender Differences in Game-Based Learning Through BKT Parameter Estimation, International Conference on Artificial Intelligence in Education, pp. 600-606, (2022); 
Ruiperez-Valient J.A., Gomez M.J., Martinez P.A., Kim Y.J., Ideating and developing a visualization dashboard to support teachers using educational games in the classroom, IEEE Access, 9, pp. 83467-83481, (2021); 
Ruiperez-Valient J.A., Kim Y.J., Baker R.S., Martinez P.A., Lin G.C., he affordances of multivariate elo-based learner modeling in game-based assessment, IEEE Transactions on Learning Technologies, pp. 1-14, (2022); 
Scharkow M., Festl R., Vogelgesang J., Quandt T., Beyond the “core-gamer”: Genre preferences and gratifications in computer games, Computers in Human Behavior, 44, pp. 293-298, (2015); 
Shaffer D.W., Gee J.P., The right kind of gate: Computer games and the future of assessment, Technology-based assessments for 21st century skills: Theoretical and practical implications from modern research, pp. 211-228, (2012); 
Shute V.J., Stealth assessment in computer-based games to support learning, Computer Games and Instruction, 55, 2, pp. 503-524, (2011); 
Shute V.J., Ventura M., Ke F., The power of play: The effects of Portal 2 and Lumosity on cognitive and noncognitive skills, Computers & Education, 80, pp. 58-67, (2015); 
Stieff M., When is a molecule three dimensional? a task-specific role for imagistic reasoning in advanced chemistry, Science Education, 95, 2, pp. 310-336, (2011); 
Sundre D.L., Wise S.L., Motivation filtering’: An exploration of the impact of low examinee motivation on the psychometric quality of tests, (2003); 
Uttal D., Cohen C., Spatial thinking and STEM education: When, why and how, Psychology of learning and motivation, 57, pp. 147-181, (2012); 
Ventura M., Shute V., The validity of a game-based assessment of persistence, Computers in Human Behavior, 29, 6, pp. 2568-2572, (2013); 
Wai J., Uttal D.H., Why spatial reasoning matters for education policy, (2018); 
Wise S.L., An investigation of the differential effort received by items on a low-stakes computer-based test, Applied Measurement in Education, 19, 2, pp. 95-114, (2006); 
Yang J.C., Chen S.Y., Effects of gender differences and spatial abilities within a digital pentominoes game, Computers & Education, 55, 3, pp. 1220-1233, (2010)#FRF#
