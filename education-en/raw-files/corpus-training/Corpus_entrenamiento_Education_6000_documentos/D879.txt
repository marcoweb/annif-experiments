#ITI#Testing the Impact of Novel Assessment Sources and Machine Learning Methods on Predictive Outcome Modeling in Undergraduate Biology#FTI#
#IRE# High levels of attrition characterize undergraduate science courses in the USA. Predictive analytics research seeks to build models that identify at-risk students and suggest interventions that enhance student success. This study examines whether incorporating a novel assessment type (concept inventories [CI]) and using machine learning (ML) methods (1) improves prediction quality, (2) reduces the time point of successful prediction, and (3) suggests more actionable course-level interventions. A corpus of university and course-level assessment and non-assessment variables (53 variables in total) from 3225 students (over six semesters) was gathered. Five ML methods were employed (two individuals, three ensembles) at three time points (pre-course, week 3, week 6) to quantify predictive efficacy. Inclusion of course-specific CI data along with university-specific corpora significantly improved prediction performance. Ensemble ML methods, in particular the generalized linear model with elastic net (GLMNET), yielded significantly higher area under the curve (AUC) values compared with non-ensemble techniques. Logistic regression achieved the poorest prediction performance and consistently underperformed. Surprisingly, increasing corpus size (i.e., amount of historical data) did not meaningfully impact prediction success. We discuss the roles that novel assessment types and ML techniques may play in advancing predictive learning analytics and addressing attrition in undergraduate science education#FRE#
#IPC# Assessment; Concept inventories; Course- vs. institution-specific data sources; Introductory biology; Machine learning; Predictive learning analytics#FPC#
#IRF# Ade R., Deshmukh P.R., Classification of students by using an incremental ensemble of classifiers, Proceedings of the 3Rd International Conference on Reliability, pp. 1-5, (2014); 
Adekitan A.I., Noma-Osaghae E., Data mining approach to predicting the performance of first year student in a university using the admissions requirement, Education and Information Technologies, 24, 2, pp. 1527-1543, (2019); 
Alexandro D., Aiming for Success: Evaluating Statistical and Machine Learning Methods to Predict High School Student Performance and Improve Early Warning Systems, (Doctoral Dissertation). University of Connecticut, Storrs, Connecticut., (2018); 
Allensworth E.M., Easton J.Q., The on-track indicator as a predictor of high school graduation, (2005); 
International Joint Conference on Neural Networks (IJCNN), pp. 713-720, (2017); 
Ambler G., Omar R.Z., Royston P., A comparison of imputation techniques for handling missing predictor values in a risk model with a binary outcome, Statistical methods in medical research, 16, 3, pp. 277-298, (2007); 
Vision and Change in Undergraduate Biology Education, (2011); 
Amrieh E.A., Hamtini T., Alijarah I., Mining educational data to predict student’s academic performance using ensemble methods, International Journal of Database Theory and Application, 9, 8, pp. 119-136, (2016); 
Anderson D.L., Fisher K.M., Norman G.J., Development and evaluation of the conceptual inventory of natural selection, Journal of research in science teaching, 39, 10, pp. 952-978, (2002); 
Aulck L., Aras R., Li L., L'Heureux C., Lu P., West J., STEM-ming the tide: Predicting STEM attrition using student transcript data, (2017); 
Baker M., Reproducibility crisis, Nature, 533, 26, pp. 353-366, (2016); 
Baker R., Data mining for education, International Encyclopedia of Education, 7, 3, pp. 112-118, (2010); 
Bayer J., Bydzovska H., Geryk J., Obsivac T., Popelinsky L., Predicting Drop-Out from Social Behaviour of Students. Proceedings of the 5Th International Conference on Educational Data Mining - EDM 2012, pp. 103-109, (2012); 
Beck H.P., Davidson W.D., Establishing an early warning system: Predicting low grades in college students from survey of academic orientations scores, Research in Higher Education, 42, 6, pp. 709-723, (2001); 
Beemer J., Spoon K., He L., Fan J., Levine R., Ensemble learning for estimating individualized treatment effects in student success studies, International Journal of Artificial Intelligence in Education, 28, 3, pp. 315-335, (2018); 
Beggrow E.P., Ha M., Nehm R.H., Pearl D., Boone W.J., Assessing scientific practices using machine-learning methods: How closely do they match clinic interview performance?, Journal of Science Education and Technology, 23, 1, pp. 160-182, (2014); 
Bekkar M., Djemaa H.K., Alitouche T.A., Evaluation measures for models assessment over imbalanced data sets, Journal of Information Engineering and Applications, 3, 10, pp. 27-38, (2013); 
Bennett R.E., Formative assessment: A critical review, Assessment in Education: Principles, Policy, & Practice, 18, 1, pp. 5-25, (2011); 
Brooks C., Thompson C., Predictive modelling in teaching and learning, C. Lang, G. Siemens, A. Wise, & D. Gašević. Handbook of Learning Analytics, pp. 61-68, (2017); 
Bucos M., Dragulescu B., Predicting student success using data generated in traditional educational environments, TEM Journal, 7, 3, (2018); 
Buuren S.V., Groothuis-Oudshoorn K., mice: Multivariate Imputation by Chained Equations in R, Journal of Statistical Software, 45, 3, pp. 1-68, (2010); 
Chang M.J., Sharkness J., Hurtado S., Newman C.B., What matters in college for retaining aspiring scientists and engineers from underrepresented racial groups, Journal of Research in Science Teaching, 51, 5, pp. 555-580, (2014); 
Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: Synthetic minority over-sampling technique, Journal of artificial intelligence research, 16, pp. 321-357, (2002); 
Chung J.Y., Lee S., Dropout early warning systems for high school students using machine learning, Children and Youth Services Review, 96, pp. 346-353, (2019); 
Cohen W., Fast effective rule induction, Machine Learning Proceedings 1995, pp. 115-123, (1995); 
Colton J., Sbeglia G., Finch S.J., Nehm R.H., A quasi-experimental study of short-and long-term learning of evolution in misconception-focused classes. Paper presented at the American Educational Research Association International conference, (2018); 
Conijn R., Snijders C., Kleingeld A., Matzat U., Predicting student performance from LMS data: A comparison of 17 blended courses using Moodle LMS, IEEE Transactions on Learning Technologies, 10, 1, pp. 17-29, (2016); 
Costa E.B., Fonseca B., Santana M.A., de Araujo F.F., Rego J., Evaluating the effectiveness of educational data mining techniques for early prediction of students' academic failure in introductory programming courses, Computers in Human Behavior, 73, pp. 247-256, (2017); 
Croninger R.G., Douglas K.M., Missing data and institutional research, New directions for institutional research, 2005, 127, pp. 33-49, (2005); 
Cox B.E., McIntosh K., Reason R.D., Terenzini P.T., Working with missing data in higher education research: A primer and real-world example, The Review of Higher Education, 37, 3, pp. 377-402, (2014); 
Daniel B.K., Improving the Pedagogy of Research Methodology through Learning Analytics, Electronics Journal of Business Research Methods, 1, (2019); 
Davidson A.C., Hinkley D.V., Bootstrap Methods and their Application (Volume 1), Cambridge University Press, (1997); 
Dobson J.L., The use of formative online quizzes to enhance class preparation and scores on summative exams, Advances in Physiology Education, 32, 4, pp. 297-302, (2008); 
Domingos P., A general method for making classifiers cost-sensitive, Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 155-164, (1999); 
Dong Y., Peng C.Y.J., Principled missing data methods for researchers, SpringerPlus, 2, 1, (2013); 
Eddy S.L., Brownell S.E., Wenderoth M.P., Gender gaps in achievement and participation in multiple introductory biology classrooms, CBE - Life Sciences Education, 13, 3, pp. 478-492, (2014); 
Epling M., Timmons S., Wharrad H., An educational panopticon? New technology, nurse education and surveillance, Nurse Education Today., 23, 6, pp. 412-418, (2003); 
Feng M., Beck J.E., Heffernan N.T., Using Learning Decomposition and Bootstrapping with Randomization to Compare the Impact of Different Educational Interventions on Learning, International Working Group on Educational Data Mining, (2009); 
Fox J., Weisberg S., An R Companion to Applied Regression, Sage Publications., (2018); 
Friedman J., Hastie T., Tibshirani R., The Elements of Statistical Learning (Volume 1, No, (2001); 
Furrow R.E., Hsu J.L., Concept inventories as a resource for teaching evolution, Evolution: Education and Outreach, 12, 1, (2019); 
Getachew M., Students' Placement Prediction Model: A Data Mining Approach. (Doctoral Dissertation), (2017); 
Graham J.W., Missing data analysis: Making it work in the real world, Annual Review of Psychology, 60, 1, pp. 549-576, (2009); 
Grimes P., The overconfident principles of economics student: An examination of a metacognitive skill, Journal of Economic Education, 33, 1, pp. 15-30, (2002); 
Gundlach E., Richards K., Nelson D., Levesque-Bristol C., A comparison of student attitudes, statistical reasoning, performance, and perceptions for web-augmented traditional, fully online, and flipped sections of a statistical literacy class, Journal of Statistics Education, 23, 1, (2015); 
Hake R.R., Interactive-engagement versus traditional methods: A six-thousand-student survey of mechanics test data for introductory physics courses, American Journal of Physics, 66, pp. 64-74, (1998); 
Haudek K.C., Kaplan J.J., Knight J., Long T., Merrill J., Munn A., Et al., Harnessing technology to improve formative assessment of student conceptions in STEM: Forging a national network, CBE - Life Science Education, 10, 2, pp. 149-155, (2011); 
Ioannidis J.P., Why most published research findings are false, PLoS medicine, 2, 8, (2005); 
Jago R., Zakeri I., Baranowski T., Watson K., Decision boundaries and receiver operating characteristic curves: New methods for determining accelerometer cutpoints, Journal of sports sciences, 25, 8, pp. 937-944, (2007); 
Jakobsen J.C., Gluud C., Wetterslev J., Winkel P., When and how should multiple imputation be used for handling missing data in randomised clinical trials – a practical guide with flowcharts, BMC Medical Research Methodology, 17, 1, (2017); 
James G., Witten D., Hastie T., Tibshirani R., An Introduction to Statistical Learning, 112, (2013); 
Jimenez S., Angeles-Valdez D., Villicana V., Reyes-Zamorano E., Alcala-Lozano R., Gonzalez-Olvera J.J., Garza-Villarreal E.A., Identifying cognitive deficits in cocaine dependence using standard tests and machine learning, Progress in Neuro-Psychopharmacology and Biological Psychiatry, (2019); 
Kalinowski S.T., Leonard M.J., Taper M.L., Development and validation of the conceptual assessment of natural selection (CANS), CBE - Life Sciences Education, 15, 4, (2016); 
Khobragade L.P., Mahadik P., Students' academic failure prediction using data mining, International Journal of Advanced Research in Computer and Communication Engineering, 4, 11, pp. 290-298, (2015); 
Kirpich A., Ainsworth E.A., Wedow J.M., Newman J.R., Michailidis G., McIntyre L.M., Variable selection in omics data: A practical evaluation of small sample sizes, PLoS, 13, 6, (2018); 
Knowles J.E., Of needles and haystacks: Building an accurate statewide dropout early warning system in Wisconsin, Journal of Educational Data Mining, 7, 3, pp. 18-67, (2015); 
Kotsiantis S., Educational data mining: A case study for predicting dropout-prone students, International Journal of Knowledge Engineering and Soft Data Paradigms, 1, 2, pp. 101-111, (2009); 
Kotsiantis S., Patriarcheas K., Xenos M., A combinational incremental ensemble of classifiers as a technique for predicting students’ performance in distance education, Knowledge-Based Systems, 23, 6, pp. 529-535, (2010); 
Krstajic D., Buturovic L.J., Leahy D.E., Thomas S., Cross-validation pitfalls when selecting and assessing regression and classification models, Journal of cheminformatics, 6, 1, pp. 1-15, (2014); 
Kuhn M., Caret: Classification and regression training, Astrophysics Source Code Library, (2015); 
Kumar M., Singh A., Evaluation of data mining techniques for predicting student's performance, International Journal of Modern Education and Computer Science, 9, 8, pp. 25-31, (2017); 
Lavesson N., Davidsson P., Quantifying the impact of learning algorithm parameter tuning, AAAI, 6, pp. 395-400, (2006); 
Lee U.J., Sbeglia G.C., Ha M., Finch S.J., Nehm R.H., Clicker score trajectories and concept inventory scores as predictors for early warning systems for large STEM classes, Journal of Science Education and Technology, 24, 6, pp. 848-860, (2015); 
Libarkin J.C., Concept Inventories in Higher Education Science. Prepared for the National Research Council Promising Practices in Undergraduate STEM Education Workshop 2, (2008); 
Lisitsyna L., Oreshin S., Machine Learning Approach of Predicting Learning Outcomes of MOOCs to Increase Its Performance, Smart Education and E-Learning, 2019, pp. 107-115, (2019); 
Lu F., Petkova E., A comparative study of variable selection methods in the context of developing psychiatric screening instruments, Statistics in Medicine, 33, 3, pp. 401-421, (2014); 
Lu W., Benson R., Glaser K., Platts L., Corna L., Worts D., Et al., Relationship between employment histories and frailty trajectories in later life: Evidence from the English Longitudinal Study of Ageing, Journal of Epidemiology Community Health, 71, 5, pp. 439-445, (2017); 
Luengo J., Garcia S., Herrera F., On the choice of the best imputation methods for missing values considering three groups of classification methods, Knowledge and information systems, 32, 1, pp. 77-108, (2012); 
Luo Y., Li Z., Guo H., Cao H., Song C., Guo X., Zhang Y., Predicting congenital heart defects: A comparison of three data mining methods, PLoS ONE, 12, 5, (2017); 
Lykourentzou I., Giannoukos I., Mpardis G., Nikolopoulos V., Loumos V., Early and dynamic student achievement prediction in e-learning courses using neural networks, Journal of the American Society for Information Science and Technology, 60, 2, pp. 372-380, (2009); 
Macfadyen L.P., Dawson S., Mining LMS data to develop an “early warning system” for educators: A proof of concept, Computers & education, 54, 2, pp. 588-599, (2010); 
Marquez-Vera C., Morales C.R., Soto S.V., Predicting school failure and dropout by using data mining techniques, IEEE Revista Iberoamericana de Tecnologias del Aprendizaje, 8, 1, pp. 7-14, (2013); 
Marquez-Vera C., Romero C., Ventura S., Predicting School Failure Using Data Mining, 4Th International Conference on Educational Data Mining, (2010); 
Marr B., Big Data: Using SMART big data, analytics and metrics to make better decisions and improve performance, John Wiley & Sons, (2015); 
Marshall A., Altman D.G., Royston P., Holder R.L., Comparison of techniques for handling missing covariate data within prognostic modelling studies: A simulation study, BMC medical research methodology, 10, 1, (2010); 
Minaei-Bidgoli B., Kashy D.A., Kortemeyer G., Punch W.F., Predicting student performance: An application of data mining methods with an education web-based system, 33Rd Annual Frontiers in Education, 2003. FIE 2003., 1, (2003); 
Moharreri K., Ha M., Nehm R.H., EvoGrader: An online formative assessment tool for automatically evaluating written evolutionary explanations, Evolution: Education and Outreach, 7, 1, (2014); 
Mwitondi K.S., Said R.A., A data-based method for harmonising heterogeneous data modelling techniques across data mining applications, Journal of statistics applications and probability, 2, 3, pp. 157-162, (2013); 
Thinking Evolutionarily: Evolution Education across the Life Sciences, (2012); 
High school dropout, graduation, and completion rates: Better data, better measures, Better Decisions, (2011); 
Nehm R.H., Biology education research: Building integrative frameworks for teaching and learning about living systems, Disciplinary and Interdisciplinary Science Education Research, 1, 1, (2019); 
Nehm R.H., Reilly L., Biology majors' knowledge and misconceptions of natural selection, BioScience, 57, 3, pp. 263-272, (2007); 
Nehm R.H., Beggrow E.P., Opfer E.P., Ha M., Reasoning about natural selection: diagnosing contextual competency using the ACORNS instrument, The American Biology Teacher, 74, 2, pp. 92-98, (2012); 
Neild R.C., Balfanz R., Herzog L., An early warning system. Educational leadership, 65, 2, pp. 28-33, (2007); 
Opfer J.E., Nehm R.H., Ha M., Cognitive foundations for science assessment design: Knowing what students know about evolution, Journal of Research in Science Teaching, 49, 6, pp. 744-777, (2012); 
Orr R., Foster S., Increasing student success using online quizzing in introductory (majors) biology, CBE - Life Sciences Education, 12, 3, pp. 509-514, (2013); 
Patel J.A., Sharma P., Big data for better health planning, In 2014 International Conference on Advances in Engineering & Technology Research (ICAETR-2014)., pp. 1-5, (2014); 
PCAST, PsCoSaT, Engage to excel: Producing one million additional college graduates with degrees in science, technology, engineering, and mathematics, (2012); 
Perkins N.J., Schisterman E.F., The inconsistency of “optimal” cutpoints obtained using two criteria based on the receiver operating characteristic curve, American Journal of Epidemiology, 163, 7, pp. 670-675, (2006); 
Peugh J.L., Enders C.K., Missing data in educational research: A review of reporting practices and suggestions for improvement, Review of Educational Research, 74, 4, pp. 525-556, (2004); 
Prinsloo P., Archer E., Barnes G., Chetty Y., Van Zyl D., Big(ger) data as better data in open distance learning, International Review of Research in Open and Distributed Learning, 16, 1, pp. 284-306, (2015); 
(2017); 
Radwan A., Cataltepe Z., Improving performance prediction on education data with noise and class imbalance, Intelligent Automation & Soft Computing, pp. 1-8, (2017); 
Ransom C.J., Kitchen N.R., Camberato J.J., Carter P.R., Ferguson R.B., Et al., Statistical and machine learning methods evaluated for incorporating soil and weather into corn nitrogen recommendations, Computers and Electronics in Agriculture, 164, (2019); 
Rath K., Peterfreund A., Xenos S., Bayliss F., Carnal N., Supplemental instruction in introductory biology I: Enhancing the performance and retention of underrepresented minority students, CBE- Life Science Education, 6, 3, pp. 203-216, (2007); 
Rebok G.W., Ball K., Guey L.T., Jones R.N., Kim H.Y., Kim H.Y., Et al., Ten-year effects of the advanced cognitive training for independent and vital elderly cognitive training trial on cognition and everyday functioning in older adults, Journal of the American Geriatrics Society, 62, 1, pp. 16-24, (2014); 
Rokach L., Ensemble-based classifiers, Artificial Intelligence Review, 33, 1-2, pp. 1-39, (2010); 
Rovira S., Puertas E., Igual L., Data-driven system to predict academic grades and dropout, PLoS, 12, 2, (2017); 
Sayre E.C., Heckler A.F., Peaks and decays of student knowledge in an introductory E&M course, Physical Review Special Topics-Physics Education Research, 5, 1, pp. 1-5, (2009); 
Schisterman E.F., Perkins N.J., Liu A., Bondell H., Optimal cut-points and its corresponding Youden index to discriminate individuals using pooled blood samples, Epidemiology, 16, 1, pp. 73-81, (2005); 
Talking about Leaving Revisited. Springer, (2019); 
Silva C., Fonseca J., Educational Data Mining: A Literature Review, Europe and MENA Cooperation Advances in Information and Communication Technologies: Advances in Intelligent Systems and Computing, 520, pp. 87-94, (2017); 
Tekin A., Early prediction of students' grade point averages at graduation: A data mining approach, Eurasian Journal of Educational Research, 54, pp. 207-226, (2014); 
Thai-Nghe N., Gantner Z., Schmidt-Thieme L., Cost-sensitive learning methods for imbalanced data, The 2010 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2010); 
Tops W., Callens M., Lammertyn J., Van Hees V., Brysbaert M., Identifying students with dyslexia in higher education, Annals of Dyslexia, 62, 3, pp. 186-203, (2012); 
Vovides Y., Sanchez-Alonso S., Mitropoulou V., Nickmans G., The use of e-learning course management systems to support learning strategies and to improve self-regulated learning, Educational Research Review, 2, 1, pp. 64-74, (2007); 
Wasserstein R.L., Lazar N.A., The ASA statement on p-values: Context, process, and purpose, The American Statistician, 70, 2, pp. 129-133, (2016); 
Waterhouse J.K., Carroll M.C., Beeman P.B., National council licensure examination success: Accurate prediction of student performance on the post-1988 examination, Journal of Professional Nursing, 9, 5, pp. 278-283, (1993); 
Watson C., Li F., Godwin J., Predicting performance in an introductory programming course by logging and analyzing student programming behavior, 2013 IEEE 13Th International Conference on Advanced Learning Technologies, pp. 319-323, (2013); 
Xue Y., Testing the Differential Efficacy of Data Mining Techniques to Predicting Student Outcomes in Higher Education. (Doctoral Dissertation), (2018); 
Yang Q., Wu X., 10 challenging problems in data mining research, International Journal of Information Technology & Decision Making, 5, pp. 597-604, (2006); 
Yukselturk E., Ozekes S., Turel Y.K., Predicting dropout student: An application of data mining methods in an online education program, European Journal of Open, Distance, and e-learning, 17, 1, pp. 118-133, (2014); 
Zhai X., Yin Y., Pellegrino J.W., Haudek K.C., Shi L., Applying machine learning in science assessments: A systematic review, Studies in Science Education, 56, 1, pp. 111-151, (2020)#FRF#
