#ITI#Can large language models replace humans in systematic reviews? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages#FTI#
#IRE# Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a “human-out-of-the-loop” approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching “human-like” levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance#FRE#
#IPC# artificial intelligence (AI); GPT; large language models (LLMs); machine learning; natural language processing (NLP); systematic reviews#FPC#
#IRF# Aromataris E., Fernandez R., Godfrey C.M., Holly C., Khalil H., Tungpunkom P., Summarizing systematic reviews: methodological development, conduct and reporting of an umbrella review approach, JBI evid, 13, 3, pp. 132-140, (2015); 
Borah R., Brown A.W., Capers P.L., Kaiser K.A., Analysis of the time and workers needed to conduct systematic reviews of medical interventions using data from the PROSPERO registry, BMJ Open, 7, 2, (2017); 
Michelson M., Reuter K., The significant cost of systematic reviews and meta-analyses: a call for greater involvement of machine learning to assess the promise of clinical trials, Contemp Clin Trials Commun, 16, (2019); 
Fiorini N., Canese K., Starchenko G., Et al., Best match: new relevance search for PubMed, PLoS Biol, 16, 8, (2018); 
Blaizot A., Veettil S.K., Saidoung P., Et al., Using artificial intelligence methods for systematic review in health sciences: a systematic review, Res Synth Methods, 13, 3, pp. 353-362, (2022); 
Van Dijk S.H.B., Brusse-Keizer M.G.J., Bucsan C.C., Van der Palen J., Doggen C.J.M., Lenferink A., Artificial intelligence in systematic reviews: promising when appropriately used, BMJ Open, 13, 7, (2023); 
Kebede M.M., Le Cornet C., Fortner R.T., In-depth evaluation of machine learning methods for semi-automating article screening in a systematic review of mechanistic literature, Res Synth Methods, 14, 2, pp. 156-172, (2023); 
Mahuli S.A., Rai A., Mahuli A.V., Kumar A., Application ChatGPT in conducting systematic reviews and meta-analyses, Br Dent J, 235, 2, pp. 90-92, (2023); 
Moreno-Garcia C.F., Jayne C., Elyan E., Aceves-Martins M., A novel application of machine learning and zero-shot classification methods for automated abstract screening in systematic reviews, Decis Anal, 6, (2023); 
Nugroho P.A., Anna N.E.V., Ismail N., The shift in research trends related to artificial intelligence in library repositories during the coronavirus pandemic. Libr Hi Tech, (2023); 
Santos A.O.D., da Silva E.S., Couto L.M., Reis G.V.L., Belo V.S., The use of artificial intelligence for automating or semi-automating biomedical literature analyses: a scoping review, J Biomed Inform, 142, (2023); 
Giummarra M.J., Lau G., Grant G., Gabbe B.J., A systematic review of the association between fault or blame-related attributions and procedures after transport injury and health and work-related outcomes, Accid Anal Prev, 135, (2020); 
Rogers C.R., Matthews P., Xu L., Et al., Interventions for increasing colorectal cancer screening uptake among African-American men: a systematic review and meta-analysis, PloS One, 15, 9, (2020); 
Marshall I.J., Nye B., Kuiper J., Et al., Trialstreamer: a living, automatically updated database of clinical trial reports, J Am Med Inform Assoc, 27, 12, pp. 1903-1912, (2020); 
Goldkuhle M., Dimaki M., Gartlehner G., Et al., Nivolumab for adults with Hodgkin's lymphoma (a rapid review using the software RobotReviewer), Cochrane Database Syst Rev, 7, 7, (2018); 
Guo E., Gupta M., Deng J., Park Y.-J., Paget M., Naugler C., Automated paper screening for clinical reviews using large language models. arXiv, (2023); 
Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need. arXiv, (2017); 
Syriani E., David I., Kumar G., Assessing the ability of ChatGPT to screen articles for systematic reviews. arXiv, (2023); 
GPT-4 technical report. arXiv, (2023); 
Lawrence A., Houghton J., Thomas J., Weldon P., Where is the evidence: realising the value of grey literature for public policy and practice, Swinburne Institute for Social Research, (2014); 
Wang S., Scells H., Koopman B., Zuccon G., Can ChatGPT write a good Boolean query for systematic review literature search? arXiv, (2023); 
Alshami A., Elsayed M., Ali E., Eltoukhy A.E.E., Zayed T., Harnessing the power of ChatGPT for automating systematic review process: methodology, case study, limitations, and future directions, Systems, 11, 7, (2023); 
Beutel G., Geerits E., Kielstein J.T., Artificial hallucination: GPT on LSD?, Crit Care, 27, 1, (2023); 
Fromke C., Kirstein M., Zapf A., A semiparametric approach for meta-analysis of diagnostic accuracy studies with multiple cut-offs, Res Synth Methods, 13, 5, pp. 612-621, (2022); 
Patel A., Cooper N., Freeman S., Sutton A., Graphical enhancements to summary receiver operating characteristic plots to facilitate the analysis and reporting of meta-analysis of diagnostic test accuracy data, Res Synth Methods, 12, 1, pp. 34-44, (2021); 
Shreffler J., Huecker M.R., Diagnostic testing accuracy: sensitivity, specificity, predictive values and likelihood ratios, StatPearls, (2023); 
Wang Z., Nayfeh T., Tetzlaff J., O'Blenis P., Murad M.H., Error rates of human reviewers during abstract screening in systematic reviews, PloS One, 15, 1, (2020); 
Cohen J., A coefficient of agreement for nominal scales, Educ Psychol Meas, 20, 1, pp. 37-46, (1960); 
McHugh M.L., Interrater reliability: the kappa statistic, Biochem Med, 22, 3, pp. 276-282, (2012); 
Byrt T., Bishop J., Carlin J.B., Bias, prevalence and kappa, J Clin Epidemiol, 46, 5, pp. 423-429, (1993); 
Sampson M., Tetzlaff J., Urquhart C., Precision of healthcare systematic review searches in a cross-sectional sample, Res Synth Methods, 2, 2, pp. 119-125, (2011); 
Ivimey-Cook E.R., Noble D.W.A., Nakagawa S., Lajeunesse M.J., Pick J.L., Advice for improving the reproducibility of data extraction in meta-analysis, Res Synth Methods, 14, pp. 911-915, (2023); 
Beller E., Clark J., Tsafnat G., Et al., Making progress with the automation of systematic reviews: principles of the international collaboration for the automation of systematic reviews (ICASR), Syst Rev, 7, 1, (2018); 
Halamoda-Kenzaoui B., Rolland E., Piovesan J., Puertas Gallardo A., Bremer-Hoffmann S., Toxic effects of nanomaterials for health applications: how automation can support a systematic review of the literature?, J Appl Toxicol, 42, 1, pp. 41-51, (2022); 
Clark J., Glasziou P., Del Mar C., Bannach-Brown A., Stehlik P., Scott A.M., A full systematic review was completed in 2 weeks using automation tools: a case study, J Clin Epidemiol, 121, pp. 81-90, (2020); 
Nye B., Li J.J., Patel R., Et al., A corpus with multi-level annotations of patients, interventions and outcomes to support language processing for medical literature: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 197–207, (2018); 
Summerscales R.L., Argamon S., Bai S., Hupert J., Schwartz A., Automatic summarization of results from clinical trials, IEEE Int Conf Bioinformatics Biomed, 2011, pp. 372-377, (2011); 
Wallace B.C., Kuiper J., Sharma A., Extracting PICO sentences from clinical trial reports using supervised distant supervision, J Mach Learn Res, 17, (2016); 
Qureshi R., Shaughnessy D., Gill K.A.R., Robinson K.A., Li T., Agai E., Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?, Syst Rev, 12, 1, (2023); 
Jakesch M., Hancock J.T., Naaman M., Human heuristics for AI-generated language are flawed, Proc Natl Acad Sci U S A, 120, 11, (2023); 
Sun S., Meta-analysis of Cohen's kappa, Health Serv Outcomes Res Methodol., 11, pp. 145-163, (2011); 
Akinseloyin O., Jiang X., Palade V., A novel question-answering framework for automated citation screening using large language models. medRxiv, (2023)#FRF#
