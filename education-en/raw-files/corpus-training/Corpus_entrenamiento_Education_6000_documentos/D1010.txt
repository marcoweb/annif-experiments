#ITI#Distributional properties of the statistic of online student evaluations the mean does not mean what you think it means#FTI#
#IRE# Student Evaluations of Teaching (SETs) are an integral part of evaluating course outcomes. They are routinely used to evaluate teaching quality for the purposes of reappointment, promotion, and tenure (RPT), annual review, and the rehiring of adjunct faculty and lecturers. These evaluations are often based almost entirely on the mean or proportion of the ordinal overall score with no regard to statistical noise. This study examines the distribution of the statistic (mean or proportion) when SETs are administered online and in-person. Using non-parametric procedures, we show that the size of the 95% confidence interval of the statistic is a function of response rates. Prior to COVID-19, online administration of SETs resulted in significantly more uncertainty than in-person administration because the in-person response rates were higher. Due to a decrease in in-person response rates in the post-COVID vaccine period, both methods result in significant levels of uncertainty of the true statistic value. In classes of fewer than 30 students, the 95% confidence interval of the statistic is wide enough for instructors to be considered for a teaching award in one semester or below average in another semester, while holding teaching quality constant#FRE#
#IPC# bootstrap; online teaching evaluation; simulations; Student evaluations; survey administration mediums#FPC#
#IRF# Arbuckle J., Williams B.D., Students' Perceptions of Expressiveness: Age and Gender Effects on Teacher Evaluations, Sex Roles, 49, 9, pp. 507-516, (2003); 
Basow S.A., Student Evaluations of College Professors: When Gender Matters, Journal of Educational Psychology, 87, 4, pp. 656-665, (1995); 
Becker W.E., Bosshardt W., Watts M., How Departments of Economics Evaluate Teaching, The Journal of Economic Education, 43, 3, pp. 325-333, (2012); 
Becker W.E., Watts M., How Departments of Economics Evaluate Teaching, American Economic Review, 89, 2, pp. 344-349, (1999); 
Boring A., Gender Biases in Student Evaluations of Teaching, Journal of Public Economics, 145, pp. 27-41, (2017); 
Boysen G.A., Significant Interpretation of Small Mean Differences in Student Evaluations of Teaching Despite Explicit Warning to Avoid Overinterpretation, Scholarship of Teaching and Learning in Psychology, 1, 2, pp. 150-162, (2015); 
Braga M., Paccagnella M., Pellizzari M., Evaluating Students' Evaluations of Professors, Economics of Education Review, 41, pp. 71-88, (2014); 
Breitbach E., Sankaran C., Wagner J., The Movement to Online Course Evaluations: Do We Hear From More Complainers, Perspectives on Economic Education Research, 10, 1, pp. 41-56, (2016); 
Carrell S.E., West J.E., Does Professor Quality Matter? Evidence From Random Assignment of Students to Professors, Journal of Political Economy, 118, 3, pp. 409-432, (2010); 
Chisadza C., Nicholls N., Yitbarek E., Race and Gender Biases in Student Evaluations of Teachers, Economics Letters, 179, pp. 66-71, (2019); 
Clayson D.E., Student Evaluations of Teaching: Are they Related to what Students Learn? A Meta-analysis and Review of the Literature, Journal of Marketing Education, 31, 1, pp. 16-30, (2009); 
Cleveland W.S., Devlin S.J., Locally Weighted Regression: An Approach to Regression Analysis by Local Fitting, Journal of the American Statistical Association, 83, 403, pp. 596-610, (1988); 
Conover W.J., Practical Nonparametric Statistics, (1998); 
Dommeyer C.J., Baum P., Chapman K.S., Hanna R.W., Attitudes of Business Faculty Towards Two Methods of Collecting Teaching Evaluations: Paper Vs. Online, Assessment & Evaluation in Higher Education, 27, 5, pp. 455-462, (2002); 
Dommeyer C.J., Baum P., Hanna R.W., Chapman K.S., Gathering Faculty Teaching Evaluations by in-class and Online Surveys: Their Effects on Response Rates and Evaluations, Assessment & Evaluation in Higher Education, 29, 5, pp. 611-623, (2004); 
Donovan J., Mader C.E., Shinsky J., Constructive Student Feedback: Online Vs. Traditional Course Evaluations, Journal of Interactive Online Learning, 9, 3, pp. 283-296, (2010); 
Efron B., Tibshirani R.J., An Introduction to the Bootstrap, (1994); 
Fan Y., Shepherd L.J., Slavich E., Waters D., Stone M., Abel R., Johnston E.L., Gender and Cultural Bias in Student Evaluations: Why Representation Matters, PLoS ONE, 14, 2, (2019); 
Fike D.S., Doyle D.J., Connelly R.J., Online Vs. Paper Evaluations of Faculty: When Less Is Just As Good, Journal of Effective Teaching, 10, 2, pp. 42-54, (2010); 
Gamliel E., Davidovitz L., Online Versus Traditional Teaching Evaluation: Mode Can Matter, Assessment & Evaluation in Higher Education, 30, 6, pp. 581-592, (2005); 
Guder F., Malliaris M., Online and Paper Course Evaluations, American Journal of Business Education (AJBE), 3, 2, pp. 131-138, (2010); 
He J., Freeman L.A., Can We Trust Teaching Evaluations when Response Rates are Not High? Implications From a Monte Carlo Simulation, Studies in Higher Education, 46, 9, pp. 1934-1948, (2021); 
Heath N.M., Lawyer S.R., Rasmussen E.B., Web-based Versus Paper-and-pencil Course Evaluations, Teaching of Psychology, 34, 4, pp. 259-261, (2007); 
MacNell L., Driscoll A., Hunt A.N., What's in a Name: Exposing Gender Bias in Student Ratings of Teaching, Innovative Higher Education, 40, 4, pp. 291-303, (2015); 
McCullough B.D., Radson D., Analysing Student Evaluations of Teaching: Comparing Means and Proportions, Evaluation & Research in Education, 24, 3, pp. 183-202, (2011); 
Morrison K., Online and Paper Evaluations of Courses: a Literature Review and Case Study, Educational Research and Evaluation, 19, 7, pp. 585-604, (2013); 
Sankaran C., Wagner J., Breitbach E., Rethinking How We Evaluate Teaching Effectiveness: Does Only the Mean Matter?, Perspectives on Economic Education Research, 11, 1, pp. 73-87, (2018); 
Scott D.W., Multivariate Density Estimation: Theory, Practice, and Visualization, (2015)#FRF#
