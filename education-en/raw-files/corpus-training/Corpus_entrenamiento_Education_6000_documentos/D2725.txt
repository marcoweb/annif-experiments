#ITI#Why multimedia might matter: The impact of animations and images on item performance and test-taker behaviour#FTI#
#IRE# The use of animations and images in technology-based assessments (TBAs) represents a significant change in assessment design. To ensure that appropriate inferences can be drawn from assessments that use multimedia stimuli, their impact on test-taker performance and behaviour must be investigated. To achieve this, an experiment was conducted with 251 Irish post-primary students using an animated and text-image version of the same TBA of scientific literacy. Eye movement (n = 33) and interview data (n = 12) were also collected as a measure of test-taker attentional behaviour. Overall, there was no significant difference in test-taker performance when identical items used animated or text-image stimuli. However, items with dynamic stimuli often had higher discrimination indices indicating that these items were better at distinguishing between those with differing levels of knowledge. Eye movement data also revealed that dynamic item stimuli encouraged longer average fixation durations on the response area of an item. These findings indicate that multimedia stimuli may potentially affect how test-takers interact with online assessments. This has implications for what claims can be made about a learner's performance on an assessment. Recommendations for policy, practice and future research are considered. Practitioner notes What is already known about this topic: The use of multimedia stimuli in the form of diagrams, high-resolutions images, animations, and simulations are becoming more commonplace in technology-based assessments (TBAs) for post-primary aged learners. It is unclear what impact the use of multimedia stimuli can have on an individual's performance and behaviour in assessment/testing contexts. Eye movement data can be used to support our understanding of test-takers' interactions with TBAs. What this paper adds: By comparing the use of different types of multimedia stimuli (animations vs images), this study has responded to calls for a more in-depth examination of test items involving multimedia stimuli for TBAs. While there was no difference in test-taker performance between those who saw test items with different forms of multimedia stimuli, key differences in attentional behaviour were noted. Test-takers interacted with the assessment differently pending the multimedia stimuli used. The current study showed that dynamic stimuli may be a way to improve item discrimination, which is generally desirable in assessments. Implications for practice and/or policy: Certain design features appeared to add additional ‘assessment load’. This information could be leveraged to improve test item design and test specifications. It may also encourage test-developers to reconsider what claims they make about individuals who complete assessments with these features. Eye-tracking technology has huge potential to support research in online assessment environments#FRE#
#IPC# assessment; computer-based exams; multimedia; post-primary; technology-based assessments#FPC#
#IRF# Standards for educational and psychological testing, (2014); 
Arslan B., Jiang Y., Gong T., Keehner M., The effect of drag-and-drop item type design on test-takers performance and strategy use, (2019); 
Belzak W.C.M., Testing differential item functioning in small samples, Multivariate Behavioural Research, 55, 5, pp. 722-747, (2019); 
Boud D., Assessment and learning: Contradictory or complimentary?, Assessment for learning in higher education, pp. 35-48, (1995); 
Brams S., Ziv G., Levin O., Spitz J., Wagemans J., Williams A.M., Helsen W.F., The relationship between gaze behavior, expertise, and performance: A systematic review, Psychological Bulletin, 145, 10, pp. 980-1027, (2019); 
Braun V., Clarke V., Using thematic analysis in psychology, Qualitative Research in Psychology, 3, 2, pp. 77-101, (2006); 
Bryant W., Developing a strategy for using technology-enhanced items in large-scale standardized tests, Practical Assessment, Research & Evaluation, 22, 1, pp. 1-5, (2017); 
Carney R.N., Levin J.R., Pictorial illustrations still improve students' learning from text, Educational Psychology Review, 14, pp. 5-26, (2002); 
Carter B., Luke S., Best practices in eye tracking research, International Journal of Psychophysiology, 155, pp. 49-62, (2020); 
Chatterji M., Insights, emerging taxonomies, and theories of action toward improving validity, Validity and test use: An international dialogue on educational assessment, accountability and equity, pp. 273-330, (2013); 
Coskun A., Cagiltay K., A systematic review of eye-tracking-based research on animated multimedia learning, Journal of Computer Assisted Learning, 38, 2, pp. 581-598, (2022); 
Dalrymple K., Manner M., Harmelink K., Teska E., Elison J., An examination of recording accuracy and precision from eye tracking data from toddlerhood to adulthood, Frontiers in Psychology, 9, (2018); 
Dancy M.H., Beichner R., Impact of animation on assessment of conceptual understanding in physics, Physical Review Special Topics—Physics Education Research, 2, 1, pp. 1-7, (2006); 
About the DEIS programme, (2022); 
Downing S., Haladyna T., Handbook of test development, (2006); 
Elbabour F., Alhadreti O., Mayhew P., Eye tracking in retrospective think-aloud usability testing: Is there added value?, Journal of Usability Studies, 12, 3, pp. 95-110, (2017); 
Hessels R.S., Kemner C., van den Boomen C., Hooge I., The area-of-interest problem in eyetracking research: A noise-robust solution for face and sparse stimuli, Behavioural Research, 48, pp. 1694-1712, (2016); 
Holmqvist K., Nystrom M., Andersson R., Dewhurst R., Jarodzka H., Van de Weijer J., Eye tracking: A comprehensive guide to methods and measures, (2011); 
Hyona J., The use of eye movements in the study of multimedia learning, Learning and Instruction, 20, 2, pp. 172-176, (2010); 
Just M., Carpenter P., A theory of reading: From eye fixations to comprehension, Psychological Review, 87, pp. 329-355, (1980); 
Karakolidis A., O'Leary M., Scully D., Animated videos in assessment: Comparing validity evidence from and test-takers' reactions to an animated and a text-based situational judgement test, International Journal of Testing, 21, pp. 57-79, (2021); 
Kirschner P., Park B., Malone S., Jarodzka H., Toward a cognitive theory of multimedia assessment, Learning, design, and technology, pp. 1-23, (2016); 
Kuncel N.R., Crede M., Thomas L., The validity of self-reported grade point averages, class ranks, and test scores: A meta-analysis and review of the literature, Review of Educational Research, 75, 1, pp. 63-82, (2005); 
Lai M., Tsai M., Yang F., Hsu C., Liu T., Lee S., Lee M., Chiou G., Liang J., Tsai C., A review of using eye-tracking technology in exploring learning from 2000 to 2012, Educational Research Review, 10, pp. 90-115, (2013); 
Lane S., Commentary II, Validation of score meaning for the next generation of assessments, pp. 136-147, (2017); 
Lehane P., Scully D., O'Leary M., ‘Time to figure out what to do’: Understanding the nature of Irish post-primary students' interactions with computer-based exams (CBEs) that use multimedia stimuli, Irish Educational Studies, 41, 1, pp. 5-25, (2022); 
Lindner M., Ihme J., Sass S., Koller O., How representational pictures enhance students' performance and test-taking pleasure in low-stakes assessment, European Journal of Psychological Assessment, 34, 6, pp. 376-385, (2018); 
Lindner M., Ludtke O., Grund S., Koller O., The merits of representational pictures in educational assessment: Evidence for cognitive and motivational effects in a time-on-task analysis, Contemporary Educational Psychology, 51, pp. 482-492, (2017); 
Luke S., Asplund A., Prereaders’ eye movements during shared storybook reading are language-mediated but not predictive, Visual Cognition, 26, 5, pp. 351-365, (2018); 
Malone S., Brunken R., Assessment of driving expertise using multiple choice questions including static vs. animated presentation of driving scenarios, Accident Analysis and Prevention, 51, pp. 112-119, (2013); 
Mayer R., Cognitive theory of multimedia learning, The Cambridge handbook of multimedia learning, pp. 43-71, (2014); 
Mayer R., Using multimedia for e-learning, Journal of Computer Assisted Learning, 33, pp. 403-423, (2017); 
Moon J., Keehner M., Katz I., Affordances of item formats and their effects on test-taker cognition under uncertainty, Educational Measurement: Issues and Practice, 38, 1, pp. 54-62, (2019); 
External exams, (2022); 
PISA: 2015 technical report, (2017); 
PISA 2015 assessment and analytical framework: Science, reading, mathematic, financial literacy and collaborative problem solving, (2017); 
PISA 2018 technical report, (2020); 
PISA 2022 assessment and analytical framework, (2020); 
Orquin J.L., Holmqvist K., Threats to the validity of eye-movement research in psychology, Behaviour Research Methods, 50, 4, pp. 1645-1656, (2018); 
Rayner K., White S.J., Johnson R., Liversedge S.P., Raeding wrods with jubmled lettres: There is a cost, Psychological Science, 17, 3, pp. 192-193, (2006); 
Russell M., A framework for examining the utility of technology-enhanced items, Journal of Applied Testing Technology, 17, 1, pp. 20-32, (2016); 
Leaving certificate computer science, (2021); 
Tobii A.B., Eye tracker data quality test report: Accuracy, precision, and detected gaze under optimal conditions—controlled environment for Tobii Pro Fusion, (2020); 
Tuzinski K., Simulations for personnel selection: An introduction, Simulations for personnel selection, pp. 1-16, (2013); 
Vorstenbosch M., Bouter S., van den Hurk M., Kooloos J., Bolhuis S., Laan R., Exploring the validity of assessment in anatomy: Do images influence cognitive processes used in answering extended matching questions?, Anatomical Sciences Education, 7, 2, pp. 107-116, (2014); 
Wu H., Chang C., Chen C.L.D., Yeh T.K., Liu C.C., Comparison of earth science achievement between animation-based and graphic-based testing designs, Research in Science Education, 40, pp. 639-673, (2010); 
Zagerman J., Pfeil U., Reiterer H., Measuring cognitive load using eye tracking technology in visual computing, pp. 78-89, (2016)#FRF#
