#ITI#It is like a friend to me: Critical usage of automated feedback systems by self-regulating English learners in higher education#FTI#
#IRE#This paper explores international students’ engagement with educational technology for self-regulated English learning at an Australian university. Despite the increased use of automated feedback systems (AFSs) for language assessment, students’ critical engagement with them for independent learning remains under-researched. The study primarily employed a qualitative approach to understand the students’ preferred AFS tools and critical engagement throughout their personalised learning journeys but it also included a small-scale quantitative component. Data were gathered from seven students’ eportfolios, focus group interviews as well as a survey among 32 participants. Results highlight positive perceptions and successful use of AFSs, with students leveraging these tools to identify improvement areas, track progress and gain confidence. The study emphasises the importance of course structure, teacher guidance and a combination of human and automated feedback, in fostering learner autonomy and emotional selfregulation. The paper underscores the potential for sustained use of AFSs beyond the cours, and the significance of guiding learners to critically use these tools for ongoing learning and growth rather than dependence. These findings have significant implications, as readily available artificial intelligence tools such as ChatGPT hold great pedagogical potential for self-regulated learning within and beyond the language learning field. Implications for practice or policy • Instructors can use AFSs as effective tools to help English learners in higher education when scaffolding critical engagement with automated feedback and emotional selfregulation and providing adaptability, as such scaffolding and flexibility are essential for mitigating the limitations of AFSs. • Course leaders and universities should consider investing in AFSs as they can elevate the availability and sustainability of feedback for language enhancement and potentially any other type of learning#FRE#
#IPC#automated feedback systems (AFSs); computer-and mobile-assisted language learning; ELSA; engagement; English language proficiency (ELP); Grammarly; self-regulated learning (SRL)#FPC#
#IRF#Alderson J. C., Haapakangas E.-L., Huhta A., Nieminen L., Ullakonoja R., The diagnosis of reading in a second or foreign language, (2014); 
Arkoudis S., Baik C., Richardson S., English language standards in higher education: From entry to exit, (2012); 
Bandura A., Self-efficacy: Toward a unifying theory of behavioral change, Psychological Review, 84, 2, pp. 191-215, (1977); 
Benzie H. J., Graduating as a ‘native speaker’: International students and English language proficiency in higher education, Higher Education Research & Development, 29, 4, pp. 447-459, (2010); 
Bonanno H., Jones J., The MASUS procedure: Measuring the academic skills of university students: A diagnostic assessment, (2007); 
Braun V., Clarke V., Thematic analysis: A practical guide, (2021); 
Butler D. L., Winne P. H., Feedback and self-regulated learning: A theoretical synthesis, Review of Educational Research, 65, 3, pp. 245-281, (1995); 
Cavaleri M. R., Dianati S., You want me to check your grammar again? The usefulness of an online grammar checker as perceived by students, Journal of Academic Language and Learning, 10, 1, pp. A223-A236, (2016); 
Chen C.-F. E., Cheng W.-Y. E. C., Beyond the design of automated writing evaluation: Pedagogical practices and perceived learning effectiveness in EFL writing classes, Language Learning & Technology, 12, 2, pp. 94-112, (2008); 
Clark T., Endres H., Computer-based diagnostic assessment of high school students’ grammar skills with automated feedback-an international trial, Assessment in Education: Principles, Policy & Practice, 28, 5-6, pp. 602-632, (2021); 
Debuse J. C., Lawley M., Shibl R., Educators' perceptions of automated feedback systems, Australasian Journal of Educational Technology, 24, 4, pp. 374-386, (2008); 
Dikli S., Bleyle S., Automated essay scoring feedback for second language writers: How does it compare to instructor feedback?, Assessing Writing, 22, pp. 1-17, (2014); 
Du Boulay B., Mitrovic A., Yacef K., Handbook of artificial intelligence in education, (2023); 
Ellis R., Second language acquisition, teacher education and language pedagogy, Language Teaching, 43, 2, pp. 182-201, (2010); 
Evanini K., Zechner K., Overview of automated speech scoring, Automated speaking assessment, pp. 3-20, (2019); 
Fang Y., Roscoe R. D., McNamara D. S., Artificial intelligence-based assessment in education, Handbook of artificial intelligence in education, pp. 485-504, (2023); 
Grimes D., Warschauer M., Utility in a fallible tool: A multi-site case study of automated writing evaluation, The Journal of Technology, Learning and Assessment, 8, 6, pp. 1-43, (2010); 
Halliday M. A. K., Language as social semiotic: The social interpretation of language and meaning, 42, (1978); 
Han C., Lu X., Can automated machine translation evaluation metrics be used to assess students’ interpretation in the language learning classroom?, Computer Assisted Language Learning, 36, 5-6, pp. 1-24, (2021); 
Hattie J., Timperley H., The power of feedback, Review of Educational Research, 77, 1, (2007); 
Hoang G. T. L., Kunnan A. J., Automated essay evaluation for English language learners: A case study of MY Access, Language Assessment Quarterly, 13, 4, pp. 359-376, (2016); 
Jing B., A longitudinal study on the long-term Impact of the Personalised English Language Enhancement course, (2024); 
Kim M., Action research on advanced bilingual enhancement in translator education, Caught in the middle: Language use and translation, pp. 195-213, (2014); 
Kim M., A personalised autonomous model to resolve a prolonged dilemma in international students’ English language needs in higher education, Higher Education Research & Development, 42, 3, pp. 603-618, (2023); 
Kim M., Jing B., A personalised autonomous model for enhancing translation students’ linguistic competence, Translation and language teaching: Continuing the dialogue, pp. 127-146, (2019); 
Koltovskaia S., Student engagement with automated written corrective feedback (AWCF) provided by Grammarly: A multiple case study, Assessing Writing, 44, (2020); 
Krueger R. A., Casey M. A., Focus groups: A practical guide for applied research, (2014); 
Laufer B., Nation P., Cobb T., Vocabulary Levels Test (Productive), (2021); 
Lesgold A., Foreword, Handbook of artificial intelligence in education, pp. xvi-xviii, (2023); 
Lodge J. M., Thompson K., Corrin L., Mapping out a research agenda for generative artificial intelligence in tertiary education, Australasian Journal of Educational Technology, 39, 1, pp. 1-8, (2023); 
Marginson S., Nyland C., Sawir E., Forbes-Mewett H., International student security, (2010); 
Mory E., Feedback research revisited, Handbook of research on educational communications and technology, pp. 745-783, (2004); 
Nation P., Vocabulary Levels Test, (2022); 
ONeill R., Russell A., Stop! Grammar time: University students’ perceptions of the automated feedback program Grammarly, Australasian Journal of Educational Technology, 35, 1, pp. 42-56, (2019); 
Panadero E., Jonsson A., Botella J., Effects of self-assessment on self-regulated learning and self-efficacy: Four meta-analyses, Educational Research Review, 22, pp. 74-98, (2017); 
Ranalli J., Link S., Chukharev-Hudilainen E., Automated writing evaluation for formative assessment of second language writing: Investigating the accuracy and usefulness of feedback as part of argument-based validation, Educational Psychology, 37, 1, pp. 8-25, (2017); 
Read J., Post-admission language assessment of university students, (2016); 
Rochecouste J., Oliver R., English language growth and the international student, HERDSA Review of Higher Education, 1, pp. 63-81, (2014); 
Senior R. M., Transforming language classes into bonded groups, ELT Journal, 51, 1, pp. 3-11, (1997); 
Sun J. C. Y., Rueda R., Situational interest, computer self-efficacy and self-regulation: Their impact on student engagement in distance education, British Journal of Educational Technology, 43, 2, pp. 191-204, (2012); 
Sun P. C., Tsai R. J., Finger G., Chen Y. Y., Yeh D., What drives a successful e-learning? An empirical investigation of the critical factors influencing learner satisfaction, Computers & Education, 50, 4, pp. 1183-1202, (2008); 
Xi X., Automated scoring and feedback systems: Where are we and where are we heading?, Language Testing, 27, 3, pp. 291-300, (2010); 
Zhang Z. V., Engaging with automated writing evaluation (AWE) feedback on L2 writing: Student perceptions and revisions, Assessing Writing, 43, (2020); 
Zimmerman B. J., Attaining self-regulation: A social cognitive perspective, Handbook of self-regulation, pp. 13-39, (2000)#FRF#
