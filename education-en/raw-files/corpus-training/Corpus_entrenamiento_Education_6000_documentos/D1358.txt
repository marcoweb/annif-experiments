#ITI#A systematic review of educational online peer-review and assessment systems: charting the landscape#FTI#
#IRE# Over the past two decades, there has been an explosion of innovation in software tools that encapsulate and expand the capabilities of the widely used student peer assessment. While the affordances and pedagogical impacts of traditional in-person, “paper-and-pencil” peer assessment have been studied extensively and are relatively well understood, computerized (online) peer assessment introduced not only shifts in scalability and efficiency, but also entirely new capabilities and forms of social learning interactions, instructor leverage, and distributed cognition, that still need to be researched and systematized. Despite the ample research on traditional peer assessment and evidence of its efficacy, common vocabulary and shared understanding of online peer-assessment system design, including the variety of methods, techniques, and implementations, is still missing. We present key findings of a comprehensive survey based on a systematic research framework for examining and generalizing affordances and constraints of online peer-assessment systems. This framework (a) provides a foundation of a design-science metatheory of online peer assessment, (b) helps structure the discussion of user needs and design options, and (c) informs educators and system design practitioners. We identified two major themes in existing and potential research—orientation towards scaffolded learning vs. exploratory learning and system maturity. We also outlined an agenda for future studies.#FRE#
#IPC# Architectures for educational technology system; Framework; Online systems; Peer assessment; Peer review; Systematic review#FPC#
#IRF# Abramovich S., Schunn C., Higashi R.M., Are badges useful in education?: It depends upon the type of badge and expertise of learner, Educational Technology Research and Development, 61, 2, pp. 217-232, (2013); 
Alqassab M., Strijbos J.-W., Panadero E., Ruiz J.F., Warrens M., To J., A systematic review of peer assessment design elements, Educational Psychology Review, 35, 1, (2023); 
Babik D., Iyer L., Ford E., Towards a comprehensive online peer assessment system: Design outline, Lect. Notes Comput. Sci. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 7286 LNCS, pp. 1-8, (2012); 
Babik D., Investigating intersubjectivity in peer-review-based, technology-enabled knowledge creation and refinement social systems, (2015); 
Babik D., Gehringer E.F., Tinapple D., Pramudianto F., Song Y., Domain model and meta-language for peer review and assessment, Proceedings of Western DS, I, (2018); 
Babik D., Singh R., Zhao X., Ford E., What you think and what I think: Studying intersubjectivity in knowledge artifacts evaluation, Information Systems Frontiers, 19, 1, pp. 31-56, (2017); 
Babik D., Tinapple D., Gehringer E.F., Pramudianto F., The effect of visualization on students’ miscalibration in the context of online peer assessment, Proceedings of Western DS, I, (2017); 
Baikadi A., Schunn C.D., Ashley K.D., Impact of revision planning on peer-reviewed writing, (2016); 
Bandura A., Social foundations of thought and action: A social cognitive theory, (1986); 
Beach L.R., Self-directed student groups and college learning, Higher Education, 3, 2, pp. 187-200, (1974); 
Bostock S., Student peer assessment, (2000); 
Boud D., Falchikov N., Quantitative studies of student self-assessment in higher education: A critical analysis of findings, Higher Education, 18, 5, pp. 529-549, (1989); 
Bouzidi L., Jaillet A., Can online peer assessment be trusted?, Educational Technology & Society, 12, 4, pp. 257-268, (2009); 
Bull S., McCalla G., Modelling cognitive style in a peer help network, Instructional Science, 30, 6, pp. 497-528, (2002); 
Carey K., A future full of badges, The Chronicle of Higher Education, (2012); 
Carlson P., Smith R., Computer-mediated peer review: A comparison of calibrated peer review and Moodle’s workshop, Faculty Publications—English & Literature, (2017); 
Casilli C., Hickey D., Transcending conventional credentialing and assessment paradigms with information-rich digital badges, The Information Society, 32, 2, pp. 117-129, (2016); 
Chang C.-Y., Lee D.-C., Tang K.-Y., Hwang G.-J., Effect sizes and research directions of peer assessments: From an integrated perspective of meta-analysis and co-citation network, Computers & Education, 164, (2021); 
Cho K., Schunn C.D., Scaffolded writing and rewriting in the discipline: A web-based reciprocal peer review system, Computers & Education, 48, 3, pp. 409-426, (2007); 
Coleman J., Katz E., Menzel H., The diffusion of an innovation among physicians, Sociometry, 20, 4, pp. 253-270, (1957); 
Davies P., Computerized peer assessment, Innovations in Education and Teaching International, 37, 4, pp. 346-355, (2000); 
de Alfaro L., Shavlovsky M., CrowdGrader: A tool for crowdsourcing the evaluation of homework assignments, Proceedings of the 45th ACM Technical Symposium on Computer Science Education, (2014); 
Dennis A., Wixom B.H., Tegarden D., Systems analysis and design: An object-oriented approach with UML, (2015); 
Denzin N.K., Lincoln Y.S., The SAGE handbook of qualitative research, (2011); 
Doiron G., The value of online student peer review, evaluation and feedback in higher education, CDTL Brief, 6, pp. 1-2, (2003); 
Double K.S., McGrane J.A., Hopfenbeck T.N., The impact of peer assessment on academic performance: A meta-analysis of control group studies, Educational Psychology Review, 32, 2, pp. 481-509, (2020); 
Falchikov N., Boud D., Student self-assessment in higher education: A meta-analysis, Review of Educational Research, 59, 4, pp. 395-430, (1989); 
Fu Q.-K., Lin C.-J., Hwang G.-J., Research trends and applications of technology-supported peer assessment: A review of selected journal publications from 2007 to 2016, Journal of Computers in Education, 6, 2, pp. 191-213, (2019); 
Gehringer E.F., A survey of methods for improving review quality, New horizons in web based learning, pp. 92-97, (2014); 
Gehringer E.F., Board 60: PeerLogic: Web services for peer assessment, In 2019 ASEE Annual Conference & Exposition., (2019); 
Gehringer E.F., Ehresman L., Conger S.G., Wagle P., Reusable learning objects through peer review: The Expertiza approach, Innovate: Journal of Online Education, 3, 5, (2007); 
Gielen S., Dochy F., Onghena P., An inventory of peer assessment diversity, Assessment & Evaluation in Higher Education, 36, 2, pp. 137-155, (2011); 
Gikandi J.W., Morrow D., Davis N.E., Online formative assessment in higher education: A review of the literature, Computers & Education, 57, 4, pp. 2333-2351, (2011); 
A focus on content: The use of rubrics in peer review to guide students and instructors, (2011); 
Goldin I., Ashley K.D., Schunn C., Redesigning educational peer review interactions using computer tools, Journal of Writing Research, 4, 2, pp. 111-119, (2012); 
Hamer J., Some experiences with the “contributing student approach, SIGCSE Bulletin, 38, 3, pp. 68-72, (2006); 
Hamer J., Kell C., Spence F., Peer assessment using Aropä, Proceedings of the Ninth Australasian Conference on Computing Education, 66, pp. 43-54, (2007); 
Hevner A.R., March S.T., Park J., Ram S., Design science in information systems research, MIS Quarterly, 28, 1, pp. 75-105, (2004); 
Jacobson I., Object oriented software engineering: A use case driven approach, (1992); 
Joordens S., Desa S., Pare D., The pedagogical anatomy of peer assessment: Dissecting a peerscholar assignment, Journal of Systemics, Cybernetics & Informatics, 7, 5, (2009); 
Kulkarni C., Wei K.P., Le H., Chia D., Papadopoulos K., Cheng J., Koller D., Klemmer S.R., Peer and self assessment in massive online classes, ACM Transactions on Computer-Human Interaction, 20, 6, pp. 1-33, (2013); 
Li H., Xiong Y., Hunter C.V., Guo X., Tywoniw R., Does peer assessment promote student learning? A meta-analysis, Assessment & Evaluation in Higher Education, 45, 2, pp. 193-211, (2020); 
Lin G.-Y., Anonymous versus identified peer assessment via a Facebook-based learning application: Effects on quality of peer feedback, perceived learning, perceived fairness, and attitude toward the system, Computers & Education, 116, pp. 81-92, (2018); 
Lu R., Anonymity in collaboration: Anonymous vs. identifiable E-peer review in writing instruction, (2011); 
Lu R., Bol L., A comparison of anonymous versus identifiable E-peer review on college student writing performance and the extent of critical feedback, Journal of Interactive Online Learning, 6, 2, pp. 100-115, (2007); 
Luxton-Reilly A., A systematic review of tools that support peer assessment, Computer Science Education, 19, 4, pp. 209-232, (2009); 
Martin P.Y., Turner B.A., Grounded theory and organizational research, The Journal of Applied Behavioral Science, 22, 2, pp. 141-157, (1986); 
Matusov E., Intersubjectivity without agreement, Mind, Culture, and Activity, 3, 1, pp. 25-45, (1996); 
Matusov E., Marjanovic-Shane A., Many faces of the concept of culture (and education), Culture & Psychology, 23, 3, pp. 309-336, (2017); 
Millard D., Fill K., Gilbert L., Howard Y., Sinclair P., Senbanjo D.O., Wills G.B., Towards a canonical view of peer assessment, Seventh IEEE International Conference on Advanced Learning Technologies (, pp. 793-797, (2007); 
Millard D., Newman D., Sinclair P., PeerPigeon: A web application to support generalised peer review, pp. 3824-3836, (2008); 
Misiejuk K., Wasson B., Backward evaluation in peer assessment: A scoping review, Computers & Education, 175, (2021); 
Morrison N., The teacher-less classroom is not as close as you think, (2014); 
Patchan M.M., Schunn C.D., Clark R.J., Accountability in peer assessment: Examining the effects of reviewing grades on peer ratings and peer feedback, Studies in Higher Education, pp. 2263-2278, (2017); 
Pramudianto F., Aljeshi M., Alhussein H., Song Y., Gehringer E.F., Babik D., Tinapple D., . CSPRED 2016: Workshop on computer-supported peer review in education, Peer Review Data Warehouse: Insights from Different Systems, (2016); 
Purchase H., Hamer J., Peer review in practice: Eight years of experience with Aropä. University of Glasgow., (2017); 
Raman K., Joachims T., Methods for ordinal peer grading, pp. 1037-1046, (2014); 
Rogers E.M., Complex adaptive systems and the diffusion of innovations, The Innovation Journal: The Public Sector Innovation Journal, 10, (2005); 
Rotsaert T., Panadero E., Schellens T., Anonymity as an instructional scaffold in peer assessment: Its effects on peer feedback quality and evolution in students’ perceptions about peer assessment skills, European Journal of Psychology of Education, 33, 1, pp. 75-99, (2018); 
Russell A.A., Calibrated peer review: A writing and critical-thinking instructional tool. UCLA, Chemistry, (2001); 
Sadler P.M., Good E., The impact of self-and peer-grading on student learning, Educational Assessment, 11, 1, pp. 1-31, (2006); 
Sargeant J., Mann K., van der Vleuten C., Metsemakers J., Directed” self-assessment: Practice and feedback within a social context, Journal of Continuing Education in the Health Professions, 28, 1, pp. 47-54, (2008); 
Shah N.B., Bradley J.K., Parekh A., Wainwright M., Ramchandran K., A case for ordinal peer evaluation in MOOCs, NIPS Workshop on Data Driven Education, pp. 1-8, (2013); 
Sitthiworachart J., Joy M., Effective peer assessment for learning computer programming, SIGCSE BULLETIN, 36, pp. 122-126, (2004); 
Sondergaard H., Mulder R.A., Collaborative learning through formative peer review: Pedagogy, programs and potential, Computer Science Education, 22, 4, pp. 343-367, (2012); 
Song Y., Pramudianto F., Gehringer E.F., A markup language for building a data warehouse for educational peer-assessment research, IEEE Frontiers in Education Conference (FIE), 2016, pp. 1-5, (2016); 
Stake R.E., Multiple case study analysis, (2013); 
Steffens K., Self-regulated learning in technology-enhanced learning environments: Lessons of a European peer review, European Journal of Education, 41, 3-4, pp. 353-379, (2006); 
Strauss A., Corbin J., Grounded theory methodology: An overview, In Handbook of Qualitative Research, (1994); 
Taraborelli D., Soft peer review. Social software and distributed scientific evaluation, Proceedings of the 8Th International Conference on the Design of Cooperative Systems, Carry-Le-Rouet, 20–23 May 2008, (2008); 
Tenorio T., Bittencourt I.I., Isotani S., Silva A.P., Does peer assessment in on-line learning environments work? A systematic review of the literature, Computers in Human Behavior, 64, pp. 94-107, (2016); 
Tinapple D., Olson L., Sadauskas J., CritViz: Web-based software supporting peer critique in large creative classrooms, Bulletin of the IEEE Technical Committee on Learning Technology, 15, 1, (2013); 
Topping K.J., Peer assessment between students in colleges and universities, Review of Educational Research, 68, 3, pp. 249-276, (1998); 
Topping K.J., Self and peer assessment in school and university: Reliability, validity and utility, Optimising new modes of assessment: In search of qualities and standards, pp. 55-87, (2003); 
Topping K.J., Trends in peer learning, Educational Psychology, 25, 6, pp. 631-645, (2005); 
Topping K.J., Digital peer assessment in school teacher education and development: A systematic review, Research Papers in Education, 38, 3, pp. 472-498, (2023); 
van den Akker J., Branch R.M., Gustafson K., Nieveen N., Plomp T., Design approaches and tools in education and training, (2012); 
van den Akker J., Gravemeijer K., McKenney S., Nieveen N., Educational design research, (2006); 
van den Berg I., Admiraal W., Pilot A., Peer assessment in university teaching: Evaluating seven course designs, Assessment & Evaluation in Higher Education, 31, 1, pp. 19-36, (2006); 
Verma P., 5 Tech trends that will transform education by 2025, Forbes., (2015); 
Von Glasersfeld E., An introduction to radical constructivism, The invented reality 1740, pp. 17-40, (1984); 
Von Glasersfeld E., Radical constructivism, (1995); 
Vygotsky L.S., Mind in society: The development of higher psychological processes, Journal of Reading Behavior, 12, pp. 161-162, (1980); 
Wahid U., Chatti M.A., Schroeder U., A systematic analysis of peer assessment in the MOOC era and future perspectives, eLmL, 75, (2016); 
Willey K., Gardner A., Improving self- and peer assessment processes with technology, Campus-Wide Information Systems, 26, 5, pp. 379-399, (2009); 
Willey K., Gardner A., Investigating the capacity of self and peer assessment activities to engage students and promote learning, European Journal of Engineering Education, 35, 4, pp. 429-443, (2010); 
Wolfe W.J., Online student peer reviews, Proceedings of the 5th conference on information technology education, pp. 33-37, (2004); 
Wooley R., Was C., Schunn C.D., Dalton D., The effects of feedback elaboration on the giver of feedback, Annual Meeting of the Cognitive Science Society, 5, pp. 2375-2380, (2008); 
Wright J.R., Thornton C., Leyton-Brown K., Mechanical TA: Partially automated high-stakes peer grading, Proceedings of the 46Th ACM Technical Symposium on Computer Science Education, pp. 96-101, (2015); 
Wu C., Chanda E., Willison J., (2010); 
Yu F.-Y., Sung S., A mixed methods approach to the assessor’s targeting behavior during online peer assessment: Effects of anonymity and underlying reasons, Interactive Learning Environments, 24, 7, pp. 1674-1691, (2016); 
Yu F.-Y., Wu C.-P., Different identity revelation modes in an online peer-assessment learning environment: Effects on perceptions toward assessors, classroom climate and learning activities, Computers & Education, 57, 3, pp. 2167-2177, (2011)#FRF#
