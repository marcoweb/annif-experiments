#ITI#Assessing the quality of scientific explanations with networks#FTI#
#IRE#This article introduces a network approach to describe the quality of written scientific explanations. Existing approaches evaluate explanations mainly on the level of sentences or as a whole but not on the elementary level of single terms. Moreover, evaluation of explanations is often based on highly inferential scoring techniques. We addressed both issues by converting the elementary structure of terms in explanations into networks (so-called element maps) and analysing these with mathematical measures, thus extracting the size and complexity of an explanation, adequacy, coherence, and use of key terms. A total of 65 explanations of experts and students were analysed quantitatively and qualitatively. Differences between expert and student maps’ measures can be interpreted meaningfully against the background of existing research findings. Thus, we argue that our approach using network analysis provides a precise, fine-grained, and low-inferential tool that complements and refines existing approaches. Element maps have the potential to improve teaching and research by precisely revealing the strengths and weaknesses of explanations#FRE#
#IPC#assessment; Explanations; networks#FPC#
#IRF#Alameh S., Abd-El-Khalick F., Towards a philosophically guided schema for studying scientific explanation in science education, Science & Education, 27, 9-10, pp. 831-861, (2018); 
Andersson B., Karrqvist C., How Swedish pupils, aged 12-15 years, understand light and its properties, European Journal of Science Education, 5, 4, pp. 387-402, (1983); 
Barabasi A.-L., Network science, (2016); 
Bechtel W., Abrahamsen A., Explanation: A mechanist alternative, Studies in History and Philosophy of Biological and Biomedical Sciences, 36, 2, pp. 421-441, (2005); 
Berthold K., Renkl A., Instructional Aids to support a conceptual understanding of multiple representations, Journal of Educational Psychology, 101, 1, pp. 70-87, (2009); 
Braaten M., Windschitl M., Working toward a stronger conceptualization of scientific explanation for science education, Science Education, 95, 4, pp. 639-669, (2011); 
de Andrade V., Freire S., Baptista M., Constructing scientific explanations: A system of analysis for students’ explanations, Research in Science Education, 49, 3, pp. 787-807, (2019); 
Delen I., Krajcik J., What do students’ explanations look like when they use second-hand data?, International Journal of Science Education, 37, 12, pp. 1953-1973, (2015); 
Forman E.A., The practice turn in learning theory and science education, Constructivist education in an age of accountability, pp. 97-111, (2018); 
Freeman L.C., A set of measures of centrality based on betweenness, Sociometry, 40, 1, pp. 35-41, (1977); 
Galili I., Hazan A., Learners’ knowledge in optics: Interpretation, structure and analysis, International Journal of Science Education, 22, 1, pp. 57-88, (2000); 
Geelan D., Teacher explanation of physics concepts: A video study, Research in Science Education, 43, 5, pp. 1751-1762, (2013); 
Halliday M.A.K., Matthiessen C.M.I.M., Halliday’s introduction to functional grammar, (2013); 
Herman B.C., Owens D.C., Oertli R.T., Zangori L.A., Newton M.H., Exploring the complexity of students’ scientific explanations and associated nature of science views within a place-based socioscientific issue context, Science & Education, 28, 3-5, pp. 329-366, (2019); 
Jonassen D.H., Beissner K., Yacci M., Structural knowledge: Techniques for representing, conveying, and acquiring structural knowledge, (2013); 
Kaewkhong K., Mazzolini A., Emarat N., Arayathanitkul K., Thai high-school students’ misconceptions about and models of light refraction through aplanar surface, Physics Education, 45, 1, (2010); 
Kang H., Thompson J., Windschitl M., Creating opportunities for students to show what they know: The role of scaffolding in assessment tasks, Science Education, 98, 4, pp. 674-704, (2014); 
Koponen I.T., Nousiainen M., Concept networks of students’ knowledge of relationships between physics concepts: Finding key concepts and their epistemic support, Applied Network Science, 3, 1, pp. 1-21, (2018); 
Koponen I.T., Pehkonen M., Coherent knowledge structures of physics represented as concept networks in teacher education, Science and Education, 19, 3, pp. 259-282, (2010); 
Kubsch M., Touitou I., Nordine J., Fortus D., Neumann K., Krajcik J., Transferring knowledge in a knowledge-in-use task—investigating the role of knowledge organization, Education Sciences, 10, 1, (2020); 
Kuhn T.S., The road since structure: Philosophical essays, 1970—1993, with an autobiographical interview, (2000); 
Kulgemeyer C., Towards a framework for effective instructional explanations in science teaching, Studies in Science Education, 54, 2, pp. 109-139, (2018); 
Lachner A., Gurlitt J., Nuckles M., A graph-oriented approach to measuring expertise—detecting structural differences between experts and intermediates, Proceedings of the 34th annual conference of the cognitive science society, pp. 653-658, (2012); 
Lemke J.L., Thematic analysis: Systems, structures, and strategies, Semiotic Inquiry, 2, 3, pp. 159-187, (1983); 
Lemke J.L., Talking science: Language, learning, and values, (1990); 
Lintern G., Moon B., Klein G., Hoffman R.R., Eliciting and representing the knowledge of experts, The Cambridge handbook of expertise and expert performance, pp. 458-522, (2018); 
Manz E., Lehrer R., Schauble L., Rethinking the classroom science investigation, Journal of Research in Science Teaching, 57, 7, pp. 1-27, (2020); 
McNeill K.L., Lizotte D.J., Krajcik J., Marx R.W., Supporting students’ construction of scientific explanations by fading scaffolds in instructional materials, Journal of the Learning Sciences, 15, 2, pp. 153-191, (2006); 
Nassar A.B., Apparent depth, The Physics Teacher, 32, 9, pp. 526-529, (1994); 
Next generation science standards: For states, by states, (2013); 
Novak J.D., Concept mapping: A useful tool for science education, Journal of Research in Science Teaching, 27, 10, pp. 937-949, (1990); 
Osborne J.F., Patterson A., Scientific argument and explanation: A necessary distinction?, Science Education, 95, 4, pp. 627-638, (2011); 
Papadouris N., Vokos S., Constantinou C.P., The pursuit of a “better” explanation as an organizing framework for science teaching and learning, Science Education, 102, 2, pp. 219-237, (2018); 
Peel A., Zangori L., Friedrichsen P., Hayes E., Sadler T., Students’ model-based explanations about natural selection and antibiotic resistance through socio-scientific issues-based learning, International Journal of Science Education, 41, 4, pp. 510-532, (2019); 
Peker D., Wallace C.S., Characterizing high school students’ written explanations in biology laboratories, Research in Science Education, 41, 2, pp. 169-191, (2011); 
Quinn H., Schweingruber H., Keller T., A framework for K-12 science education: Practices, crosscutting concepts, and core ideas, (2012); 
Redfors A., Ryder J., University physics students’ use of models in explanations of phenomena involving interaction between metals and electromagnetic radiation, International Journal of Science Education, 23, 12, pp. 1283-1301, (2001); 
Rocksen M., The many roles of “explanation” in science education: A case study, Cultural Studies of Science Education, 11, 4, pp. 837-868, (2016); 
Ruiz-Primo M.A., Li M., Tsai S.-P., Schneider J., Testing one premise of scientific inquiry in science classrooms: Examining students’ scientific explanations and student learning, Journal of Research in Science Teaching, 47, 5, pp. 583-608, (2010); 
Ruxton G.D., The unequal variance t-test is an underused alternative to student’s t-test and the Mann–Whitney U test, Behavioral Ecology, 17, 4, pp. 688-690, (2006); 
Salmon W.C., Four decades of scientific explanation, (2006); 
Sandoval W.A., Conceptual and epistemic aspects of students’ scientific explanations, The Journal of the Learning Sciences, 12, 1, pp. 5-51, (2003); 
Schaal S., Concept mapping in science education assessment: An approach to computer-supported achievement tests in an interdisciplinary hypermedia learning environment, Proceedings of the 3rd international conference on concept mapping, pp. 228-235, (2008); 
Siew C.S.Q., Applications of network science to education research: Quantifying knowledge and the development of expertise through network analysis, Education Sciences, 10, 4, (2020); 
Taber K.S., Watts M., Learners’ explanations for chemical phenomena, Chemistry Education Research and Practice, 1, 3, pp. 329-353, (2000); 
Tang K.-S., Constructing scientific explanations through premise–reasoning–outcome (PRO): An exploratory study to scaffold students in structuring written explanations, International Journal of Science Education, 38, 9, pp. 1415-1440, (2016); 
Thurn C.M., Hanger B., Kokkonen T., Concept mapping in magnetism and electrostatics: Core concepts and development over time, Education Sciences, 10, 5, (2020); 
Wiley J., Hastings P., Blaum D., Jaeger A.J., Hughes S., Wallace P., Griffin T.D., Britt M.A., Different approaches to assessing the quality of explanations following a multiple-document inquiry activity in science, International Journal of Artificial Intelligence in Education, 27, 4, pp. 758-790, (2017); 
Williams C.G., Using concept maps to assess conceptual knowledge of function, Journal for Research in Mathematics Education, 29, 4, pp. 414-421, (1998); 
Wulff P., Buschhuter D., Westphal A., Mientus L., Nowak A., Borowski A., Bridging the gap between qualitative and quantitative assessment in science education research with machine learning—A case for pretrained language models-based clustering, Journal of Science Education and Technology, 31, 4, pp. 490-513, (2022); 
Yun E., Park Y., Extraction of scientific semantic networks from science textbooks and comparison with science teachers’ spoken language by text network analysis, International Journal of Science Education, 40, 17, pp. 2118-2136, (2018); 
Zacharia Z.C., The impact of interactive computer simulations on the nature and quality of postgraduate science teachers’ explanations in physics, International Journal of Science Education, 27, 14, pp. 1741-1767, (2005); 
Zangori L., Forbes C.T., Schwarz C.V., Exploring the effect of embedded scaffolding within curricular tasks on third-grade students’ model-based explanations about hydrologic cycling, Science & Education, 24, 7-8, pp. 957-981, (2015); 
Zarkadis N., Papageorgiou G., A fine-grained analysis of students’ explanations based on their knowledge of the atomic structure, International Journal of Science Education, 42, 7, pp. 1162-1182, (2020); 
Zhai X., Yin Y., Pellegrino J.W., Haudek K.C., Shi L., Applying machine learning in science assessment: A systematic review, Studies in Science Education, 56, 1, pp. 111-151, (2020)#FRF#
