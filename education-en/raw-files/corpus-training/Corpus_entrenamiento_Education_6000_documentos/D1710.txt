#ITI#Examining the structure of credibility evaluation when sixth graders read online texts#FTI#
#IRE# Background: Previous research indicates that students lack sufficient online credibility evaluation skills. However, the results are fragmented and difficult to compare as they are based on different types of measures and indicators. Consequently, there is no clear understanding of the structure of credibility evaluation. Objectives: The present study sought to establish the structure of credibility evaluation of online texts among 265 sixth graders. Methods: Students' credibility evaluation skills were measured with a task in which they read four online texts, two more credible (a popular science text and a newspaper article) and two less credible (a layperson's blog text and a commercial text). Students read one text at a time and evaluated the author's expertise, the author's benevolence and the quality of the evidence before ranking the texts according to credibility. Four competing measurement models of students' credibility evaluations were assessed. Results: The model termed the Genre-based Confirming-Questioning Model reflected the structure of credibility evaluation best. The results suggest that credibility evaluation reflects the source texts and requires two latent skills: confirming the more credible texts and questioning the less credible texts. These latent skills of credibility evaluation were positively associated with students' abilities to rank the texts according to credibility. Implications: The study revealed that the structure of credibility evaluation might be more complex than previously conceptualized. Consequently, students would benefit from activities that ask them to carefully analyse different credibility aspects of more and less credible texts, as well as the connections between these aspects#FRE#
#IPC# adolescents; credibility evaluation; information literacy; internet; sourcing#FPC#
#IRF# Abendroth J., Richter T., Mere plausibility enhances comprehension: The role of plausibility in comprehending an unfamiliar scientific debate, Journal of Educational Psychology, 113, 7, pp. 1304-1322, (2021); 
Anmarkrud O., Braten I., Florit E., Mason L., The role of individual differences in sourcing: A systematic review, Educational Psychology Review, 34, pp. 749-792, (2022); 
Bandura A., Self-efficacy: The exercise of control, (1997); 
Barzilai S., Chinn C.A., A review of educational responses to the “post-truth” condition: Four lenses on “post-truth” problems, Educational Psychologist, 55, 3, pp. 107-119, (2020); 
Barzilai S., Tal-Savir D., Abed F., Mor-Hagani S., Zohar A.R., Mapping multiple documents: From constructing multiple document models to argumentative writing, Reading and Writing, (2021); 
Barzilai S., Thomm E., Shlomi-Elooz T., Dealing with disagreement: The roles of topic familiarity and disagreement explanation in evaluation of conflicting expert claims and sources, Learning and Instruction, 69, (2020); 
Bauman M.L., The evolution of internet genres, Computers and Composition, 16, 2, pp. 269-282, (1999); 
Berkenkotter C., Huckin T., Genre knowledge in disciplinary communication: Cognition, culture, power, (1995); 
Brand-Gruwel S., Wopereis I., Vermetten Y., Information problem solving: Analysis of a complex cognitive skill, Computers in Human Behavior, 21, pp. 487-508, (2005); 
Braten I., Braasch J.L., Stromso H.I., Ferguson L.E., Establishing trustworthiness when students read multiple documents containing conflicting scientific evidence, Reading Psychology, 36, 4, pp. 315-349, (2015); 
Braten I., Brante E.W., Stromso H.I., Teaching sourcing in upper secondary school: A comprehensive sourcing intervention with follow-up data, Reading Research Quarterly, 54, 4, pp. 481-505, (2019); 
Braten I., Stadtler M., Salmeron L., The role of sourcing in discourse comprehension, Routledge handbooks in linguistics. The Routledge handbook of discourse processes, pp. 141-166, (2018); 
Cohen J., Statistical power analysis for the behavioral sciences, (1988); 
Coiro J., Coscarelli C., Maykel C., Forzani E., Investigating criteria that seventh graders use to evaluate the quality of online information, Journal of Adolescent & Adult Literacy, 59, 3, pp. 287-297, (2015); 
Common core state standards for English language arts and literacy in history/social studies, science, and technical subjects, (2010); 
Crowston K., Internet genres, Encyclopedia of library and information science, pp. 2583-2596, (2010); 
Duke N.K., Roberts K.L., The genre-specific nature of reading comprehension, The Routledge international handbook of English, language and literacy teaching, pp. 74-86, (2010); 
National core curriculum for basic education 2014, (2014); 
Fisher R., Reconciling disciplinary literacy perspectives with genre-oriented activity theory: Toward a fuller synthesis of traditions, Reading Research Quarterly, 54, 2, pp. 237-251, (2019); 
Flanagin A.J., Metzger M.J., The role of site features, user attributes, and information verification behaviors on the perceived credibility of web-based information, New Media & Society, 9, 2, pp. 319-342, (2007); 
Forzani E., A three-tiered framework for proactive critical evaluation during online inquiry, Journal of Adolescent & Adult Literacy, 63, 4, pp. 401-414, (2020); 
Greenleaf E.A., Measuring extreme response style, Public Opinion Quarterly, 56, 3, pp. 328-351, (1992); 
Hahnel C., Eichmann B., Goldhammer F., Evaluation of online information in university students: Development and scaling of the screening instrument EVON, Frontiers in Psychology, 11, (2020); 
Hendriks F., Kienhues D., Bromme R., Measuring laypeople's trust in experts in a digital age: The muenster epistemic trustworthiness inventory (METI), PloS ONE, 10, 10, (2015); 
Hendriks F., Kienhues D., Bromme R., Evoking vigilance: Would you (dis) trust a scientist who discusses ethical implications of research in a science blog?, Public Understanding of Science, 25, 8, pp. 992-1008, (2016); 
Hu L., Bentler P.M., Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives, Structural Equation Modeling: A Multidisciplinary Journal, 6, pp. 1-55, (1999); 
Kiili C., Forzani E., Brante E.W., Raikkonen E., Marttunen M., Sourcing on the internet: Examining the relations among different phases of online inquiry, Computers and Education Open, 2, (2021); 
Kiili C., Leu D.J., Utriainen J., Coiro J., Kanniainen L., Tolvanen A., Lohvansuu K., Leppanen P.H.T., Reading to learn from online information: Modeling the factor structure, Journal of Literacy Research, 50, pp. 304-334, (2018); 
Kozyreva A., Lewandowsky S., Hertwig R., Citizens versus the internet: Confronting digital challenges with cognitive tools, Psychological Science in the Public Interest, 21, 3, pp. 103-156, (2020); 
Leeder C., Student misidentification of online genres, Library & Information Science Research, 38, 2, pp. 125-132, (2016); 
Leu D.J., Kinzer C.K., Coiro J., Castek J., Henry L.A., New literacies: A dual level theory of the changing nature of literacy, instruction, and assessment, Theoretical models and processes of literacy, pp. 319-346, (2019); 
Leu D.J., Kinzer C.K., Coiro J.L., Cammack D.W., Toward a theory of new literacies emerging from internet and other information and communication technologies, Theoretical models and process of reading, pp. 1570-1613, (2004); 
Li C.H., Confirmatory factor analysis with ordinal data: Comparing robust maximum likelihood and diagonally weighted least squares, Behavior Research Methods, 48, pp. 936-949, (2016); 
List A., Defining digital literacy development: An examination of pre-service teachers' beliefs, Computers and Education, 138, pp. 146-158, (2019); 
List A., Alexander P.A., Corroborating students' self-reports of source evaluation, Behaviour & Information Technology, 37, 3, pp. 198-216, (2018); 
List A., Alexander P.A., Stephens L.A., Trust but verify: Examining the association between students' sourcing behaviors and ratings of text trustworthiness, Discourse Processes, 54, 2, pp. 83-104, (2017); 
Mason L., Junyent A.A., Tornatora M.C., Epistemic evaluation and comprehension of web-source information on controversial science-related topics: Effects of a short-term instructional intervention, Computers & Education, 76, pp. 143-157, (2014); 
McCrudden M.T., Text relevance and multiple-source use, Handbook of multiple source use, pp. 168-183, (2018); 
McGrew S., Breakstone J., Ortega T., Smith M., Wineburg S., Can students evaluate online sources? Learning from assessments of civic online reasoning, Theory & Research in Social Education, 46, 2, pp. 165-193, (2018); 
Muthen L.K., Muthen B.O., Mplus user's guide, (1998); 
Nussbaum E.M., Critical integrative argumentation: Toward complexity in students' thinking, Educational Psychologist, 56, 1, pp. 1-17, (2020); 
Educational structure of population. Population with educational qualification by level of education, field of education and gender, (2020); 
Okan O., Bollweg T.M., Berens E.M., Hurrelmann K., Bauer U., Schaeffer D., Coronavirus-related health literacy: A cross-sectional study in adults during the COVID-19 infodemic in Germany, International Journal of Environmental Research and Public Health, 17, 15, (2020); 
Pellegrino J.W., DiBello L.V., Goldman S.R., A framework for conceptualizing and evaluating the validity of instructionally relevant assessments, Educational Psychologist, 51, 1, pp. 59-81, (2016); 
Pieschl S., Sivyer D., Secondary students' epistemic thinking and year as predictors of critical source evaluation of internet blogs, Computers & Education, 160, (2021); 
Potocki A., de Pereyra G., Ros C., Macedo-Rouet M., Stadtler M., Salmeron L., Rouet J.F., The development of source evaluation skills during adolescence: Exploring different levels of source processing and their relationships, Journal for the Study of Education and Development, 43, 1, pp. 19-59, (2020); 
Purcell-Gates V., Duke N., Martineau J., Learning to read and write genre-specific text: Roles of authentic experience and explicit teaching, Reading Research Quarterly, 42, pp. 8-46, (2007); 
Richter T., Maier J., Comprehension of multiple documents with conflicting information: A two-step model of validation, Educational Psychologist, 52, 3, pp. 148-166, (2017); 
Rindskopf D., Rose T., Some theory and applications of confirmatory second-order factor analysis, Multivariate Behavioral Research, 23, 1, pp. 51-67, (1988); 
Satorra A., Bentler P.M., A scaled difference chi-square test statistic for moment structure analysis, Psychometrika, 66, 4, pp. 507-514, (2001); 
Stadtler M., Bromme R., The content–source integration model: A taxonomic description of how readers comprehend conflicting scientific information, Processing inaccurate information: Theoretical and applied perspectives from cognitive science and the educational sciences, pp. 379-402, (2014); 
Sundin O., Francke H., In search of credibility: Pupils' information practices in learning environments, Information Research, 14, 4, (2009); 
Tangcharoensathien V., Calleja N., Nguyen T., Purnat T., D'Agostino M., Garcia-Saiso S., Landry M., Rashidian A., Hamilton C., AbdAllah A., Ghiga I., Hill A., Hougendobler D., van Andel J., Nunn M., Brooks I., Sacco P.L., De Domenico M., Mai P., Briand S., Framework for managing the COVID-19 infodemic: Methods and results of an online, crowdsourced WHO technical consultation, Journal of Medical Internet Research, 22, 6, (2020); 
Thomm E., Bromme R., How source information shapes lay interpretations of science conflicts: Interplay between sourcing, conflict explanation, source evaluation, and claim evaluation, Reading and Writing, 29, 8, pp. 1629-1652, (2016); 
Tierney R.J., Pearson P.D., A history of literacy education: Waves of research and practice, (2021); 
Zarefsky D., The practice of argumentation: Effective reasoning in communication, (2019)#FRF#
