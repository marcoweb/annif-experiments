#ITI#Measuring the Quality of Test-based Exercises Based on the Performance of Students#FTI#
#IRE# In order to be effective, a learning process requires the use of valid and suitable educational resources. However, measuring the quality of an educational resource is not an easy task for a teacher. The data of the performance of the students can be used to measure how appropriate the didactic resources are. Besides this data, adequate metrics and statistics are also needed. In this paper, TEA, a Visual Learning Analytics tool for measuring the quality of a particular type of educational resources, in particular test-based exercises, is presented. TEA is a teacher-oriented tool aimed at helping them to improve the quality of the learning material they have created by analyzing and visualizing the performance of the students. TEA evaluates not only the adequacy of individual items but also the appropriateness of a whole test. TEA provides the results of the evaluation so that they are easily interpretable by teachers and developers of educational material. The development of TEA required a thorough analysis and classification of metrics and statistics to identify those which are useful to measure the quality of test-based exercises using the data about the performance of the students. The tool provides visual representations of the performance of the students to allow teachers to evaluate the appropriateness of the test-based exercises they have created. The experimentation carried out with TEA at higher education level is also presented#FRE#
#IPC# Quality evaluation of test-based exercises; Test-based exercises; Visual Learning Analytics#FPC#
#IRF# Evaluation Methodologies in Automatic Question Generation 2013–2018, In Proceedings of the 11Th International Conference on Natural Language Generation, pp. 307-317; 
Arruarte A., Fernandez I., Ferrero B., Greer J., The IRIS Shell: How to Build ITSs from Pedagogical and Design Requisites, Journal of Artificial Intelligence in Education, 8, pp. 341-381, (1997); 
Arruarte A., Fernandez I., Greer J., The CLAI Model. A Cognitive Theory to Guide ITS Development, Journal of Artificial Intelligence in Education, 7, 3-4, pp. 277-313, (1996); 
The IRIS Authoring Tool, Automating Tools for Advanced Learning Environments, pp. 233-267, (2003); 
A conceptual framework for making knowledge actionable through capital formation, D.M. dissertation, University of Maryland, (2007); 
Baker F.B., The Basics of Item Response Theory, (2001); 
Applying the Agent Metaphor to Learning Content Management Systems and Learning Object Repositories, ITS 2006, LNCS, 4053, pp. 808-810, (2006); 
Visualizing Lecture Capture Usage: A Learning Analytics Case Study. Wave 2013 Workshop at LAK13, April 8, (2013); 
Learning analytics dashboards to support adviser-student dialogue, IEEE Transactions on Learning Technologies, (2018); 
Chen Q., Chen Y., Liu D., Shi C., Wu Y., Qu H., PeakVizor: Visual Analytics of Peaks in Video Clikstreams from Massive Open Online Courses, IEEE Transactions on Visualization and Computer Graphics, 22, 10, pp. 2315-2330, (2016); 
Clements K., Pawlowski J., Manouselis N., (2014). Why open educational resources repositories fail -review of quality assurance approaches, International Association of Technology, Education and Development (IATED, (2014); 
Conde A., Larranaga M., Arruarte A., Elorriaga J.A., A combined approach for eliciting relationships for educational ontologies using general-purpose knowledge bases, IEEE ACCESS, 7, pp. 48339-48355, (2019); 
Conde A., Larranaga M., Arruarte A., Elorriaga J.A., Roth D., LiTeWi: A combined term extraction and entity linking method for eliciting educational Ontologies from textbooks’, Journal of the Association for Information Science and Technology, 67, 2, pp. 380-399, (2016); 
Conejo R., Barros B., Bertoa M.F., Automated assessment of complex programming tasks using SIETTE, IEEE Transactions on Learning Technologies, 12, 4, pp. 470-484, (2019); 
Conejo R., Guzman E., Trella M., The SIETTE automatic assessment environment, International Journal of Artificial Intelligence in Education, 26, pp. 270-292, (2016); 
Greer J., Molinaro M., Ochoa X., McKay T., Learning Analytics for Curriculum and Program Quality Improvement, In Proceedings of the Sixth International Conference on Learning Analytics & Knowledge, pp. 494-495, (2016); 
Greer J., Molinaro M., Ochoa X., McKay T., Learning Analytics for Curriculum and Program Quality Improvement, In Proceedings of the Sixth International Conference on Learning Analytics & Knowledge, pp. 494-495, (2016); 
Kurdi G., Leo J., Parsia B., Sattler U., Al-Emari S., A Systematic Review of Automatic Question Generation for Educational Purposes, International Journal of Artificial Intelligence in Education, (2019); 
Larranaga M., Enhancing ITS building process with semi-automatic domain acquisition using ontologies and NLP techniques, Proceedings of the Young Researches Track. Intelligent Tutoring Systems, (2002); 
Larranaga M., Conde A., Calvo I., Elorriaga J.A., Arruarte A., Automatic generation of the domain module from electronic textbooks: Method and validation, IEEE Transactions on Knowledge and Data Engineering, 26, 1, pp. 69-82, (2014); 
Leitner P., Khalil M., Ebner M., Learning analytics in higher education—A literature review, Learning Analytics: Fundaments, Applications, and Trends, 94, pp. 1-23, (2017); 
Mendez G., Ochoa X., Chiluizawever K., B. (2014). Mendez, G., Ochoa, X., Chiluiza, K., & de Wever, B, Curricular Design Analysis: A Data-Driven Perspective. Journal of Learning Analytics, 1, 3, pp. 84-119, (2014); 
Mitchell J., Ryder A., Developing and using dashboard indicators in student affairs assessment, New Directions for Student Services, 142, pp. 71-81, (2013); 
Noorozi O., Alikhani I., Jarvela S., Kirschner P.A., Juuso I., Seppanen T., Multimodal data to design visual learning analytics for understanding regulation of learning, Computers in Human Behavior, 100, pp. 298-304, (2019); 
Novick M.R., The axioms and principal results of classical test theory, Journal of Mathematical Psychology, 3, 1, pp. 1-18, (1966); 
Paul R., Gaftandzhieva S., Kausar S., Hussain S., Doneva R., Baruah A.K., Exploring Student Academicperformance Using Data Mining Tools. Ijet International Journal of Emerging Technologies in Learning, 15, 8, pp. 195-208, (2020); 
Pelanek R., Learning Analytics Challenges: Trade-offs, Methodology, Scalability, Proceedings of the 10Th International Learning Analytics & Knowledge, pp. 554-558, (2020); 
Pena D., Fundamentos De estadística, (2014); 
Rigney J.W., Learning Strategies: A Traditional Perspective, Learning Strategies, pp. 165-205, (1978); 
Schwendimann B.A., Rodriguez-Triana M.J., Vozkiuk A., Prieto L.P., Boroujeni M.S., Holzer A., Gillet D., Dillenbourg P., Perceiving Learning at a Glance: A Systematic Literature Review of Learning Dashboard Research, IEEE Transactions on Learning Technologies, 10, 1, pp. 30-41, (2017); 
Thomas J.J., Cook K.A., A visual Analytics Agenda, IEEE Computer Graphics and Applications, 26, 1, pp. 10-13, (2006); 
Verbert K., Duval E., Klerkx J., Govaerts S., Santos J.L., Learning analytics dashboard applications, American Behavioral Scientist, pp. 1-10, (2013); 
Verbert K., Ochoa X., de Croon R., Dourado R.A., De L., T. Learning analytics dashboards: The past, the present and the future, Proceedings of the 10Th International Learning Analytics & Knowledge, pp. 35-40, (2020); 
Vieira C., Parsons P., Byrd V., Visual Learning Analytics of Educational Data: A Systematic Literature Review and Research Agenda, Computers & Education, 122, pp. 119-135, (2018); 
Virvou M., Alepis E., Tsihrintzis G.A., Jain L.C., Machine Learning Paradigms, Advanced in Learning Analytics, (2020); 
Weinstein C.E., Mayer R.E., The teaching of Learning Strategies, Handbook of Research on Teaching, pp. 315-327, (1986)#FRF#
