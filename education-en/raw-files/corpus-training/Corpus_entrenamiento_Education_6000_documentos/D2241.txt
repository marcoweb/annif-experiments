#ITI#Can High-Dimensional Questionnaires Resolve the Ipsativity Issue of Forced-Choice Response Formats?#FTI#
#IRE# Forced-choice questionnaires can prevent faking and other response biases typically associated with rating scales. However, the derived trait scores are often unreliable and ipsative, making interindividual comparisons in high-stakes situations impossible. Several studies suggest that these problems vanish if the number of measured traits is high. To determine the necessary number of traits under varying sample sizes, factor loadings, and intertrait correlations, simulations were performed for the two most widely used scoring methods, namely the classical (ipsative) approach and Thurstonian item response theory (IRT) models. Results demonstrate that while especially Thurstonian IRT models perform well under ideal conditions, both methods yield insufficient reliabilities in most conditions resembling applied contexts. Moreover, not only the classical estimates but also the Thurstonian IRT estimates for questionnaires with equally keyed items remain (partially) ipsative, even when the number of traits is very high (i.e., 30). This result not only questions earlier assumptions regarding the use of classical scores in high-dimensional questionnaires, but it also raises doubts about many validation studies on Thurstonian IRT models because correlations of (partially) ipsative scores with external criteria cannot be interpreted in a usual way.#FRE#
#IPC# forced-choice format; ipsative data; multidimensional IRT; Thurstonian IRT model#FPC#
#IRF# Allaire J., Xie Y., McPherson J., Luraschi J., Ushey K., Atkins A., Wickham H., Cheng J., Chang W., Iannone R., Rmarkdown: Dynamic documents for R, (2018); 
Anguiano-Carrasco C., MacCann C., Geiger M., Seybert J.M., Roberts R.D., Development of a forced-choice measure of typical-performance emotional intelligence, Journal of Psychoeducational Assessment, 33, 1, pp. 83-97, (2015); 
Aust F., Barth M., papaja: Create APA manuscripts with R Markdown, (2018); 
Baron H., Strengths and limitations of ipsative measurement, Journal of Occupational and Organizational Psychology, 69, 1, pp. 49-56, (1996); 
Bartram D., The relationship between ipsatized and normative measures of personality, Journal of Occupational and Organizational Psychology, 69, 1, pp. 25-39, (1996); 
Brown A., Item response models for forced-choice questionnaires: A common framework, Psychometrika, 81, 1, pp. 135-160, (2016); 
Brown A., Bartram D., OPQ32r technical manual, (2011); 
Brown A., Bartram D., The occupational personality questionnaire revolution: Applying item response theory to questionnaire design and scoring, (2013); 
Brown A., Inceoglu I., Lin Y., Preventing rater biases in 360-degree feedback by forcing choice, Organizational Research Methods, 20, 1, pp. 121-148, (2017); 
Brown A., Maydeu-Olivares A., Item response modeling of forced-choice questionnaires, Educational and Psychological Measurement, 71, 3, pp. 460-502, (2011); 
Brown A., Maydeu-Olivares A., Fitting a Thurstonian IRT model to forced-choice data using Mplus, Behavior Research Methods, 44, 4, pp. 1135-1147, (2012); 
Brown A., Maydeu-Olivares A., How IRT can solve problems of ipsative data in forced-choice questionnaires, Psychological Methods, 18, 1, pp. 36-52, (2013); 
Brown A., Maydeu-Olivares A., Ordinal factor analysis of graded-preference questionnaire data, Structural Equation Modeling, 25, 4, pp. 516-529, (2018); 
Burkner P.-C., thurstonianIRT: Thurstonian IRT models in R, (2019); 
Burkner P.-C., Schulte N., Holling H., On the statistical and practical limitations of Thurstonian IRT models, Educational and Psychological Measurement, 79, 5, pp. 827-854, (2019); 
Cao M., Drasgow F., Does forcing reduce faking? A meta-analytic review of forced-choice personality measures in high-stakes situations, Journal of Applied Psychology, 104, 11, pp. 1347-1368, (2019); 
Carpenter B., Gelman A., Hoffman M., Lee D., Goodrich B., Betancourt M., Guo J., Li P., Ridell A., Stan: A probabilistic programming language, Journal of Statistical Software, 76, 1, (2017); 
Cattell R.B., Psychological measurement: Normative, ipsative, interactive, Psychological Review, 51, 5, pp. 292-303, (1944); 
Christiansen N.D., Burns G.N., Montgomery G.E., Reconsidering forced-choice item formats for applicant personality assessment, Human Performance, 18, 3, pp. 267-307, (2005); 
Clemans W.V., An analytical and empirical examination of some properties of ipsative measures, (1966); 
Coombs C.H., A theory of data, Psychological Review, 67, 3, pp. 143-159, (1960); 
Cornwell J.M., Dunlap W.P., On the questionable soundness of factoring ipsative data: A response to Saville & Willson (1991), Journal of Occupational and Organizational Psychology, 67, 2, pp. 89-100, (1994); 
Costa P.T., McCrae R.R., NEO-PI-R professional manual, (1992); 
Crede M., Bashshur M., Niehorster S., Reference group effects in the measurement of personality and attitudes, Journal of Personality Assessment, 92, 5, pp. 390-399, (2010); 
Fisher P.A., Robie C., Christiansen N.D., Speer A.B., Schneider L., Criterion-related validity of forced-choice personality measures: A cautionary note regarding Thurstonian IRT versus classical test theory scoring, Personnel Assessment and Decisions, 5, 1, (2019); 
Goldberg L.R., The structure of phenotypic personality traits, American Psychologist, 48, 1, pp. 26-34, (1993); 
Guenole N., Brown A., Cooper A.J., Forced-choice assessment of work-related maladaptive personality traits: Preliminary evidence from an application of Thurstonian item response modeling, Assessment, 25, 4, pp. 513-526, (2018); 
Guilford J.P., When not to factor analyze, Psychological Bulletin, 49, 1, pp. 26-37, (1952); 
He J., Bartram D., Inceoglu I., van de Vijver F.J.R., Response styles and personality traits: A multilevel analysis, Journal of Cross-Cultural Psychology, 45, 7, pp. 1028-1045, (2014); 
Hicks L.E., Some properties of ipsative, normative, and forced-choice normative measures, Psychological Bulletin, 74, 3, pp. 167-184, (1970); 
Hontangas P.M., Torre J., de la, Ponsoda V., Leenen I., Morillo D., Abad F.J., Comparing traditional and IRT scoring of forced-choice tests, Applied Psychological Measurement, 39, 8, pp. 598-612, (2015); 
Johnson C.E., Wood R., Blinkhorn S.F., Spuriouser and spuriouser: The use of ipsative personality tests, Journal of Occupational Psychology, 61, 2, pp. 153-162, (1988); 
Johnson T., Kulesa P., Cho Y.I., Shavitt S., The relation between culture and response styles: Evidence from 19 countries, Journal of Cross-Cultural Psychology, 36, 2, pp. 264-277, (2005); 
Joubert T., Inceoglu I., Bartram D., Dowdeswell K., Lin Y., A comparison of the psychometric properties of the forced choice and Likert scale versions of a personality instrument, International Journal of Selection and Assessment, 23, 1, pp. 92-97, (2015); 
Lee P., Joo S.-H., Lee S., Examining stability of personality profile solutions between Likert-type and multidimensional forced choice measure, Personality and Individual Differences, 142, 1, pp. 13-20, (2019); 
Lee P., Lee S., Stark S., Examining validity evidence for multidimensional forced choice measures with different scoring approaches, Personality and Individual Differences, 123, pp. 229-235, (2018); 
Lewis J.L., Korn ferry four dimensional executive assessment, (2015); 
Lin Y., Brown A., Influence of context on item parameters in forced-choice personality assessments, Educational and Psychological Measurement, 77, 3, pp. 389-414, (2017); 
Maydeu-Olivares A., Bockenholt U., Structural equation modeling of paired-comparison and ranking data, Psychological Methods, 10, 3, pp. 285-304, (2005); 
Meade A.W., Psychometric problems and issues involved with creating and using ipsative measures for selection, Journal of Occupational and Organizational Psychology, 77, 4, pp. 531-552, (2004); 
Merk J., Schlotz W., Falter T., The Motivational Value Systems Questionnaire (MVSQ): Psychometric analysis using a forced choice Thurstonian IRT model, Frontiers in Psychology, 8, (2017); 
Muthen L., Muthen B., Mplus, The comprehensive modelling program for applied researchers: User’s guide, 5, (2015); 
Ostendorf F., Angleitner A., NEO-PI-R: Neo-persönlichkeitsinventar nach Costa und McCrae, (2004); 
Parvin S., Wang P., Assessing best-worst scaling in consumer value research, Proceedings of Australian and New Zealand Marketing Academy Conference 2014, pp. 780-786, (2014); 
Paulhus D.L., Jones D.N., Measurement of dark personalities, Measures of personality and social psychological constructs, pp. 562-594, (2014); 
Paulhus D.L., Vazire S., The self-report method, Handbook of research methods in personality psychology, pp. 224-239, (2007); 
R: A language and environment for statistical computing, (2018); 
Rosseel Y., lavaan: An R package for structural equation modeling, Journal of Statistical Software, 48, 2, pp. 1-36, (2012); 
RStudio: Integrated development for R, (2018); 
Sass R., Frick S., Reips U.-D., Wetzel E., Taking the test taker’s perspective: Response process and test motivation in multidimensional forced-choice versus rating scale instruments, Assessment, 27, 3, pp. 572-584, (2018); 
Saville P., Holdsworth R., Nyfield G., Cramp L., Maybey W., Occupational personality questionnaire manual, (1992); 
Saville P., Willson E., The reliability and validity of normative and ipsative approaches in the measurement of personality, Journal of Occupational Psychology, 64, 3, pp. 219-238, (1991); 
Stark S., Chernyshenko O.S., Drasgow F., An IRT approach to constructing and scoring pairwise preference items involving stimuli on different dimensions: The multi-unidimensional pairwise-preference model, Applied Psychological Measurement, 29, 3, pp. 184-203, (2005); 
Stewart G.L., Darnold T.C., Zimmerman R.D., Parks L., Dustin S.L., Exploring how response distortion of personality measures affects individuals, Personality and Individual Differences, 49, 6, pp. 622-628, (2010); 
Thurstone L.L., A law of comparative judgment, Psychological Review, 34, 4, pp. 273-286, (1927); 
van Eijnatten F.M., van der Ark L.A., Holloway S.S., Ipsative measurement and the analysis of organizational values: An alternative approach for data analysis, Quality & Quantity: International Journal of Methodology, 49, 2, pp. 559-579, (2015); 
Walton K.E., Cherkasova L., Roberts R.D., On the validity of forced choice scores derived from the Thurstonian item response theory model, Assessment, 27, 4, pp. 706-718, (2019); 
Wang W.-C., Qiu X.-L., Chen C.-W., Ro S., Jin K.-Y., Item response theory models for ipsative tests with multidimensional pairwise comparison items, Applied Psychological Measurement, 41, 8, pp. 600-613, (2017); 
Watrin L., Geiger M., Spengler M., Wilhelm O., Forced-choice versus Likert responses on an occupational big five questionnaire, Journal of Individual Differences, 40, 3, (2019); 
Wetzel E., Bohnke J.R., Brown A., Response biases, The ITC international handbook of testing and assessment, pp. 349-363, (2016); 
Wetzel E., Frick S., Comparing the validity of trait estimates from the multidimensional forced-choice format and the rating scale format, Psychological Assessment, (2019); 
Wetzel E., Greiff S., The world beyond rating scales: Why we should think more carefully about the response format in questionnaires, European Journal of Psychological Assessment, 34, 1, pp. 1-5, (2018); 
Wetzel E., Roberts B.W., Fraley R.C., Brown A., Equivalence of narcissistic personality inventory constructs and correlates across scoring approaches and response formats, Journal of Research in Personality, 61, pp. 87-98, (2016); 
Wickham H., ggplot2: Elegant graphics for data analysis, (2016); 
Wickham H., Tidyverse: Easily install and load the “tidyverse, (2017); 
Xiao Y., Liu H., Li H., Integration of the forced-choice questionnaire and the Likert scale: A simulation study, Frontiers in Psychology, 8, (2017); 
Xie Y., Knitr: A comprehensive tool for reproducible research in R, Implementing reproducible research, pp. 3-22, (2014); 
Young A.L., Faking resistance of a forced-choice measure of the dark triad, (2018)#FRF#
