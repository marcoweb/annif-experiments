#ITI#Systematic Validation in Science Learning Progression Research#FTI#
#IRE#Learning progressions (LPs) are cognitive models that describe the development of scientific knowledge and practices in students. They are constructed based on learning theories and student data. Scholars have advocated for using LPs to align curriculum, instruction, and assessment into a coherent system, and by doing so, promote productive learning (Duncan & Hmelo-Silver, 2009; National Research Council [NRC], 2005, 2007). Systematic validation can be used to monitor and evaluate how well LPs enhance the coherence in curriculum-instruction-assessment systems. A framework for systematic validation of LP research is presented in this article, which illustrates Kane’s argument-based validation approach (Kane, 2013) can be applied to science LP research. In the framework, an interpretation/use argument and a validity argument are established to ensure that the LP aligns curriculum, instruction, and assessment into a coherent system. The interpretation/use argument contains three claims and their assumptions. The three claims are the LP, students’ proficiency measured by the LP, and the use of the LP to inform teaching. The validity argument specifies what and how theoretical rationale and empirical evidence are obtained and used to evaluate those assumptions and hence the claims. We use the activities, data, and results from the Mathematical Thinking in Science (MTS) project to illustrate how these two arguments can be built in an iterative and progressive manner. The framework, along with our experiences and lessons learned, will be of value to other researchers as they conduct their own LP studies#FRE#
#IPC#Assessment; Learning progression; Validity#FPC#
#IRF#Abedi J., Sato E., Linguistic modification. A report prepared for the U.S. Department of Education LEP Partnership. U.S, (2007); 
Standards for educational and psychological testing, (2014); 
Anderson C.W., Learning progressions for environmental science literacy, (2008); 
Anderson C.W., de Los Santos E.X., Bodbyl S., Covitt B.A., Edwards K.D., Designing educational systems to support enactment of the next generation science standards, Journal of Research in Science Teaching, 55, 7, pp. 1026-1052, (2018); 
Brotman J.S., Moore F.M., Girls and science: A review of four themes in the science education literature, Journal of Research in Science Teaching: The Official Journal of the National Association for Research in Science Teaching, 45, 9, pp. 971-1002, (2008); 
Carey S., Spelke E., Domain-specific knowledge and conceptual change, Mapping the mind: Domain specificity in cognition and culture, pp. 169-200, (1994); 
Cronbach L.J., Thorndike R.L., Test validation, Educational Measurement, pp. 443-507, (1971); 
Cronbach L.J., Meehl P.E., Construct validity in psychological tests, Psychological Bulletin, 52, 4, pp. 281-302, (1955); 
DiSessa A.A., Toward an epistemology of physics, Cognition and Instruction, 10, 2-3, pp. 105-225, (1993); 
DiSessa A.A., Conceptual change in a microcosm, Human Development, 60, 1, pp. 1-37, (2017); 
DiSessa A.A., A bird’s-eye view of the ‘pieces’ vs ‘coherence’ controversy (from the pieces’ side of the fence), International handbook of research on conceptual change, pp. 35-60, (2009); 
Drasgow F., Polychoric and polyserial correlations., 7, pp. 68-74, (1986); 
Duncan R.G., Hmelo-Silver C.E., Learning progressions: Aligning curriculum, instruction, and assessment, Journal of Research in Science Teaching, 46, pp. 606-609, (2009); 
Ericsson K.A., Simon H.A., (1993); 
Fortus D., Krajcik J., Curriculum coherence and learning progressions, Second International Handbook of Science Education, pp. 783-798, (2012); 
Glaser B.G., The constant comparative method of qualitative analysis, Social Problems, 12, 4, pp. 436-445, (1965); 
Gotwals A.W., Songer N.B., Validity evidence for learning progression-based assessment items that fuse core disciplinary ideas and science practices, Journal of Research in Science Teaching, 50, 5, pp. 597-626, (2013); 
Graf E.A., van Rijn P.W., Eames C.L., A cycle for validating a learning progression illustrated with an example from the concept of function, The Journal of Mathematical Behavior, 62, (2021); 
Gunckel K.L., Covitt B.A., Salinas I., Learning progressions as tools for supporting teacher content knowledge and pedagogical content knowledge about water in environmental systems, Journal of Research in Science Teaching, 55, 9, pp. 1339-1362, (2018); 
Hadenfeldt J.C., Neumann K., Bernholt S., Liu X.F., Parchmann I., Students’ progression in understanding the matter concept, Journal of Research in Science Teaching, 53, 5, pp. 683-708, (2016); 
Holton G.J., Brush S.G., Physics, the human adventure: From Copernicus to Einstein and beyond, (2001); 
Inagaki K., Hatano G., Young children’s naive thinking about the biological world, (2002); 
Jin H., Anderson C.W., A learning progression for energy in socio-ecological systems, Journal of Research in Science Teaching, 49, 9, pp. 1149-1180, (2012); 
Jin H., Delgado C., Bauer M.I., Wylie E.C., Cisterna D., Llort K.F., A hypothetical learning progression for quantifying phenomena in science, Science & Education, 28, 9, pp. 1181-1208, (2019); 
Jin H., Mikeska J.N., Hokayem H., Mavronikolas E., Toward coherence in curriculum instruction and assessment: A review of learning progression literature, Science Education, 103, 5, pp. 1206-1234, (2019); 
Jin H., van Rijn P., Moore J.C., Bauer M.I., Pressler Y., Yestness N., A validation framework for science learning progression research, International Journal of Science Education, 41, 10, pp. 1324-1346, (2019); 
Jin H., Cisterna D., Shin H.-J., Vonk M., Mathematization: A crosscutting theme to enhance the curricular coherence., pp. 261-279, (2022); 
Kaldaras L., Akaeze H., Krajcik J., Developing and validating next generation science standards-aligned learning progression to track three-dimensional learning of electrical interactions in high school physical science, Journal of Research in Science Teaching, 58, 4, pp. 589-618, (2021); 
Kane M.T., An argument-based approach to validity, Psychological Bulletin, 112, 3, (1992); 
Kane M.T., Current concerns in validity theory, Journal of Educational Measurement, 38, 4, pp. 319-342, (2001); 
Kane M.T., Validating the interpretations and uses of test scores, Journal of Educational Measurement, 50, 1, pp. 1-73, (2013); 
Kline M., Mathematics: The Loss of Certainty, 686, (1982); 
Landis J.R., Koch G.G., The measurement of observer agreement for categorical data, Biometrics, 33, 1, pp. 159-174, (1977); 
Lee O., Luykx A., Science education and student diversity: Race/ethnicity, language, culture, and socioeconomic status, Handbook of Research on Science Education, 1, pp. 171-197, (2007); 
Lord F.M., Novick M.R., Statistical theories of mental test scores, (1968); 
McComas W.F., Clough M.P., Almazroa H., The role and character of the nature of science in science education, The Nature of Science in Science Education, pp. 3-39, (1998); 
Messick S., Validity, ETS Research Report Series, 1987, 2, (1987); 
Messick S., Validity of test interpretation and use, (1990); 
Minstrell J., Facets of students’ knowledge and relevant instruction. In, pp. 110-128, (1992); 
Neumann K., Viering T., Boone W.J., Fischer H.E., Towards a learning progression of energy, Journal of Research in Science Teaching, 50, 2, pp. 162-188, (2013); 
A framework for K-12 science education: Practices, crosscutting concepts, and core ideas, (2012); 
Systems for State Science Assessment., (2006); 
Taking Science to School, (2007); 
Piaget J., The child’s Conception of the World, (1929); 
Russ R.S., Lee V.R., Sherin B.L., Framing in cognitive clinical interviews about intuitive science knowledge: Dynamic student understandings of the discourse interaction, Science Education, 96, 4, pp. 573-599, (2012); 
Salimpour S., Tytler R., Doig B., Fitzgerald M.T., Eriksson U., Conceptualizing the cosmos: Development and validation of the cosmology concept inventory for high school, International Journal of Science and Mathematics Education, (2022); 
Shea N., Duncan R.G., From theory to data: Refining a learning progression, Journal of the Learning Sciences, 22, 1, pp. 7-32, (2012); 
Shepard L.A., Chapter 9: Evaluating test validity, Review of Research in Education, 19, 1, pp. 405-450, (1993); 
Sikorski T.-R., Hammer D., A critique of how learning progressions research conceptualizes sophistication and progress, Proceedings of the 9Th International Conference of the Learning Sciences, pp. 1032-1039, (2010); 
Sireci S.G., On validity theory and test validation, Educational Researcher, 36, 8, pp. 477-481, (2007); 
Smith C.L., Wiser M., Anderson C.W., Krajcik J., Implications of research on children’s learning for standards and assessment: A proposed learning progression for matter and the atomic-molecular theory, Measurement Interdisciplinary Research & Perspective, 4, 1-2, pp. 1-98, (2006); 
Stevens S.S., Handbook of experimental psychology, (1951); 
Next generation science standards: For states, by states, (2013); 
Thompson P.W., Quantitative reasoning, complexity, and additive structures, Educational Studies in Mathematics, 25, 3, pp. 165-208, (1993); 
Thompson P.W., Quantitative reasoning and mathematical modeling, New perspectives and directions for collaborative research in mathematics education, pp. 33-57, (2011); 
Vosniadou S., On the nature of naive physics, Reconsidering Conceptual Change: Issues in Theory and Practice, pp. 61-76, (2002); 
Wilson M., Measuring progressions: Assessment structures underlying a learning progression, Journal of Research in Science Teaching, 46, 6, pp. 716-730, (2009); 
Wylie E.C., Bauer M.I., Arieli-Attali M., (2015); 
Zapata-Rivera J.D., Zwick R., Vezzu M., Exploring the effectiveness of a measurement error tutorial in helping teachers understand score report results, Educational Assessment, 21, 3, pp. 215-229, (2016)#FRF#
