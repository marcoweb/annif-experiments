#ITI#What Affects the Quality of Score Transformations? Potential Issues in True-Score Equating Using the Partial Credit Model#FTI#
#IRE# This simulation study investigated to what extent departures from construct similarity as well as differences in the difficulty and targeting of scales impact the score transformation when scales are equated by means of concurrent calibration using the partial credit model with a common person design. Practical implications of the simulation results are discussed with a focus on scale equating in health-related research settings. The study simulated data for two scales, varying the number of items and the sample sizes. The factor correlation between scales was used to operationalize construct similarity. Targeting of the scales was operationalized through increasing departure from equal difficulty and by varying the dispersion of the item and person parameters in each scale. The results show that low similarity between scales goes along with lower transformation precision. In cases with equal levels of similarity, precision improves in settings where the range of the item parameters is encompassing the person parameters range. With decreasing similarity, score transformation precision benefits more from good targeting. Difficulty shifts up to two logits somewhat increased the estimation bias but without affecting the transformation precision. The observed robustness against difficulty shifts supports the advantage of applying a true-score equating methods over identity equating, which was used as a naive baseline method for comparison. Finally, larger sample size did not improve the transformation precision in this study, longer scales improved only marginally the quality of the equating. The insights from the simulation study are used in a real-data example.#FRE#
#IPC# common person design; equating; multidimensionality; Rasch analysis; simulation study; true-score equating#FPC#
#IRF# Ackerman T.A., Using multidimensional item response theory to understand what items and tests are measuring, Applied Measurement in Education, 7, 4, pp. 255-278, (1994); 
Almond R.G., Steinberg L.S., Mislevy R.J., A framework for reusing assessment components, New developments in psychometrics, pp. 281-288, (2003); 
Andrich D., University paper series on quantitative applications in the social sciences, (1988); 
ANQ—Swiss National Association for Quality Development in Hospitals and Clinics, (2022); 
Arai S., Mayekawa S.-I., A comparison of equating methods and linking designs for developing an item pool under item response theory, Behaviormetrika, 38, 1, pp. 1-16, (2011); 
(2022); 
Ballert C.S., Hopfe M., Kus S., Mader L., Prodinger B., Using the refined ICF linking rules to compare the content of existing instruments and assessments: A systematic review and exemplary analysis of instruments measuring participation, Disability and Rehabilitation, 41, 5, pp. 584-600, (2019); 
Battauz M., Multiple equating of separate IRT calibrations, Psychometrika, 82, 3, pp. 610-636, (2017); 
Beguin A., Bradley A.H., Effect of noncompensatory multidimensionality on separate and concurrent estimation in IRT observed score equating, (2001); 
Bolt D.M., Evaluating the effects of multidimensionality on IRT true-score equating, Applied Measurement in Education, 12, 4, pp. 383-407, (1999); 
Bolt D.M., Adams D.J., Exploring rubric-related multidimensionality in polytomously scored test items, Applied Psychological Measurement, 41, 3, pp. 163-177, (2017); 
Brossman B.G., Lee W.-C., Observed score and true score equating procedures for multidimensional item response theory, Applied Psychological Measurement, 37, 6, pp. 460-481, (2013); 
(2022); 
Chalmers R.P., mirt: A multidimensional item response theory package for the R environment, Journal of Statistical Software, 48, 6, pp. 1-29, (2012); 
Chan T.L., Perlmutter M.S., Andrews M., Sunness J.S., Goldstein J.E., Massof R.W., Equating visual function scales to facilitate reporting of medicare functional g-code severity/complexity modifiers for low-vision patients, Archives of Physical Medicine and Rehabilitation, 96, 10, pp. 1859-1865, (2015); 
Chen W.-H., Revicki D.A., Lai J.-S., Cook K.F., Amtmann D., Linking pain items from two studies onto a common scale using item response theory, Journal of Pain and Symptom Management, 38, 4, pp. 615-628, (2009); 
Choi S.W., Schalet B., Cook K.F., Cella D., Establishing a common metric for depressive symptoms: Linking the BDI-II, CES-D, and PHQ-9 to PROMIS depression, Psychological Assessment, 26, 2, pp. 513-527, (2014); 
Cook K.F., Taylor P.W., Dodd B.G., Teal C.R., McHorney C.A., Evidence-based practice for equating health status items: Sample size and IRT model, Journal of Applied Measurement, 8, 2, (2007); 
Cook L.L., Eignor D.R., Using item response theory in test score equating, International Journal of Educational Research, 13, 2, pp. 161-173, (1989); 
Cook L.L., Paterson N.S., Problems related to the use of conventional and item response theory equating methods in less than optimal circumstances, Applied Psychological Measurement, 11, 3, pp. 225-244, (1987); 
Covic T., Cumming S.R., Pallant J.F., Manolios N., Emery P., Conaghan P.G., Tennant A., Depression and anxiety in patients with rheumatoid arthritis: Prevalence rates based on a comparison of the Depression, Anxiety and Stress Scale (DASS) and the Hospital, Anxiety and Depression Scale (HADS), BMC Psychiatry, 12, 1, (2012); 
Diao H., Keller L., Investigating repeater effects on small sample equating: Include or exclude?, Applied Measurement in Education, 33, 1, pp. 54-66, (2020); 
Doganay Erdogan B., Elhan A.H., Kaskati O.T., Oztuna D., Kucukdeveci A.A., Kutlay S., Tennant A., Integrating patient reported outcome measures and computerized adaptive test estimates on the same common metrics: An example from the assessment of activities in rheumatoid arthritis, International Journal of Rheumatic Diseases, 20, 10, pp. 1413-1425, (2017); 
Dorans N.J., Linking scores from multiple health outcome instruments, Quality of Life Research, 16, pp. 85-94, (2007); 
Edelen M.O., Rodriguez A., Herman P., Hays R.D., Crosswalking the patient-reported outcomes measurement information system physical function, pain interference, and pain intensity scores to the Roland-Morris Disability Questionnaire and the Oswestry Disability Index, Archives of Physical Medicine and Rehabilitation, 102, 7, pp. 1317-1323, (2021); 
Fischer H.F., Tritt K., Klapp B.F., Fliege H., How to compare scores from different depression scales: Equating the Patient Health Questionnaire (PHQ) and the ICD-10-Symptom Rating (ISR) using item response theory, International Journal of Methods in Psychiatric Research, 20, 4, pp. 203-214, (2011); 
Forero C.G., Maydeu-Olivares A., Estimation of IRT graded response models: Limited versus full information methods, Psychological Methods, 14, 3, pp. 275-299, (2009); 
Gatz M., Reynolds C.A., Finkel D., Hahn C.J., Zhou Y., Zavala C., Data harmonization in aging research: Not so fast, Experimental Aging Research, 41, 5, pp. 475-495, (2015); 
Gibbons C.J., Mills R.J., Thornton E.W., Ealing J., Mitchell J.D., Shaw P.J., Talbot K., Tennant A., Young C.A., Rasch analysis of the Hospital Anxiety and Depression Scale (HADS) for use in motor neurone disease, Health and Quality of Life Outcomes, 9, 1, (2011); 
Gibbons R.D., Perraillon M.C., Kim J.B., Item response theory approaches to harmonization and research synthesis, Health Services and Outcomes Research Methodology, 14, 4, pp. 213-231, (2014); 
Han K.C.T., Wells C.S., Sireci S.G., The impact of multidirectional item parameter drift on IRT scaling coefficients and proficiency estimates, Applied Measurement in Education, 25, 2, pp. 97-117, (2012); 
Hanson B.A., Beguin A.A., Obtaining a common scale for item response theory item parameters using separate versus concurrent estimation in the common-item equating design, Applied Psychological Measurement, 26, 1, pp. 3-24, (2002); 
Hart D.L., Mioduski J.E., Werneke M.W., Stratford P.W., Simulated computerized adaptive test for patients with lumbar spine impairments was efficient and produced valid measures of function, Journal of Clinical Epidemiology, 59, 9, pp. 947-956, (2006); 
Hays R.D., Morales L.S., Reise S.P., Item response theory and health outcomes measurement in the 21st century, Medical Care, 38, (2000); 
He Y., Cui Z., Evaluating robust scale transformation methods with multiple outlying common items under IRT true score equating, Applied Psychological Measurement, 44, 4, pp. 296-310, (2020); 
He Y., Cui Z., Fang Y., Chen H., Using a linear regression method to detect Outliers in IRT common item equating, Applied Psychological Measurement, 37, 7, pp. 522-540, (2013); 
Hirsch T.M., Multidimensional equating, Journal of Educational Measurement, 26, 4, pp. 337-349, (1989); 
Jones L.A.T., Li C.-Y., Weitzenkamp D., Steeves J., Charlifue S., Whiteneck G., Development and validation of crosswalks between FIM® and SCIM III for voluntary musculoskeletal movement functions, Neurorehabilitation and Neural Repair, 35, 10, pp. 880-889, (2021); 
Keller L.A., Keller R.R., The effect of changing content on IRT scaling methods, Applied Measurement in Education, 28, 2, pp. 99-114, (2015); 
Kim K.Y., Lim E., Lee W.-C., A comparison of the relative performance of four IRT models on equating passage-based tests, International Journal of Testing, 19, 3, pp. 248-269, (2019); 
Kolen M.J., Brennan R.L., Test equating, scaling, and linking: Methods and practices, (2014); 
Kopp J.P., Jones A.T., Impact of item parameter drift on Rasch scale stability in small samples over multiple administrations, Applied Measurement in Education, 33, 1, pp. 24-33, (2020); 
Lambert S.D., Clover K., Pallant J.F., Britton B., King M.T., Mitchell A.J., Carter G., Making sense of variations in prevalence estimates of depression in cancer: A co-calibration of commonly used depression scales using Rasch analysis, Journal of National Comprehensive Cancer Network, 13, 10, pp. 1203-1211, (2015); 
Latimer S., Covic T., Tennant A., Co-calibration of Deliberate Self Harm (DSH) behaviours: Towards a common measurement metric, Psychiatry Research, 200, 1, pp. 26-34, (2012); 
Lee W.-C., Ban J.-C., A comparison of IRT linking procedures, Applied Measurement in Education, 23, 1, pp. 23-48, (2009); 
Lin X., Chen Z., Jin L., Gao W., Qu B., Zuo Y., Liu R., Yu M., Rasch analysis of the hospital anxiety and depression scale among Chinese cataract patients, PLOS ONE, 12, 9, (2017); 
Lord F.M., Applications of item response theory to practical testing problems, (1980); 
Manna V.F., Gu L., Different methods for adjusting for form difficulty under the Rasch model: Impact on consistency of assessment results, (2019); 
Maritz R., Fellinghauer C., Brach M., Curt A., Gmunder H.P., Hopfe M., Hund-Georgiadis M., Jordan X., Scheel-Sailer A., Stucki G., A Rasch-based comparison of the functional independence measure and spinal cord independence measure for outcome and quality in the rehabilitation of persons with spinal cord injury, Journal of Rehabilitation Medicine, 54, (2022); 
Martin M., Kosinski M., Bjorner J.B., Ware J.E., MacLean R., Li T., Item response theory methods can improve the measurement of physical function by combining the modified health assessment questionnaire and the SF-36 physical function scale, Quality of Life Research, 16, 4, pp. 647-660, (2007); 
Masters G.N., A Rasch model for partial credit scoring, Psychometrika, 47, pp. 149-174, (1982); 
Masters G.N., Common-person equating with the Rasch model, Applied Psychological Measurement, 9, 1, pp. 73-82, (1985); 
McCreary L.L., Conrad K.M., Conrad K.J., Scott C.K., Funk R.R., Dennis M.L., Using the Rasch measurement model in psychometric analysis of the family effectiveness measure, Nursing Research, 62, 3, pp. 149-159, (2013); 
McDonough C.M., Carmichael D., Marino M.E., Ni P., Tosteson A.N.A., Bynum J.P.W., The development of a crosswalk for functional measures in postacute medicare claims, Physical Therapy, 100, 10, pp. 1862-1871, (2020); 
Otto S.A., How to normalize the RMSE, (2019); 
Paek I., Cole K., Using R for item response theory model applications, (2019); 
Peabody M.R., Some methods and evaluation for linking and equating with small samples, Applied Measurement in Education, 33, 1, pp. 3-9, (2020); 
Peterson N.S., Equating: Best practices and challenges to best practices, Statistics for social and behavioral sciences: Linking and aligning scores and scales, pp. 59-72, (2007); 
Preston C.C., Colman A.M., Optimal number of response categories in rating scales: Reliability, validity, discriminating power, and respondent preferences, Acta Psychologica, 104, 1, pp. 1-15, (2000); 
Rasch G., Studies in mathematical psychology, (1960); 
R: A language and environment for statistical computing, (2020); 
Reckase M.D., Ackerman T.A., Carlson J.E., Building a unidimensional test using multidimensional items, Journal of Educational Measurement, 25, 3, pp. 193-203, (1988); 
Romine W.L., Todd A.N., Walter E.M., A closer look at the items within three measures of evolution acceptance: Analysis of the MATE, I-SEA, and GAENE as a single corpus of items, Evolution: Education and Outreach, 11, 1, (2018); 
Rupp A.A., Zumbo B.D., Which model is best? Robustness properties to justify model choice among unidimensional IRT models under itm parameter drift, Alberta Journal of Educational Research, 49, 3, pp. 264-276, (2003); 
Ryan J., Brockmann F., A practicioner’s introduction to equating with primers on classical test theory and item response theory, (2010); 
Sabariego C., Fellinghauer C., Lee L., Kamenov K., Posarac A., Bickenbach J., Kostanjsek N., Chatterji S., Cieza A., Generating comprehensive functioning and disability data worldwide: Development process, data analyses strategy and reliability of the WHO and World Bank Model Disability Survey, Archives of Public Health, 80, 1, (2022); 
Salzberger T., The validity of polytomous items in the Rasch model—The role of statistical evidence of the threshold order, Psychological Test and Assessment Modeling, 57, 3, pp. 377-395, (2015); 
Shinwar N., Akseer T., Kamali M., Model disability survey of Afghanistan 2019, (2020); 
Skaggs G., Wolfe E.W., Equating designs and procedures used in rasch scaling, Journal of Applied Measurement, 11, 2, pp. 182-195, (2010); 
Skaggs G., Lissitz R.W., IRT test equating: Relevant issues and a review of recent research, Review of Educational Research, 56, 4, pp. 495-529, (1986); 
Smith R.M., Kramer G.A., A comparison of two methods of test equating in the Rasch model, Educational and Psychological Measurement, 52, 4, pp. 835-846, (1992); 
Smith R.M., Taylor P.A., Equating rehabilitation outcome scales: Developing common metrics, Journal of Applied Measurement, 5, 3, pp. 229-242, (2004); 
Suanthong S., Schumacker R.E., Beyerlein M.M., An investigation of factors affecting test equating in latent trait theory, Journal of Applied Measurement, 1, 1, pp. 25-43, (2000); 
Surla D., Application of the Rasch model of modern test theory to equate multiple tests using their total scores, (2020); 
Taylor W.J., McPherson K.M., Using Rasch analysis to compare the psychometric properties of the short form 36 physical function score and the Health Assessment Questionnaire disability index in patients with psoriatic arthritis and rheumatoid arthritis, Arthritis Care & Research, 57, 5, pp. 723-729, (2007); 
ten Klooster P.M., Oude Voshaar M., Gandek B., Rose M., Bjorner J., Taal E., Glas C., Riel P., Laar M., Development and evaluation of a crosswalk between the SF-36 physical functioning scale and Health Assessment Questionnaire disability index in rheumatoid arthritis, Health and Quality of Life Outcomes, 11, (2013); 
Tennant A., Conaghan P.G., The Rasch measurement model in rheumatology: What is it and why use it? When should it be applied, and what should one look for in a Rasch paper?, Arthritis Care & Research, 57, 8, pp. 1358-1362, (2007); 
Tong Y., Kolen M.J., Assessing equating results on different equating criteria, Applied Psychological Measurement, 29, 6, pp. 418-432, (2005); 
Velozo C.A., Woodbury M.L., Translating measurement findings into rehabilitation practice: An example using Fugl-Meyer assessment-upper extremity with patients following stroke, Journal of Rehabilitation Research and Development, 48, 10, pp. 1211-1222, (2011); 
Velstra I.-M., Ballert C.S., Cieza A., A systematic literature review of outcome measures for upper extremity function using the international classification of functioning, disability, and health as reference, Physical Medicine and Rehabilitation, 3, 9, pp. 846-860, (2011); 
Vilca L.W., Chavez B.V., Fernandez Y.S., Caycho-Rodriguez T., Spanish version of the Revised Mental Health Inventory-5 (R-MHI-5): New psychometric evidence from the Classical Test Theory (CTT) and the Item Response Theory Perspective (IRT), Trends in Psychology, 30, 1, pp. 111-128, (2022); 
von Davier M., Gonzalez J., von Davier A.A., Local equating using the Rasch model, the OPLM, and the 2PL IRT model-or-what is it anyway if the model captures everything there is to know about the test takers?, Journal of Educational Measurement, 50, 3, pp. 295-303, (2013); 
Vos L., Whiteneck G.G., Ngan E., Leon-Novelo L., Sherer M., Rasch analysis of postconcussive symptoms: Development of crosswalks and the brain injury symptom scale, Archives of Physical Medicine and Rehabilitation, 100, 10, pp. 1844-1852, (2019); 
Waterbury G.T., DeMars C.E., Anchors aweigh: How the choice of anchor items affects the vertical scaling of 3PL data with the Rasch model, Educational Assessment, 26, 3, pp. 175-197, (2021); 
Wells C.S., Subkoviak M.J., Serlin R.C., The effect of item parameter drift on examinee ability estimates, Applied Psychological Measurement, 26, 1, pp. 77-87, (2002); 
Wiberg M., Alternative linear item response theory observed-score equating methods, Applied Psychological Measurement, 40, 3, pp. 180-199, (2016); 
Witt E.A., Stahl J.A., Bergstrom B.A., Muckle T., Impact of item drift with non-normal distributions, (2003); 
Wolfe E.W., Equating and item banking with the Rasch model, Journal of Applied Measurement, 1, 4, pp. 409-434, (2000); 
ICF: International classification of functioning, disability and health, (2001); 
Wright B.D., Bell S.R., Item banks: What, why, how, Journal of Educational Measurement, 21, 4, pp. 331-345, (1984); 
Xiao Y., Koenig K., Han J., Liu Q., Xiong J., Bao L., Test equity in developing short version conceptual inventories: A case study on the conceptual survey of electricity and magnetism, Physical Review Physics Education Research, 15, (2019); 
Yamaguchi J., Positive vs. negative wording, Rasch Measurement Transactions, 11, 2, (1997); 
Yen W.M., Effects of local item dependence on the fit and equating performance of the three-parameter logistic model, Applied Psychological Measurement, 8, 2, pp. 125-145, (1984); 
Zhang X., McDermott P.A., Fantuzzo J.W., Gadsden V.L., Longitudinal stability of IRT and equivalent-groups linear and equipercentile equating, Psychological Reports, 113, 1, pp. 291-313, (2013); 
Zhong Q., Gelaye B., Fann J.R., Sanchez S.E., Williams M.A., Cross-cultural validity of the Spanish version of PHQ-9 among pregnant Peruvian women: A Rasch item response theory analysis, Journal of Affective Disorders, 158, pp. 148-153, (2014)#FRF#
