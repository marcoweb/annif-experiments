#ITI#Assessing Preknowledge Cheating via Innovative Measures: A Multiple-Group Analysis of Jointly Modeling Item Responses, Response Times, and Visual Fixation Counts#FTI#
#IRE# Many approaches have been proposed to jointly analyze item responses and response times to understand behavioral differences between normally and aberrantly behaved test-takers. Biometric information, such as data from eye trackers, can be used to better identify these deviant testing behaviors in addition to more conventional data types. Given this context, this study demonstrates the application of a new method for multiple-group analysis that concurrently models item responses, response times, and visual fixation counts collected from an eye-tracker. It is hypothesized that differences in behavioral patterns between normally behaved test-takers and those who have different levels of preknowledge about the test items will manifest in latent characteristics of the different data types. A Bayesian estimation scheme is used to fit the proposed model to experimental data and the results are discussed.#FRE#
#IPC# eye-tracking; gaze-fixation counts; item response theory; joint modeling; response times; technology enhanced assessment#FPC#
#IRF# Bergner Y., von Davier A.A., Process data in naep: Past, present, and future, Journal of Educational and Behavioral Statistics, 44, 6, pp. 706-732, (2019); 
Birnbaum Z.W., On the importance of different components in a multicomponent system, (1968); 
Bolsinova M., De Boeck P., Tijmstra J., Modelling conditional dependence between response time and accuracy, Psychometrika, 82, pp. 1126-1148, (2017); 
Constantinides A., Belk M., Fidas C., Pitsillides A., On the accuracy of eye gaze-driven classifiers for predicting image content familiarity in graphical passwords, Proceedings of the 27th ACM conference on user modeling, adaptation and personalization, pp. 201-205, (2019); 
De Boeck P., Jeon M., An overview of models for response times and processes in cognitive tests, Frontiers in Psychology, 10, (2019); 
Ercikan K., Pellegrino J.W., Validation of score meaning for the next generation of assessments: the use of response processes, (2017); 
Fox J.P., Marianti S., Joint modeling of ability and differential speed using responses and response times, Multivariate Behavioral Research, 51, 4, pp. 540-553, (2016); 
Friedman B.H., Thayer J.F., Autonomic balance revisited: Panic anxiety and heart rate variability, Journal of Psychosomatic Research, 44, 1, pp. 133-151, (1998); 
Gelman A., Carlin J.B., Stern H.S., Rubin D.B., Bayesian data analysis, (2003); 
Gelman A., Meng X.L., Stern H., Posterior predictive assessment of model fitness via realized discrepancies, Journal of Educational and Behavioral Statistics, 6, pp. 733-807, (1996); 
Guo H., Rios J.A., Haberman S., Liu O.L., Wang J., Paek I., A new procedure for detection of students’ rapid guessing responses using response time, Applied Measurement in Education, 29, 3, pp. 173-183, (2016); 
Hambleton R.K., Swaminathan H., Rogers H.J., Fundamentals of item response theory, (1991); 
Hao J., Smith L., Mislevy R., von Davier A., Bauer M., Taming log files from game/simulation-based assessments: Data models and data analysis tools, ETS Research Report Series, 2016, 1, pp. 1-17, (2016); 
Jacob R.J., Karn K.S., Eye tracking in human-computer interaction and usability research: Ready to deliver the promises, The mind’s eye: Cognitive and applied aspects of eye movement research, pp. 573-605, (2003); 
Jiao H., Lissitz R., Technology enhanced innovative assessment development, modeling, and scoring from an interdisciplinary perspective, (2018); 
Kang H.-A., Zheng Y., Chang H.-H., Online calibration of a joint model of item responses and response times in computerized adaptive testing, Journal of Educational and Behavioral Statistics, 45, 2, pp. 175-208, (2020); 
Levy M., Mislevy R.J., Sinharay S., Posterior predictive model checking for multidimensionality in item response theory, Applied Psychological Measurement, 33, 7, pp. 519-537, (2009); 
Lord F.M., A theory of test scores, (1952); 
Lu J., Wang C., Zhang J., Tao J., A mixture model for responses and response times with a higher-order ability structure to detect rapid guessing behaviour, British Journal of Mathematical and Statistical Psychology, 73, 2, pp. 261-288, (2020); 
Man K., Methods of integrating multi-modal data for detecting aberrant testing behaviors in large-scale assessments, (2020); 
Man K., Harring J.R., Liu Y., Methods of Integrating Multi-Modal Data for Assessing Aberrant Test-Taking Behaviors, Multivariate Behavioral Research, 55, 1, pp. 155-156, (2020); 
Man K., Harring J.R., Negative binomial models for visual fixation counts on test items, Educational and Psychological Measurement, 79, 4, pp. 617-635, (2019); 
Man K., Harring J.R., Jiao H., Zhan P., Joint modeling of compensatory multidimensional item responses and response times, Applied Psychological Measurement, 43, 8, pp. 639-654, (2019); 
Mislevy R.J., Evidence-centered design for simulation-based assessment, (2011); 
Molenaar D., Tuerlinckx F., van der Maas H.L.J., A generalized linear factor model approach to the hierarchical framework for responses and response times, British Journal of Mathematical and Statistical Psychology, 68, 2, pp. 197-219, (2015); 
Morad Y., Lemberg H., Dagan Y., Pupillography as an objective indicator of fatigue, Current Eye Research, 21, 1, pp. 535-542, (2000); 
Patz R.J., Junker B.W., Applications and extensions of MCMC in IRT: Multiple item types, missing data, and rated responses, Journal of Educational and Behavioral Statistics, 24, 4, pp. 342-366, (1999); 
Plummer M., JAGS: Just another Gibbs sampler, (2015); 
Poole A., Ball L.J., Phillips P., In search of salience: A response-time and eye movement analysis of bookmark recognition, People and computers XVIII—Design for life, pp. 363-378, (2004); 
Rasch G., Studies in mathematical psychology: I. probabilistic models for some intelligence and attainment tests, (1960); 
Reckase M.D., Development and application of a multivariate logistic latent trait model, (1972); 
Rubin D.B., Comment: On posterior predictive p-values, Statistica Sinica, 6, pp. 787-792, (1996); 
Schaeffer M., Tardel A., Hofmann S., Hansen-Schirra S., Cognitive effort and efficiency in translation revision, Quality assurance and assessment practices in translation and interpreting, pp. 226-243, (2019); 
Sinharay S., Johnson M.S., Stern H.S., Posterior predictive assessment of item response theory models, Applied Psychological Measurement, 30, 4, pp. 298-321, (2006); 
Smith R.W., Prometric T., The impact of braindump sites on item exposure and item parameter drift, (2004); 
Su Y.S., Yajima M., R2jags: Using R to run JAGS, (2015); 
van der Linden W.J., A lognormal model for response times on test items, Journal of Educational and Behavioral Statistics, 31, 2, pp. 181-204, (2006); 
van der Linden W.J., A hierarchical framework for modeling speed and accuracy on test items, Psychometrika, 72, 3, pp. 287-308, (2007); 
van der Linden W.J., Klein Entink R.H., Fox J.P., IRT parameter estimation with response times as collateral information, Applied Psychological Measurement, 34, 5, pp. 327-347, (2010); 
Volodin N., Adams R., Identifying and estimating a D-dimensional item response model, (1995); 
Wang S., Zhang S., Douglas J., Culpepper S., Using response times to assess learning progress: A joint model for responses and response times, Measurement: Interdisciplinary Research and Perspectives, 16, 1, pp. 45-58, (2018); 
Wise S.L., DeMars C.E., An application of item response time: The effort-moderated irt model, Journal of Educational Measurement, 43, 1, pp. 19-38, (2006); 
Wu M., Adams R., Wilson M., Haldane S., Conquest: Generalized item response modeling software, (1998); 
Yoss R.E., Moyer N.J., Hollenhorst R.W., Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep, Neurology, 20, 6, (1970)#FRF#
