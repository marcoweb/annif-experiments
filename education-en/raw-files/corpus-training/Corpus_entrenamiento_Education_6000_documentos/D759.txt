#ITI#Assessing the validity of test scores using response process data from an eye-tracking study: a new approach#FTI#
#IRE# Understanding the response process used by test takers when responding to multiple-choice questions (MCQs) is particularly important in evaluating the validity of score interpretations. Previous authors have recommended eye-tracking technology as a useful approach for collecting data on the processes test taker’s use to respond to test questions. This study proposes a new method for evaluating alternative score interpretations by using eye-tracking data and machine learning. We collect eye-tracking data from 26 students responding to clinical MCQs. Analysis is performed by providing 119 eye-tracking features as input for a machine-learning model aiming to classify correct and incorrect responses. The predictive power of various combinations of features within the model is evaluated to understand how different feature interactions contribute to the predictions. The emerging eye-movement patterns indicate that incorrect responses are associated with working from the options to the stem. By contrast, correct responses are associated with working from the stem to the options, spending more time on reading the problem carefully, and a more decisive selection of a response option. The results suggest that the behaviours associated with correct responses are aligned with the real-world model used for score interpretation, while those associated with incorrect responses are not. To the best of our knowledge, this is the first study to perform data-driven, machine-learning experiments with eye-tracking data for the purpose of evaluating score interpretation validity#FRE#
#IPC# Eye tracking; Machine learning; Score interpretation; Validity#FPC#
#IRF# Cronbach L.J., Validity on parole: How can we go straight, New directions in testing and measurement: Measuring achievement over a decade, 5, pp. 99-108, (1980); 
Davis J., Goadrich M., In Proceedings of the 23Rd International Conference on Machine Learning, pp. 233-240; 
Durning S.J., Graner J., Artino A.R., Pangaro L.N., Beckman T., Holmboe E., Oakes T., Roy M., Riedy G., Capaldi V., Walter R., van der Vleuten C., Schuwirth L., Using functional neuroimaging combined with a think-aloud protocol to explore clinical reasoning expertise in internal medicine, Military Medicine, 177, pp. 72-78, (2012); 
Gorin J.S., Test design with cognition in mind, Educational Measurement: Issues and Practice, 25, 4, pp. 21-35, (2006); 
Harik P., Feinberg R.A., Clauser B.E., How examinees use time: Examples from a medical licensing examination, Integrating timing considerations to improve standardized testing practices, pp. 73-89, (2020); 
Hegarty M., Mayer R.E., Green C.E., Comprehension of arithmetic word problems: Evidence from students’ eye fixations, Journal of Educational Psychology, 84, pp. 76-84, (1992); 
Hu Y., Wu B., Gu X., An eye tracking study of high- and low-performing students in solving interactive and analytical problems, Educational Technology & Society, 20, 4, pp. 300-311, (2017); 
Kane M., Mislevy R., Validating score interpretations based on response processes, Validation of score meaning for the next generation of assessments, pp. 39-51, (2017); 
Langenfeld T., Thomas J., Zhu R., Morris C.A., Integrating multiple sources of validity evidence for an assessment-based cognitive model, Journal of Educational Measurement, 57, pp. 159-184, (2020); 
Lee S., Wollack J.A., Concurrent use of response time and response accuracy for detecting examinees with item preknowledge, Integrating timing considerations to improve testing practices, pp. 165-175, (2020); 
Maddox B., Bayliss A.P., Fleming P., Engelhardt P.E., Edwards S.G., Borgonovi F., Observing response processes with eye tracking in international large-scale assessments: Evidence from the OECD PIAAC assessment, European Journal of Psychology of Education, 33, pp. 543-558, (2018); 
Margolis M.J., Feinberg R.A., Integrating timing considerations to improve standardized testing practices, (2020); 
Oranje A., Gorin J., Jia Y., Kerr D., Ercikan K., Pellegrino J.W., Collecting, analysing, and interpreting response time, eye tracking and log data, Validation of score meaning for the next generation of assessments, pp. 39-51, (2017); 
Tai R.H., Loehr J.F., Brigham F.J., An exploration of the use of eye-gaze tracking to study problem-solving on standardized science assessments, International Journal of Research & Method in Education, 29, 2, pp. 185-208, (2006); 
Tibshirani R., Regression shrinkage and selection via the lasso, Journal of the Royal Statistical Society: Series B (methodological), 58, pp. 267-288, (1996); 
Wise S.L., Effort analysis: Individual score validation of achievement test data, Applied Measurement in Education, 28, 3, pp. 237-252, (2015); 
Wise S.L., Rapid-guessing behavior: Its identification, interpretation, and implications, Educational Measurement: Issues and Practice, 36, 4, pp. 52-61, (2017); 
Yaneva V., Clauser B.E., Morales A., Paniagua M., online ahead of publication), (2021)#FRF#
