#ITI#Learning to work with the black box: Pedagogy for a world with artificial intelligence#FTI#
#IRE# Artificial intelligence (AI) is increasingly integrating into our society. University education needs to maintain its relevance in an AI-mediated world, but the higher education sector is only beginning to engage deeply with the implications of AI within society. We define AI according to a relational epistemology, where, in the context of a particular interaction, a computational artefact provides a judgement about an optimal course of action and that this judgement cannot be traced. Therefore, by definition, AI must always act as a ‘black box’. Rather than seeking to explain ‘black boxes’, we argue that a pedagogy for an AI-mediated world involves learning to work with opaque, partial and ambiguous situations, which reflect the entangled relationships between people and technologies. Such a pedagogy asks learners locate AI as socially bounded, where AI is always understood within the contexts of its use. We outline two particular approaches to achieve this: (a) orienting students to quality standards that surround AIs, what might be called the tacit and explicit ‘rules of the game’; and (b) providing meaningful interactions with AI systems. Practitioner notes What is already known about this topic Artificial intelligence (AI) is conceptualised in many different ways but is rarely defined in the higher education literature. Experts have outlined a range of graduate capabilities for working in a world of AI such as teamwork or ethical thinking. The higher education literature outlines an imperative need to respond to AI, as underlined by recent commentary on ChatGPT. What this paper adds A definition of an AI that is relational: A particular interaction where a computational artefact provides a judgement about an optimal course of action, which cannot be easily traced. Focusing on working with AI black boxes rather than trying to see inside the technology. Describing a pedagogy for an AI-mediated world that promotes working in complex situations with partial and indeterminate information. Implications for practice and/or policy Focusing on quality standards helps learners understand the social regulating boundaries around AI. Promoting learner interactions with AI as part of a sociotechnical ensemble helps build evaluative judgement in weighting AI's contribution to work. Asking learners to work with AI systems prompts understanding of the evaluative, ethical and practical necessities of working with a black box#FRE#
#IPC# artificial intelligence; evaluative judgement; generative AI; higher education; relational epistemology#FPC#
#IRF# Ajjawi R., Bearman M., Boud D., Performing standards: A critical perspective on the contemporary use of standards in assessment, Teaching in Higher Education, 26, 5, pp. 728-741, (2021); 
Aoun J.E., Robot-proof: Higher education in the age of artificial intelligence, (2017); 
Bearman M., Prefigurement, identities and agency: The disciplinary nature of evaluative judgement, Developing evaluative judgement in higher education: Assessment for knowing and producing quality work, pp. 147-155, (2018); 
Bearman M., Ajjawi R., Can a rubric do more than be transparent? Invitation as a new metaphor for assessment criteria, Studies in Higher Education, 1, pp. 359-368, (2019); 
Bearman M., Brown J., Kirby C., Ajjawi R., Feedback that helps trainees learn to practice without supervision, Academic Medicine, 96, 2, pp. 205-209, (2020); 
Bearman M., Luckin R., Preparing university assessment for a world with AI: Tasks for human intelligence, Re-imagining university assessment in a digital world, pp. 49-63, (2020); 
Bearman M., Ryan J., Ajjawi R., Discourses of artificial intelligence in higher education: A critical literature review, Higher Education, pp. 1-17, (2022); 
Bechmann A., Bowker G.C., Unsupervised by any other name: Hidden layers of knowledge production in artificial intelligence on social media, Big Data & Society, 6, 1, (2019); 
Castanelli D.J., Weller J.M., Molloy E., Bearman M., How trainees come to trust supervisors in workplace-based assessment: A grounded theory study, Academic Medicine, 97, 5, pp. 704-710, (2022); 
Fenwick T., Re-thinking the “thing”, Journal of Workplace Learning, 22, 1-2, pp. 104-116, (2010); 
Foucault M., The birth of the clinic, (1963); 
Freire P., Reading the world and reading the word: An interview with Paulo Freire, Language Arts, 62, 1, pp. 15-21, (1985); 
Gilpin L.H., Bau D., Yuan B.Z., Bajwa A., Specter M., Kagal L., Explaining explanations: An overview of interpretability of machine learning, 2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA), (2018); 
Hayward K.J., Maas M.M., Artificial intelligence and crime: A primer for criminologists, Crime, Media, Culture, 17, 2, pp. 209-233, (2020); 
Hoeyer K., Wadmann S., ‘Meaningless work’: How the datafication of health reconfigures knowledge about work and erodes professional judgement, Economy and Society, 49, 3, pp. 433-454, (2020); 
Hoffman R.R., Mueller S.T., Klein G., Litman J., Metrics for explainable AI: Challenges and prospects, (2018); 
Johnson D.G., Verdicchio M., Reframing AI discourse, Minds and Machines, 27, 4, pp. 575-590, (2017); 
Latour B., Visualization and cognition, Knowledge and Society, 6, 6, pp. 1-40, (1986); 
Latour B., Pandora's hope: Essays on the reality of science studies, (1999); 
Latour B., Reassembling the social: An introduction to actor-network-theory, (2007); 
Law J., Actor network theory and material semiotics, The New Blackwell Companion to Social Theory, 3, pp. 141-158, (2009); 
Luckin R., Machine learning and human intelligence: The future of education for the 21st century, (2018); 
Markauskaite L., Marrone R., Poquet O., Knight S., Martinez-Maldonado R., Howard S., Tondeur J., De Laat M., Buckingham Shum S., Gasevic D., Siemens G., Rethinking the entwinement between artificial intelligence and human learning: What capabilities do learners need for a world with AI?, Computers and Education: Artificial Intelligence, 3, (2022); 
Moscardini A.O., Strachan R., Vlasova T., The role of universities in modern society, Studies in Higher Education, 1, pp. 812-830, (2020); 
Newcomb A., Go grandmaster Lee Sedol reflects on losing series to Google's computer, ABC News, (2016); 
O'Donovan B., Price M., Rust C., Know what I mean? Enhancing student understanding of assessment standards and criteria, Teaching in Higher Education, 9, 3, pp. 325-335, (2004); 
Olson R.E., Smith A., Good P., Neate E., Hughes C., Hardy J., Emotionally reflexive labour in end-of-life communication, Social Science & Medicine, 291, (2021); 
Orr S., Assessment moderation: Constructing the marks and constructing the students, Assessment & Evaluation in Higher Education, 32, 6, pp. 645-656, (2007); 
Pangrazio L., Sefton-Green J., Digital rights, digital citizenship and digital literacy: What's the difference?, Journal of New Approaches in Educational Research, 10, 1, pp. 15-27, (2021); 
Roose K., An A.I.—Generated picture won an art prize. Artists aren't happy, The New York Times, (2022); 
Russell S., Norvig P., Artificial intelligence: A modern approach, (2016); 
Sadler D.R., Perils in the meticulous specification of goals and assessment criteria, Assessment in Education, 14, 3, pp. 387-392, (2007); 
Searle J.R., Minds, brains, and programs, Behavioral and Brain Sciences, 3, 3, pp. 417-424, (1980); 
Selwyn N., Digital technology and the contemporary university: Degrees of digitization, (2014); 
Siemens G., Connectivism: A learning theory for the digital age, International Journal of Instructional Technology and Distance Learning, 2, 1, (2005); 
Tai J., Ajjawi R., Boud D., Dawson P., Panadero E., Developing evaluative judgement: Enabling students to make decisions about the quality of work, Higher Education, 76, 3, pp. 467-481, (2018); 
Vock I., ChatGPT proves that AI still has a racism problem, The New Statesman, (2022); 
Zednik C., Solving the black box problem: A normative framework for explainable artificial intelligence, Philosophy & Technology, 34, 2, pp. 265-288, (2021)#FRF#
