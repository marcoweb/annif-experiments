#ITI#Using natural language processing to support peer-feedback in the age of artificial intelligence: A cross-disciplinary framework and a research agenda#FTI#
#IRE# Advancements in artificial intelligence are rapidly increasing. The new-generation large language models, such as ChatGPT and GPT-4, bear the potential to transform educational approaches, such as peer-feedback. To investigate peer-feedback at the intersection of natural language processing (NLP) and educational research, this paper suggests a cross-disciplinary framework that aims to facilitate the development of NLP-based adaptive measures for supporting peer-feedback processes in digital learning environments. To conceptualize this process, we introduce a peer-feedback process model, which describes learners' activities and textual products. Further, we introduce a terminological and procedural scheme that facilitates systematically deriving measures to foster the peer-feedback process and how NLP may enhance the adaptivity of such learning support. Building on prior research on education and NLP, we apply this scheme to all learner activities of the peer-feedback process model to exemplify a range of NLP-based adaptive support measures. We also discuss the current challenges and suggest directions for future cross-disciplinary research on the effectiveness and other dimensions of NLP-based adaptive support for peer-feedback. Building on our suggested framework, future research and collaborations at the intersection of education and NLP can innovate peer-feedback in digital learning environments. Practitioner notes What is already known about this topic There is considerable research in educational science on peer-feedback processes. Natural language processing facilitates the analysis of students' textual data. There is a lack of systematic orientation regarding which NLP techniques can be applied to which data to effectively support the peer-feedback process. What this paper adds A comprehensive overview model that describes the relevant activities and products in the peer-feedback process. A terminological and procedural scheme for designing NLP-based adaptive support measures. An application of this scheme to the peer-feedback process results in exemplifying the use cases of how NLP may be employed to support each learner activity during peer-feedback. Implications for practice and/or policy To boost the effectiveness of their peer-feedback scenarios, instructors and instructional designers should identify relevant leverage points, corresponding support measures, adaptation targets and automation goals based on theory and empirical findings. Management and IT departments of higher education institutions should strive to provide digital tools based on modern NLP models and integrate them into the respective learning management systems; those tools should help in translating the automation goals requested by their instructors into prediction targets, take relevant data as input and allow for evaluating the predictions#FRE#
#IPC# adaptivity; artificial intelligence; digital learning; large language models; learner support; natural language processing; peer-feedback#FPC#
#IRF# Aben J.E., Dingyloudi F., Timmermans A.C., Strijbos J.W., Embracing errors for learning: Intrapersonal and interpersonal factors in feedback provision and processing in dyadic interactions, The impact of feedback in higher education, pp. 107-125, (2019); 
Aben J.E.J., Timmermans A.C., Dingyloudi F., Lara M.M., Strijbos J.-W., What influences students' peer-feedback uptake? Relations between error tolerance, feedback tolerance, writing self-efficacy, perceived language skills and peer-feedback processing, Learning and Individual Differences, 97, (2022); 
Afrin T., Litman D., Annotation and classification of sentence-level revision improvement, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pp. 240-246, (2018); 
Afrin T., Wang E., Litman D., Matsumura L.C., Correnti R., Annotation and classification of evidence and reasoning revisions in argumentative writing, Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, pp. 75-84, (2020); 
Agarwal A., Xie B., Vovsha I., Rambow O., Passonneau R.J., Sentiment analysis of Twitter data, Proceedings of the Workshop on Language in Social Media, pp. 30-38, (2011); 
Alemdag E., Yildirim Z., Effectiveness of online regulation scaffolds on peer feedback provision and uptake: A mixed methods study, Computers & Education, 188, (2022); 
Alqassab M., Strijbos J.W., Ufer S., The impact of peer solution quality on peer-feedback provision on geometry proofs: Evidence from eye-movement analysis, Learning and Instruction, 58, pp. 182-192, (2018); 
Alqassab M., Strijbos J.W., Ufer S., Training peer-feedback skills on geometric construction tasks: Role of domain knowledge and peer-feedback levels, European Journal of Psychology of Education, 33, 1, pp. 11-30, (2018); 
Anderson N.J., Student involvement in assessment: Healthy self-assessment and effective peer assessment, The Cambridge guide to second language assessment, pp. 187-197, (2012); 
Bannert M., Mengelkamp C., Scaffolding hypermedia learning through metacognitive prompts, International handbook of metacognition and learning technologies, (2013); 
Bauer E., Fischer F., Kiesewetter J., Shaffer D.W., Fischer M.R., Zottmann J.M., Sailer M., Diagnostic activities and diagnostic practices in medical education and teacher education: An interdisciplinary comparison, Frontiers in Psychology, 11, (2020); 
Belland B.R., Scaffolding: Definition, current debates, and future directions, Handbook of research on educational communications and technology, pp. 505-518, (2014); 
Bender E.M., Friedman B., Data statements for natural language processing: Toward mitigating system bias and enabling better science, Transactions of the Association for Computational Linguistics, 6, pp. 587-604, (2018); 
Berndt M., Strijbos J.W., Fischer F., Effects of written peer-feedback content and sender's competence on perceptions, performance, and mindful cognitive processing, European Journal of Psychology of Education, 33, 1, pp. 31-49, (2018); 
Berndt M., Strijbos J.W., Fischer F., Impact of sender and peer-feedback characteristics on performance, cognitive load, and mindful cognitive processing, Studies in Educational Evaluation, 75, (2022); 
Blomeke S., Gustafsson J.-E., Shavelson R.J., Beyond dichotomies: Competence viewed as a continuum, Zeitschrift für Psychologie, 223, pp. 3-13, (2015); 
Bolzer M., Strijbos J.W., Fischer F., Inferring mindful cognitive-processing of peer-feedback via eye-tracking: Role of feedback-characteristics, fixation-durations and transitions, Journal of Computer Assisted Learning, 31, 5, pp. 422-434, (2015); 
Bowman S.R., Angeli G., Potts C., Manning C.D., A large annotated corpus for learning natural language inference, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 632-642, (2015); 
Brewer S., Klein J.D., Type of positive interdependence and affiliation motive in an asynchronous, collaborative learning environment, Educational Technology Research and Development, 54, 4, pp. 331-354, (2006); 
Brown T., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D., Wu J., Winter C., Amodei D., Language models are few-shot learners, Advances in neural information processing systems, pp. 1877-1901, (2020); 
Burstein J., The E-rater® scoring engine: Automated essay scoring with natural language processing, Automated essay scoring: A cross-disciplinary perspective, pp. 113-121, (2003); 
Burstein J., Kukich K., Wolff S., Lu C., Chodorow M., Braden-Harder L., Harris M.D., Automated scoring using a hybrid feature identification technique, 1, (1998); 
Butler D.L., Winne P.H., Feedback and self-regulated learning: A theoretical synthesis, Review of Educational Research, 65, 3, pp. 245-281, (1995); 
Caciularu A., Cohan A., Beltagy I., Peters M.E., Cattan A., Dagan I., CDLM: Cross-document language modeling, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2648-2662, (2021); 
Cheng L., Bing L., Yu Q., Lu W., Si L., APE: Argument pair extraction from peer review and rebuttal via multi-task learning, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pp. 7000-7011, (2020); 
Cho K., MacArthur C., Student revision with peer and expert reviewing, Learning and Instruction, 20, 4, pp. 328-338, (2010); 
Cho K., Schunn C.D., Scaffolded writing and rewriting in the discipline: A web-based reciprocal peer review system, Computers & Education, 48, 3, pp. 409-426, (2007); 
Cho Y.H., Cho K., Peer reviewers learn from giving comments, Instructional Science, 39, 5, pp. 629-643, (2011); 
Chronopoulou A., Peters M.E., Dodge J., Efficient hierarchical domain adaptation for pretrained language models, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1336-1351, (2022); 
Dasgupta T., Naskar A., Dey L., Saha R., Augmenting textual qualitative features in deep convolution recurrent neural network for automatic essay scoring, Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, pp. 93-102, (2018); 
Dasigi P., Lo K., Beltagy I., Cohan A., Smith N.A., Gardner M., A dataset of information-seeking questions and answers anchored in research papers, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4599-4610, (2021); 
De Wever B., Van Keer H., Schellens T., Valcke M., Assessing collaboration in a wiki: The reliability of university students' peer assessment, The Internet and Higher Education, 14, 4, pp. 201-206, (2011); 
Deutsch T., Jasbi M., Shieber S., Linguistic features for readability assessment, Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, pp. 1-17, (2020); 
Devlin J., Chang M.W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); 
Double K.S., McGrane J.A., Hopfenbeck T.N., The impact of peer assessment on academic performance: A meta-analysis of control group studies, Educational Psychology Review, 32, 2, pp. 481-509, (2020); 
Dycke N., Kuznetsov I., Gurevych I., Yes-yes-yes: Proactive data collection for ACL rolling review and beyond, Findings of the Association for Computational Linguistics: EMNLP 2022, pp. 300-318, (2022); 
Dycke N., Kuznetsov I., Gurevych I., NLPeer: A unified resource for the computational study of peer review, (2023); 
Fabbri A.R., Li I., She T., Li S., Radev D.R., Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 1074-1084, (2019); 
Fischer F., Bauer E., Seidel T., Schmidmaier R., Radkowitsch A., Neuhaus B.J., Hofer S.I., Sommerhoff D., Ufer S., Kuhn J., Kuchemann S., Sailer M., Koenen J., Gartmeier M., Berberat P., Frenzel A., Heitzmann N., Holzberger D., Pfeffer J., Fischer M.R., Representational scaffolding in digital simulations—Learning professional practices in higher education, Information and Learning Sciences, 123, 11-12, pp. 645-665, (2022); 
Fischer F., Kollar I., Ufer S., Sodian B., Hussmann H., Pekrun R., Neuhaus B., Dorner B., Pankofer S., Fischer M., Strijbos J.-W., Heene M., Eberle J., Scientific reasoning and argumentation: Advancing an interdisciplinary research agenda in education, Frontline Learning Research, 2, 3, pp. 28-45, (2014); 
Fischer G., User modeling in human–computer interaction, User Modeling and User-Adapted Interaction, 11, 1, pp. 65-86, (2001); 
Fischer G., Wolf K.D., What can residential, research-based universities learn about their core competencies from MOOCs (massive open online courses)?, Teaching is touching the future. Academic teaching within and across disciplines, pp. 65-75, (2015); 
Gielen M., De Wever B., Structuring the peer assessment process: A multilevel approach for the impact on product improvement and peer feedback quality, Journal of Computer Assisted Learning, 31, 5, pp. 435-449, (2015); 
Greene J.A., Azevedo R., A macro-level analysis of SRL processes and their relations to the acquisition of a sophisticated mental model of a complex system, Contemporary Educational Psychology, 34, 1, pp. 18-29, (2009); 
Greisel M., Spang L., Fett K., Melzner N., Dresel M., Kollar I., “Houston, we have a problem!” Homogeneous problem perception, and immediacy and intensity of strategy use in online collaborative learning, Proceedings of the 14th International Conference on Computer-Supported Collaborative Learning—CSCL 2021, pp. 99-106, (2021); 
Grosse C.S., Renkl A., Finding and fixing errors in worked examples: Can this foster learning outcomes?, Learning and Instruction, 17, 6, pp. 612-634, (2007); 
Hattie J., Visible learning: A synthesis of over 800 meta-analyses relating to achievement, (2008); 
Hattie J., Timperley H., The power of feedback, Review of Educational Research, 77, 1, pp. 81-112, (2007); 
Heitzmann N., Opitz A., Stadler M., Sommerhoff D., Fink M.C., Obersteiner A., Schmidmaier R., Neuhaus B.J., Ufer S., Seidel T., Fischer M.R., Fischer F., Cross-disciplinary research on learning and instruction—Coming to terms, Frontiers in Psychology, 1539, (2021); 
Hetmanek A., Engelmann K., Opitz A., Fischer F., Beyond intelligence and domain knowledge: Scientific reasoning and argumentation as a set of cross-domain skills, Scientific reasoning and argumentation: The roles of domain-specific and domain-general knowledge, pp. 203-226, (2018); 
Hornstein J., Greisel M., Ott J., Weidenbacher A., Kollar I., Promoting evidence-informed reasoning in student teachers through peer feedback, 20th Biennial EARLI Conference Thessaloniki, (2023); 
Hua X., Nikolov M., Badugu N., Wang L., Argument mining for understanding peer reviews, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2131-2137, (2019); 
Huisman B., Saab N., van Driel J., van den Broek P., Peer feedback on academic writing: Undergraduate students' peer feedback role, peer feedback perceptions and essay performance, Assessment & Evaluation in Higher Education, 43, 6, pp. 955-968, (2018); 
Huisman B., Saab N., Van Driel J., Van Den Broek P., A questionnaire to assess students' beliefs about peer-feedback, Innovations in Education and Teaching International, 57, 3, pp. 328-338, (2020); 
Kalyuga S., Expertise reversal effect and its implications for learner-tailored instruction, Educational Psychology Review, 19, 4, pp. 509-539, (2007); 
Kasneci E., Sessler K., Kuchemann S., Bannert M., Dementieva D., Fischer F., Gasser U., Groh G., Gunnemann S., Hullermeier E., Krusche S., Kutyniok G., Michaeli T., Nerdel C., Pfeffer J., Poquet O., Sailer M., Schmidt A., Seidel T., Kasneci G., ChatGPT for good? On opportunities and challenges of large language models for education, Learning and Individual Differences, 103, (2023); 
Kaufman J.H., Schunn C.D., Students' perceptions about peer assessment for writing: Their origin and impact on revision work, Instructional Science, 39, 3, pp. 387-406, (2011); 
Ke Z., Ng V., Automated essay scoring: A survey of the state of the art, Proceedings of IJCAI-19, pp. 6300-6308, (2019); 
Kennard N., O'Gorman T., Das R., Sharma A., Bagchi C., Clinton M., Yelugam P.K., Zamani H., McCallum A., DISAPERE: A dataset for discourse structure in peer review discussions, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1234-1249, (2022); 
Koivuniemi M., Panadero E., Malmberg J., Jarvela S., Higher education students' learning challenges and regulatory skills in different learning situations/Desafíos de aprendizaje y habilidades de regulación en distintas situaciones de aprendizaje en estudiantes de educación superior, Infancia y Aprendizaje, 40, 1, pp. 19-55, (2017); 
Kucirkova N., Gerard L., Linn M.C., Designing personalised instruction: A research and design framework, British Journal of Educational Technology, 52, 5, pp. 1839-1861, (2021); 
Kuznetsov I., Buchmann J., Eichler M., Gurevych I., Revise and resubmit: An intertextual model of text-based collaboration in peer review, Computational Linguistics, 48, 4, pp. 1-38, (2022); 
Li H., Xiong Y., Hunter C.V., Guo X., Tywoniw R., Does peer assessment promote student learning? A meta-analysis, Assessment & Evaluation in Higher Education, 45, 2, pp. 193-211, (2020); 
Lin J.W., Tsai C.W., The impact of an online project-based learning environment with group awareness support on students with different self-regulation levels: An extended-period experiment, Computers & Education, 99, pp. 28-38, (2016); 
Linn M.C., Eylon B.-S., Davis E.A., The knowledge integration perspective on learning, Internet environments for science education, pp. 29-46, (2013); 
Lippi M., Torroni P., Argumentation mining: State of the art and emerging trends, ACM Transactions on Internet Technology (TOIT), 16, 2, pp. 1-25, (2016); 
Liu L., Hao J., von Davier A.A., Kyllonen P., Zapata-Rivera J., A tough nut to crack: Measuring collaborative problem solving, Handbook of research on technology tools for real-world skill development, pp. 344-359, (2016); 
Logan R.L., Passos A., Singh S., Chang M.W., FRUIT: Faithfully reflecting updated information in text, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 3670-3686, (2022); 
Lugini L., Litman D., Predicting specificity in classroom discussion, Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications, pp. 52-61, (2017); 
Lugini L., Litman D., Contextual argument component classification for class discussions, Proceedings of the 28th International Conference on Computational Linguistics, pp. 1475-1480, (2020); 
Lundstrom K., Baker W., To give is better than to receive: The benefits of peer review to the reviewer's own writing, Journal of Second Language Writing, 18, pp. 30-43, (2009); 
Maynez J., Narayan S., Bohnet B., McDonald R., On faithfulness and factuality in abstractive summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 1906-1919, (2020); 
Michel C., Lavoue E., George S., Ji M., Supporting awareness and self-regulation in project-based learning through personalized dashboards, International Journal of Technology Enhanced Learning, 9, 2-3, pp. 204-226, (2017); 
Mohammad S., Ethics sheets for AI tasks, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp. 8368-8379, (2022); 
Narciss S., Feedback strategies for interactive learning tasks, Handbook of research on educational communications and technology, pp. 125-144, (2008); 
Narciss S., Sosnovsky S., Schnaubert L., Andres E., Eichelmann A., Goguadze G., Melis E., Exploring feedback and student characteristics relevant for personalizing feedback strategies, Computers & Education, 71, pp. 56-76, (2014); 
Newman-Griffis D., Lehman J.F., Rose C., Hochheiser H., Translational NLP: A new paradigm and general principles for natural language processing research, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4125-4138, (2021); 
Nguyen H., Xiong W., Litman D., Instant feedback for increasing the presence of solutions in peer reviews, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, pp. 6-10, (2016); 
Nicol D., The power of internal feedback: Exploiting natural comparison processes, Assessment & Evaluation in Higher Education, 46, 5, pp. 756-778, (2021); 
Nicol D., Thomson A., Breslin C., Rethinking feedback practices in higher education: A peer review perspective, Assessment & Evaluation in Higher Education, 39, 1, pp. 102-122, (2014); 
Ninaus M., Sailer M., Closing the loop—The human role in artificial intelligence for education, Frontiers in Psychology, 13, (2022); 
GPT-4 Technical Report, (2023); 
Page E.B., The use of the computer in analyzing student essays, International Review of Education, 14, 2, pp. 210-225, (1968); 
Panadero E., Is it safe? Social, interpersonal, and human effects of peer assessment, Handbook of human and social conditions in assessment, pp. 247-266, (2016); 
Panadero E., Lipnevich A.A., A review of feedback models and typologies: Towards an integrative model of feedback elements, Educational Research Review, 35, (2022); 
Patchan M.M., Hawk B., Stevens C.A., Schunn C.D., The effects of skill diversity on commenting and revisions, Instructional Science, 41, 2, pp. 381-405, (2013); 
Patchan M.M., Schunn C.D., Understanding the benefits of providing peer feedback: How students respond to peers' texts of varying quality, Instructional Science, 43, 5, pp. 591-614, (2015); 
Patchan M.M., Schunn C.D., Clark R.J., Accountability in peer assessment: Examining the effects of reviewing grades on peer ratings and peer feedback, Studies in Higher Education, 43, 12, pp. 2263-2278, (2018); 
Patchan M.M., Schunn C.D., Correnti R.J., The nature of feedback: How peer feedback features affect students' implementation rate and quality of revisions, Journal of Educational Psychology, 108, 8, pp. 1098-1120, (2016); 
Peters O., Korndle H., Narciss S., Effects of a formative assessment script on how vocational students generate formative feedback to a peer's or their own performance, European Journal of Psychology of Education, 33, 1, pp. 117-143, (2018); 
Pfeiffer J., Meyer C.M., Schulz C., Kiesewetter J., Zottmann J., Sailer M., Bauer E., Fischer F., Fischer M.R., Gurevych I., Famulus: Interactive annotation and feedback generation for teaching diagnostic reasoning, The 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing—Proceedings of system demonstrations: Emnlp-IJCNLP 2019, pp. 73-78, (2019); 
Pfeiffer J., Vulic I., Gurevych I., Ruder S., MAD-X: An adapter-based framework for multi-task cross-lingual transfer, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pp. 7654-7673, (2020); 
Plass J.L., Pawar S., Toward a taxonomy of adaptivity for learning, Journal of Research on Technology in Education, 52, 3, pp. 275-300, (2020); 
Quintana C., Reiser B.J., Davis E.A., Krajcik J., Fretz E., Duncan R.G., Kyza E., Edelson D., Soloway E., A scaffolding design framework for software to support science inquiry, Journal of the Learning Sciences, 13, 3, pp. 337-386, (2004); 
Rakovic M., Bernacki M.L., Greene J.A., Plumley R.D., Hogan K.A., Gates K.M., Panter A.T., Examining the critical role of evaluation and adaptation in self-regulated learning, Contemporary Educational Psychology, 68, (2022); 
Rapanta C., Walton D., The use of argument maps as an assessment tool in higher education, International Journal of Educational Research, 79, pp. 211-221, (2016); 
Reimers N., Gurevych I., Sentence-BERT: Sentence embeddings using Siamese BERT-networks, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pp. 3982-3992, (2019); 
Rogers A., Baldwin T., Leins K., ‘Just what do you think you're doing, Dave?’ A checklist for responsible data use in NLP, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 4821-4833, (2021); 
Rotsaert T., Panadero E., Schellens T., Raes A., “Now you know what you're doing right and wrong!” Peer feedback quality in synchronous peer assessment in secondary education, European Journal of Psychology of Education, 33, 2, pp. 255-275, (2018); 
Rouet J.-F., Britt M.A., Relevance processes in multiple document comprehension, Text relevance and learning from text, pp. 19-52, (2011); 
Sailer M., Bauer E., Hofmann R., Kiesewetter J., Glas J., Gurevych I., Fischer F., Adaptive feedback from artificial neural networks facilitates pre-service teachers' diagnostic reasoning in simulation-based learning, Learning and Instruction, 83, (2023); 
Sailer M., Schultz-Pernice F., Fischer F., Contextual facilitators for learning activities involving technology in higher education: The C♭-model, Computers in Human Behavior, 121, (2021); 
Schick T., Dwivedi-Yu J., Jiang Z., Petroni F., Lewis P., Izacard G., You Q., Nalmpantis C., Grave E., Riedel S., PEER: A collaborative language model, (2022); 
Schulz C., Meyer C.M., Gurevych I., Challenges in the automatic analysis of students' Ddiagnostic reasoning, The 57th Annual Meeting of the Association for Computational Linguistics—Proceedings of the Conference, pp. 6974-6981, (2019); 
Strijbos J.-W., Pat-El R., Narciss S., Structural validity and invariance of the feedback perceptions questionnaire, Studies in Educational Evaluation, 68, (2021); 
Tabak I., Kyza E.A., Research on scaffolding in the learning sciences: A methodological perspective, International handbook of the learning sciences, pp. 191-200, (2018); 
Tenney I., Wexler J., Bastings J., Bolukbasi T., Coenen A., Gehrmann S., Jiang E., Pushkarna M., Radebaugh C., Reif E., Yuan A., The language interpretability tool: Extensible, interactive visualizations and analysis for NLP models, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 107-118, (2020); 
Tetzlaff L., Schmiedek F., Brod G., Developing personalized education: A dynamic framework, Educational Psychology Review, 33, 3, pp. 863-882, (2021); 
Tsovaltzi D., McLaren B.M., Melis E., Meyer A.K., Erroneous examples: Effects on learning fractions in a web-based setting, International Journal of Technology Enhanced Learning, 4, 3-4, pp. 191-230, (2012); 
Utama P.A., Moosavi N.S., Gurevych I., Towards debiasing NLU models from unknown biases, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pp. 7597-7610, (2020); 
Van Merrienboer J.J., Kirschner P.A., 4C/ID in the context of instructional design and the learning sciences, International handbook of the learning sciences, pp. 169-179, (2018); 
Voet M., Gielen M., Boelens R., De Wever B., Using feedback requests to actively involve assessees in peer assessment: Effects on the assessor's feedback content and assessee's agreement with feedback, European Journal of Psychology of Education, 33, 1, pp. 145-164, (2018); 
Vogel F., Kollar I., Fischer F., Reiss K., Ufer S., Adaptable scaffolding of mathematical argumentation skills: The role of self-regulation when scaffolded with CSCL scripts and heuristic worked examples, International Journal of Computer-Supported Collaborative Learning, 17, pp. 39-64, (2022); 
Wambsganss T., Niklaus C., Cetto M., Sollner M., Handschuh S., Leimeister J.M., AL: An adaptive learning support system for argumentation skills, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-14, (2020); 
Wang X., Kollar I., Stegmann K., Adaptable scripting to foster regulation processes and skills in computer-supported collaborative learning, International Journal of Computer-Supported Collaborative Learning, 12, pp. 153-172, (2017); 
Wang Y., Mishra S., Alipoormolabashi P., Kordi Y., Mirzaei A., Arunkumar A., Ashok A., Dhanasekaran A.S., Naik A., Stap D., Pathak E., Karamanolakis G., Lai H.G., Purohit I., Mondal I., Anderson J., Kuznia K., Doshi K., Patel M., Khashabi D., Super-natural instructions: Generalization via declarative instructions on 1600+ nlp tasks, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 5085-5109, (2022); 
Wichmann A., Funk A., Rummel N., Leveraging the potential of peer feedback in an academic writing activity through sense-making support, European Journal of Psychology of Education, 33, 1, pp. 165-184, (2018); 
Wu Y., Schunn C.D., When peers agree, do students listen? The central role of feedback quality and feedback frequency in determining uptake of feedback, Contemporary Educational Psychology, 62, (2020); 
Yang D., Halfaker A., Kraut R., Hovy E., Identifying semantic edit intentions from revisions in Wikipedia, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2000-2010, (2017); 
Zhang F., Hashemi H.B., Hwa R., Litman D., A corpus of annotated revisions for studying argumentative writing, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 1568-1578, (2017); 
Zhang H., Litman D., Essay quality signals as weak supervision for source-based essay scoring, Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications, pp. 85-96, (2021); 
Zhang T., Kishore V., Wu F., Weinberger K.Q., Artzi Y., BERTScore: Evaluating text generation with BERT. International Conference on Learning Representations, (2020)#FRF#
