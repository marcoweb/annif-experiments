#ITI#Interpretable Dropout Prediction: Towards XAI-Based Personalized Intervention#FTI#
#IRE# Student drop-out is one of the most burning issues in STEM higher education, which induces considerable social and economic costs. Using machine learning tools for the early identification of students at risk of dropping out has gained a lot of interest recently. However, there has been little discussion on dropout prediction using interpretable machine learning (IML) and explainable artificial intelligence (XAI) tools.In this work, using the data of a large public Hungarian university, we demonstrate how IML and XAI tools can support educational stakeholders in dropout prediction. We show that complex machine learning models – such as the CatBoost classifier – can efficiently identify at-risk students relying solely on pre-enrollment achievement measures, however, they lack interpretability. Applying IML tools, such as permutation importance (PI), partial dependence plot (PDP), LIME, and SHAP values, we demonstrate how the predictions can be explained both globally and locally. Explaining individual predictions opens up great opportunities for personalized intervention, for example by offering the right remedial courses or tutoring sessions. Finally, we present the results of a user study that evaluates whether higher education stakeholders find these tools interpretable and useful.#FRE#
#IPC# Dropout prediction; Educational data science; Explainable AI; Higher education; Interpretable machine learning#FPC#
#IRF# Adadi A., Berrada M., Peeking inside the black-box: a survey on explainable artificial intelligence (XAI), IEEE Access, 6, pp. 52138-52160, (2018); 
Akiba T., Sano S., Yanase T., Ohta T., Koyama M., Optuna: A next-generation hyperparameter optimization framework, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (2019); 
Alyahyan E., Dustegor D., Predicting academic success in higher education: literature review and best practices, International Journal of Educational Technology in Higher Education, 17, 1, pp. 1-21, (2020); 
Avella J.T., Kebritchi M., Nunn S.G., Kanai T., Learning analytics methods, benefits, and challenges in higher education: a systematic literature review, Online Learning, 20, 2, pp. 13-29, (2016); 
Baranyi M., Nagy M., Molontay R., Interpretable deep learning for university dropout prediction, Proceedings of the 21st Annual Conference on Information Technology Education, pp. 13-19, (2020); 
Baranyi M., Molontay R., Comparing the effectiveness of two remedial mathematics courses using modern regression discontinuity techniques, Interactive Learning Environments, 29, 2, pp. 247-269, (2021); 
Behr A., Giese M., Theune K., Et al., Early prediction of university dropouts – a random forest approach, Jahrbücher Für Nationalökonomie Und Statistik, 240, 6, pp. 743-789, (2020); 
Cano A., Leonard J.D., Interpretable multiview early warning system adapted to underrepresented student populations, IEEE Transactions on Learning Technologies, 12, 2, pp. 198-211, (2019); 
Coussement K., Phan M., De Caigny A., Benoit D.F., Raes A., Predicting student dropout in subscription-based online learning environments: the beneficial impact of the logit leaf model, Decision Support Systems, 135, (2020); 
Dutt A., Ismail M.A., Herawan T., A systematic review on educational data mining, IEEE Access, 5, pp. 15991-16005, (2017); 
Fisher A., Rudin C., Dominici F., All models are wrong, but many are useful: learning a variable’s importance by studying an entire class of prediction models simultaneously, Journal of Machine Learning Research, 20, 177, pp. 1-81, (2019); 
Freitas F., Vasconcelos F.F., Peixoto S.A., Hassan M.M., Dewan M., Albuquerque V., Et al., IoT system for school dropout prediction using machine learning techniques based on socioeconomic data, Electronics, 9, 10, (2020); 
Greenwell B.M., Boehmke B.C., McCarthy A.J., A simple and effective model-based variable importance measure, (2018); 
Why do tree-based models still outperform deep learning on typical tabular data?, In: Thirty-Sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track., (2022); 
Gunning D., Stefik M., Choi J., Miller T., Stumpf S., Yang G.Z., XAI—Explainable artificial intelligence, Science Robotics, 4, 37, (2019); 
He J., Bailey J., Rubinstein B., Zhang R., Identifying at-risk students in massive open online courses, Proceedings of the AAAI Conference on Artificial Intelligence, vol 29 no 1, (2015); 
Helal S., Li J., Liu L., Ebrahimie E., Dawson S., Murray D.J., Identifying key factors of student academic performance by subgroup discovery, Int J Data Sci Anal, 7, 3, pp. 227-245, (2019); 
Jin W., Fan J., Gromala D., Pasquier P., Li X., Hamarneh G., Transcending XAI algorithm boundaries through end-user-inspired design, (2022); 
Karimi A.H., Barthe G., Balle B., Valera I., Model-agnostic counterfactual explanations for consequential decisions, International Conference on Artificial Intelligence and Statistics, PMLR, pp. 895-905, (2020); 
Karlos S., Kostopoulos G., Kotsiantis S., Predicting and interpreting students’ grades in distance higher education through a semi-regression method, Applied Sciences, 10, 23, (2020); 
Kumar V.S., Boulanger D., Automated essay scoring and the deep learning black box: how are rubric scores determined?, International Journal of Artificial Intelligence in Education, 31, 3, pp. 538-584, (2021); 
Latif A., Choudhary A.I., Hammayun A.A., Economic effects of student dropouts: a comparative study, Journal of Global Economics, 3, 137, (2015); 
Lee S., Chung J.Y., The machine learning-based dropout early warning system for improving the performance of dropout prediction, Applied Sciences, 9, 15, (2019); 
Looveren A.V., Klaise J., Interpretable counterfactual explanations guided by prototypes, Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 650-665, (2021); 
Lundberg S.M., Lee S.I., A unified approach to interpreting model predictions, Advances in Neural Information Processing Systems 30, pp. 4765-4774, (2017); 
Marquez-Vera C., Cano A., Romero C., Noaman A.Y.M., Mousa Fardoun H., Ventura S., Early dropout prediction using data mining: a case study with high school students, Expert Systems, 33, 1, pp. 107-124, (2016); 
Mingyu Z., Sutong W., Yanzhang W., Dujuan W., An interpretable prediction method for university student academic crisis warning, Complex & Intelligent Systems, 8, pp. 1-14, (2021); 
General pitfalls of model-agnostic interpretation methods for machine learning models, In: Ai-Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, pp. 39-68, (2022); 
Molnar C., Interpretable Machine Learning, (2020); 
Molontay R., Nagy M., How to improve the predictive validity of a composite admission score? a case study from hungary, Assessment & Evaluation in Higher Education, pp. 1-19, (2022); 
Mothilal R.K., Sharma A., Tan C., Explaining machine learning classifiers through diverse counterfactual explanations, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 607-617, (2020); 
Nagrecha S., Dillon J.Z., Chawla N.V., MOOC Dropout Prediction: Lessons learned from making pipelines interpretable, Proceedings of the 26th International Conference on World Wide Web Companion, pp. 351-359, (2017); 
Nagy M., Molontay R., Szabo M., A web application for predicting academic performance and identifying the contributing factors, 47th Annual Conference of SEFI, pp. 1794-1806, (2019); 
Nagy M., Molontay R., Comprehensive analysis of the predictive validity of the university entrance score in Hungary, Assessment & Evaluation in Higher Education, pp. 1-19, (2021); 
Niculescu-Mizil A., Caruana R., Predicting good probabilities with supervised learning, Proceedings of the 22nd international conference on Machine learning, pp. 625-632, (2005); 
Platt J., Et al., Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods, Advances in large margin classifiers, 10, 3, pp. 61-74, (1999); 
Powell W.W., Snellman K., The knowledge economy, The Annual Review of Sociology, 30, pp. 199-220, (2004); 
Prokhorenkova L., Gusev G., Vorobev A., Dorogush A.V., Gulin A., Catboost: unbiased boosting with categorical features, Proceedings of the 32nd International Conference on Neural Information Processing Systems (NeurIPS’18), pp. 1-11, (2018); 
Rastrollo-Guerrero J.L., Gomez-Pulido J.A., Duran-Dominguez A., Analyzing and predicting students’ performance by means of machine learning: a review, Applied Sciences, 10, 3, (2020); 
Ribeiro M.T., Singh S., Guestrin C., Why should I trust you?”: Explaining the predictions of any classifier, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13–17, 2016, pp. 1135-1144, (2016); 
Rovira S., Puertas E., Igual L., Data-driven system to predict academic grades and dropout, PLoS One, 12, 2, (2017); 
Sargsyan A., Karapetyan A., Woon W.L., Alshamsi A., Explainable AI as a Social Microscope: A Case Study on Academic Performance, International Conference on Machine Learning, Optimization, and Data Science, pp. 257-268, (2020); 
Schneider J., Richner R., Riser M., Towards trustworthy autograding of short, multi-lingual, multi-type answers, International Journal of Artificial Intelligence in Education, 33, pp. 88-118, (2022); 
Sellei B., Stumphauser N., Molontay R., Traits versus grades—the incremental predictive power of positive psychological factors over pre-enrollment achievement measures on academic performance, Applied Sciences, 11, 4, (2021); 
Shaffer J., 5 tips on designing colorblind-friendly visualizations, (2016); 
Shwartz-Ziv R., Armon A., Tabular data: Deep learning is not all you need, Inform Fusion, 81, pp. 84-90, (2022); 
Smith B.I., Chimedza C., Buhrmann J.H., Individualized help for at-risk students using model-agnostic and counterfactual explanations, Education and Information Technologies, 27, pp. 1539-1558, (2021); 
Varga E.B., Satan A., Detecting at-risk students on computer science bachelor programs based on pre-enrollment characteristics, Hungarian Educational Research Journal, 3, 11, pp. 297-310, (2021); 
Vultureanu- Albisi A., Badica C.,  Improving students’ performance by interpretable explanations using ensemble tree-based approaches, IEEE 15th International Symposium on Applied Computational Intelligence and Informatics (SACI), IEEE, pp. 215-220, (2021); 
Yu H., Miao C., Leung C., White T.J., Towards AI-powered personalization in MOOC learning, npj Science of Learning, 2, 1, pp. 1-5, (2017); 
Yu R., Lee H., Kizilcec R.F.,  Should college dropout prediction models include protected attributes?, Proceedings of the eighth ACM conference on learning@ scale, pp. 91-100, (2021); 
Zawacki-Richter O., Marin V.I., Bond M., Gouverneur F., Systematic review of research on artificial intelligence applications in higher education–where are the educators?, International Journal of Educational Technology in Higher Education, 16, 1, pp. 1-27, (2019); 
Zeleny K., Molontay R., Szabo M., A kollégiumi lét egyetemi teljesítményre gyakorolt hatásának vizsgálata, Statisztikai Szemle, 99, 1, pp. 46-79, (2021); 
Zhang W., Zhou Y., Yi B., An interpretable online learner’s performance prediction model based on learning analytics, Proceedings of the 2019 11th International Conference on Education Technology and Computers, pp. 148-154, (2019); 
Zwick R., Himelfarb I., The effect of high school socioeconomic status on the predictive validity of sat scores and high school grade-point average, Journal of Educational Measurement, 48, 2, pp. 101-121, (2011)#FRF#
