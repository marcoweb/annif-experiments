#ITI#Learning challenging L2 sounds via computer-assisted training: Audiovisual training with an airflow model#FTI#
#IRE# Background: Teaching Mandarin as a second language (L2) has become an important profession and an important research area. The acquisition of unaspirated and aspirated consonants in Mandarin has been reported to be rather challenging for L2 learners. Objectives: In the current study, a 3-D airflow model was integrated into the virtual talking head for audiovisual pronunciation training in these Mandarin consonants. Methods: Using the eye-tracking technique, Experiment 1 investigated L2 learners' general acceptance and gauged attention distribution online while learning with the system. To further compare training efficacy, learning outcomes were evaluated by randomly dividing Japanese learners of Mandarin into different training groups using the 3-D tutor with and without an airflow model, respectively, in Experiment 2. Results and Conclusions: Eye-tracking results showed that the talking head was well accepted, and was successful in directing L2 learners' attention to the visual modality of the airflow model marking the contrast in aspiration. Furthermore, the additional visual cue of the airflow model helped enhance their production of the aspirated Mandarin stops. Moreover, this computer-assisted training approach was shown to be robust as the advantage of training with an airflow model can be generalized to novel syllables with a change of tones or rimes#FRE#
#IPC# airflow model; audiovisual pronunciation training; eye tracking; second language learning; talking head#FPC#
#IRF# Abramson A.S., Whalen D.H., Voice onset time (VOT) at 50: Theoretical and practical issues in measuring voicing distinctions, Journal of Phonetics, 63, pp. 75-86, (2017); 
Badin P., Elisei F., Bailly G., Tarabalka Y., An Audiovisual Talking Head for Augmented Speech Generation: Models and Animations Based on a Real Speaker's Articulatory Data, Articulated Motion and Deformable Objects, 5098, pp. 132-143, (2008); 
Balter O., Engwall O., Oster A.-M., Kjellstrom H., Wizard-of-Oz test of ARTUR: A computer-based speech training system with articulation correction, (2005); 
Bates D., Machler M., Bolker B., Walker S., Fitting linear mixed-effects models using lme4, Journal of Statistical Software, 67, 1, pp. 1-48, (2015); 
Best C.T., Tyler M.D., Nonnative and second-language speech perception: Commonalities and complementarities, Language learning & language teaching, 17, pp. 13-34, (2007); 
Brown C.A., The role of the L1 grammar in the L2 acquisition of segmental structure, Second Language Research, 14, 2, pp. 136-193, (1998); 
Chen F., Chen H., Wang L., Zhou Y., He J., Yan N., Peng G., Intelligible enhancement of 3D articulation animation by incorporating airflow information, pp. 6130-6134, (2016); 
Chen M., Computer-aided feedback on the pronunciation of Mandarin Chinese tones: Using Praat to promote multimedia foreign language learning, Computer Assisted Language Learning, 1-26, pp. 1-26, (2022); 
Chen N.F., Tong R., Wee D., Lee P., Ma B., Li H., iCALL corpus: Mandarin Chinese spoken by non-native speakers of European descent, 2015, pp. 324-328, (2015); 
Chen N.F., Wee D., Tong R., Ma B., Li H., Large-scale characterization of non-native mandarin Chinese spoken by speakers of European origin: Analysis on iCALL, Speech Communication, 84, pp. 46-56, (2016); 
Chen T.H., Massaro D.W., Evaluation of synthetic and natural mandarin visual speech: Initial consonants, single vowels, and syllables, Speech Communication, 53, 7, pp. 955-972, (2011); 
Cho T., Ladefoged P., Variation and universals in VOT: Evidence from 18 languages, Journal of Phonetics, 27, 2, pp. 207-229, (1999); 
Chun D.M., Signal analysis software for teaching discourse intonation, Language Learning and Technology, 2, 1, pp. 74-93, (1998); 
Colpaert J., The “publish and perish” syndrome, Computer Assisted Language Learning, 25, 5, pp. 383-391, (2012); 
Colpaert J., Big content in an educational engineering approach, Journal of Technology and Chinese Language Teaching, 7, 1, pp. 1-14, (2016); 
Couper G., The short and long-term effects of pronunciation instruction, Prospect, 21, 1, pp. 46-66, (2006); 
Felix U., Analysing recent CALL effectiveness research—towards a common agenda, Computer Assisted Language Learning, 18, 1-2, pp. 1-32, (2005); 
Flege J., Second language speech learning: Theory, findings and problems, Speech perception and linguistic experience: Issues in cross-language research, pp. 229-273, (1995); 
Godfroid A., Schmidtke J., What do eye movements tell us about awareness? A triangulation of eye-movement data, verbal reports, and vocabulary learning scores, Noticing and second language acquisition: Studies in honor of Richard Schmidt, pp. 183-206, (2013); 
Golonka E.M., Bowles A.R., Frank V.M., Richardson D.L., Freynik S., Technologies for foreign language learning: A review of technology types and their effectiveness, Computer Assisted Language Learning, 27, 1, pp. 70-105, (2014); 
Haslam N.O., The relationship of three L2 learning factors with pronunciation proficiency: Language aptitude, strategy use, and learning context, (2010); 
Hazan V., Sennema A., Iba M., Faulkner A., Effect of audiovisual perceptual training on the perception and production of consonants by Japanese learners of English, Speech Communication, 47, 3, pp. 360-378, (2005); 
Hincks R., Speech technologies for pronunciation feedback and evaluation, ReCALL, 15, 1, pp. 3-20, (2003); 
Hua Z., Dodd B., The phonological acquisition of Putonghua (modern standard Chinese), Journal of Child Language, 27, 1, pp. 3-42, (2000); 
Hubbard P., A review of subject characteristics in CALL research, Computer Assisted Language Learning, 18, 5, pp. 351-368, (2005); 
Kipp M., ANVIL - a generic annotation tool for multimodal dialogue. In EUROSPEECH 2001 Scandinavia, 7th European Conference on Speech Communication and Technology, pp. 1367-1370, (2001); 
Krashen S.D., The input hypothesis: Issues and implications, (1985); 
Kuznetsova A., Brockhoff P.B., Christensen R.H.B., lmerTest package: Tests in linear mixed effects models, Journal of Statistical Software, 82, 13, pp. 1-26, (2017); 
Lai Y., Asymmetry in mandarin affricate perception by learners of mandarin Chinese, Language and Cognitive Processes, 24, 7-8, pp. 1265-1285, (2009); 
Lam H.C., Ki W.W., Law N., Chung A.L.S., Ko P.Y., Ho A.H.S., Pun S.W., Designing CALL for learning Chinese characters: CALL for learning Chinese characters, Journal of Computer Assisted Learning, 17, 1, pp. 115-128, (2001); 
Lenth R.V., Least-squares means: The R package lsmeans, Journal of Statistical Software, 69, 1, pp. 1-33, (2016); 
Li H., Yang M., Tao J., Speaker-independent lips and tongue visualization of vowels, pp. 8106-8110, (2013); 
Liu H.-C., Chuang H.-H., An examination of cognitive processing of multimedia information based on viewers' eye movements, Interactive Learning Environments, 19, 5, pp. 503-517, (2011); 
Liu X., Yan N., Wang L., Wu X., Ng M.L., An interactive speech training system with virtual reality articulation for mandarin-speaking hearing impaired children, pp. 191-196, (2013); 
Massaro D.W., Perceiving talking faces: From speech perception to a behavioral principle, (1998); 
Mcclelland J., Fiez J., Mccandliss B., Teaching the /r/−/l/ discrimination to Japanese adults: Behavioral and neural aspects, Physiology & Behavior, 77, 4-5, pp. 657-662, (2002); 
Morley J., The pronunciation component in teaching English to speakers of other languages, TESOL Quarterly, 25, 3, (1991); 
Motohashi-Saigo M., Hardison D., Acquisition of L2 Japanese geminates: Training with waveform displays, Language Learning and Technology, 13, 2, pp. 29-47, (2009); 
Navarra J., Soto-Faraco S., Hearing lips in a second language: Visual articulatory information enables the perception of second language sounds, Psychological Research, 71, 1, pp. 4-12, (2007); 
Ni H., Wang J., Wang L., Yan N., Track your emotional perception of 3-D virtual talking head in human-computer interaction, 2018, pp. 298-303, (2018); 
Okuno T., Hardison D., Perception-production link in L2 Japanese vowel duration: Training with technology, Language, Learning and Technology, 20, 2, pp. 61-80, (2016); 
Olson D., Benefits of visual feedback on segmental production in the L2 classroom, Language Learning and Technology, 18, 3, pp. 173-192, (2014); 
Peng X., Chen H., Wang L., Wang H., Evaluating a 3-D virtual talking head on pronunciation learning, International Journal of Human-Computer Studies, 109, pp. 26-40, (2018); 
Piper T., Cansin D., Factors influencing the foreign accent, The Canadian Modern Language Review, 44, 2, pp. 334-342, (1988); 
Plopski A., Hirzle T., Norouzi N., Qian L., Bruder G., Langlotz T., The eye in extended reality: A survey on gaze interaction and eye tracking in head-worn extended reality, ACM Computing Surveys, 55, 3, pp. 53:1-53:39, (2022); 
R: A language and environment for statistical computing, (2017); 
Rizzolatti G., Craighero L., The mirror-neuron system, Annual Review of Neuroscience, 27, 1, pp. 169-192, (2004); 
Robinson P., Attention, memory, and the “noticing” hypothesis, Language Learning, 45, 2, pp. 283-331, (1995); 
Schmidt R.W., The role of consciousness in second language learning, Applied Linguistics, 11, 2, pp. 129-158, (1990); 
Segalowitz N., Automaticity and second languages, The handbook of second language acquisition, pp. 382-408, (2003); 
Shei C., Hsieh H.-P., Linkit: A CALL system for learning Chinese characters, words, and phrases, Computer Assisted Language Learning, 25, 4, pp. 319-338, (2012); 
Stam J., Stable fluids. In Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques - SIGGRAPH ‘99, 121–128, (1999); 
Stevens C.J., Gibert G., Leung Y., Zhang Z., Evaluating a synthetic talking head using a dual task: Modality effects on speech understanding and cognitive load, International Journal of Human-Computer Studies, 71, 4, pp. 440-454, (2013); 
Stockwell G., A review of technology choice for teaching language skills and areas in the CALL literature, ReCALL, 19, 2, pp. 105-120, (2007); 
Tham I., Chau M.H., Thang S.M., Bilinguals' processing of lexical cues in L1 and L2: An eye-tracking study, Computer Assisted Language Learning, 33, 7, pp. 665-687, (2020); 
Theobald B.-J., Fagel S., Bailly G., Elisei F., LIPS2008: Visual speech synthesis challenge, 2008, pp. 2310-2313, (2008); 
Vance T.J., An introduction to Japanese phonology, (1997); 
Wang J., Antonenko P., Dawson K., Does visual attention to the instructor in online video affect learning and learner perceptions?, An eye-tracking analysis. Computers & Education, 146, (2020); 
Wang L., Chen H., Li S., Meng H.M., Phoneme-level articulatory animation in pronunciation training, Speech Communication, 54, 7, pp. 845-856, (2012); 
Wang X., Hueber T., Badin P., On the use of an articulatory talking head for second language pronunciation training: The case of Chinese learners of French, pp. 449-452, (2014); 
Wang Y., Jongman A., Sereno J.A., Acoustic and perceptual evaluation of mandarin tone productions before and after perceptual training, The Journal of the Acoustical Society of America, 113, 2, pp. 1033-1043, (2003); 
Wang Y.-H., Could a mobile-assisted learning system support flipped classrooms for classical Chinese learning?, Journal of Computer Assisted Learning, 32, 5, pp. 391-415, (2016); 
Weiss B., Kuhnel C., Wechsung I., Fagel S., Moller S., Quality of talking heads in different interaction and media contexts, Speech Communication, 52, 6, pp. 481-492, (2010); 
Wu Z.Y., Zhang S., Cai L.H., Meng H.M., Real-time synthesis of Chinese visual speech and facial expressions using MPEG-4 FAP features in a three-dimensional avatar, pp. 1802-1805, (2006); 
Xie H., Zhao T., Deng S., Peng J., Wang F., Zhou Z., Using eye movement modelling examples to guide visual attention and foster cognitive performance: A meta-analysis, Journal of Computer Assisted Learning, 37, 4, pp. 1194-1206, (2021); 
Yu J., Li A., 3D visual pronunciation of mandarin Chinese for language learning, 2014 IEEE International Conference on Image Processing (ICIP), pp. 2036-2040, (2014); 
Zhang D., Liu X., Yan N., Wang L., Zhu Y., Chen H., A multi-channel/multi-speaker articulatory database in mandarin for speech visualization, pp. 299-303, (2014); 
Zhang H., Roberts L., The role of phonological awareness and phonetic radical awareness in acquiring Chinese literacy skills in learners of Chinese as a second language, System, 81, pp. 163-178, (2019); 
Zhang L.J., Perceptual training and the acquisition of Chinese aspirated/unaspirated consonants by Japanese students, Language Teaching and Linguistic Studies, 4, pp. 560-566, (2009); 
Zhao Y., Recent developments in technology and language learning: A literature review and meta-analysis, CALICO Journal, 21, 1, pp. 7-27, (2003)#FRF#
