#ITI#How well do collaboration quality estimation models generalize across authentic school contexts?#FTI#
#IRE# Multimodal learning analytics (MMLA) research has made significant progress in modelling collaboration quality for the purpose of understanding collaboration behaviour and building automated collaboration estimation models. Deploying these automated models in authentic classroom scenarios, however, remains a challenge. This paper presents findings from an evaluation of collaboration quality estimation models. We collected audio, video and log data from two different Estonian schools. These data were used in different combinations to build collaboration estimation models and then assessed across different subjects, different types of activities (collaborative-writing, group-discussion) and different schools. Our results suggest that the automated collaboration model can generalize to the context of different schools but with a 25% degradation in balanced accuracy (from 82% to 57%). Moreover, the results also indicate that multimodality brings more performance improvement in the case of group-discussion-based activities than collaborative-writing-based activities. Further, our results suggest that the video data could be an alternative for understanding collaboration in authentic settings where higher-quality audio data cannot be collected due to contextual factors. The findings have implications for building automated collaboration estimation systems to assist teachers with monitoring their collaborative classrooms. Practitioners notes What is already known about this topic Multimodal learning analytics researchers have established several features as potential indicators for collaboration quality, e.g., speaking time or joint visual attention. The current state of the art has shown the feasibility of building automated collaboration quality models. Recent research has provided preliminary evidence of the generalizability of developed automated models across contexts different in terms of given task and subject. What does this paper add This paper offers collaboration indicators for different types of collaborative learning activities in authentic classroom settings. The paper includes a systematic investigation into collaboration quality automated model's generalizability across different tasks, types of tasks and schools. This paper also offers a comparison between different modalities' potential to estimate collaboration quality in authentic settings. Implications for practice The findings inform the development of automated collaboration monitoring systems for authentic classroom settings. This paper provides evidence on across-school generalizability capabilities of collaboration quality estimation models#FRE#
#IPC# collaboration quality; computer-supported collaborative learning; generalizability; machine learning; multimodal learning analytics#FPC#
#IRF# Asterhan C.S.C., Schwarz B.B., Gil J., Small-group, computer-mediated argumentation in middle-school classrooms: The effects of gender and different types of online teacher guidance, British Journal of Educational Psychology, 82, 3, pp. 375-397, (2012); 
Barron B., When smart groups fail, The Journal of the Learning Sciences, 12, 3, pp. 307-359, (2003); 
Cai Y., Shimojo S., Hayashi Y., Observing facial muscles to estimate the learning state during collaborative learning: A focus on the ICAP framework, ICCE 2020 - 28th International Conference on Computers in Education, Proceedings, 1, pp. 119-126, (2020); 
Chejara P., Prieto L.P., Ruiz-Calleja A., Rodriguez-Triana M.J., Shankar S.K., Kasepalu R., EFAR-MMLA: An evaluation framework to assess and report generalizability of machine learning models in MMLA, Sensors, 21, 8, pp. 1-27, (2021); 
Chejara P., Kasepalu R., Prieto L.P., Rodriguez-Triana M.J., Ruiz-Calleja A., Shankar S.K., Multimodal learning analytics research in the wild: Challenges and their potential solutions, Proceedings of the 6th Workshop on Leveraging Multimodal Data for Generating Meaningful Feedback (CROSSMMLA 2023) at the 13th International Learning Analytics & Knowledge, pp. 36-42, (2023); 
Chejara P., Prieto L.P., Rodriguez-Triana M.J., Kasepalu R., Ruiz-Calleja A., Shankar S.K., How to build more generalizable models for collaboration quality? Lessons learned from exploring multi-context audio-log datasets using multimodal learning analytics, LAK23: 13th International Learning Analytics and Knowledge Conference, pp. 111-121, (2023); 
Chejara P., Prieto L.P., Rodriguez-Triana M.J., Ruiz-Calleja A., Kasepalu R., Chounta I.-A., Schneider B., Exploring indicators for collaboration quality and its dimensions in classroom settings using multimodal learning analytics, Responsive and sustainable educational futures, pp. 60-74, (2023); 
Chejara P., Prieto L.P., Rodriguez-Triana M.J., Ruiz-Calleja A., Khalil M., Impact of window size on the generalizability of collaboration quality estimation models developed using Multimodal Learning Analytics, LAK23: 13th International Learning Analytics and Knowledge Conference, pp. 559-565, (2023); 
Chounta I.A., Avouris N., Time series analysis of collaborative activities, Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics), 7493, pp. 145-152, (2012); 
Chua Y.H.V., Dauwels J., Tan S.C., Technologies for automated analysis of co-located, real-life, physical learning spaces, LAK’19: Proceedings of the 9th International Conference on Learning Analytics & Knowledge, pp. 11-20, (2019); 
Cocea M., Weibelzahl S., Can log files analysis estimate learners' level of motivation?, Lernen, Wissensentdeckung Und Adaptivitat, LWA, 2006, pp. 32-35, (2006); 
Craig S.D., D'Mello S., Witherspoon A., Graesser A., Emote aloud during learning with AutoTutor: Applying the facial action coding system to cognitive—Affective states during learning, Cognition and Emotion, 22, 5, pp. 777-788, (2008); 
Di Mitri D., Schneider J., Specht M., Drachsler H., From signals to knowledge: A conceptual model for multimodal learning analytics, Journal of Computer Assisted Learning, 34, 4, pp. 338-349, (2018); 
Duncan S., Some signals and rules for taking speaking turns in conversations, Journal of Personality and Social Psychology, 23, 2, pp. 283-292, (1972); 
Fiedler K., Beier S., Affect and cognitive processes in educational contexts, International handbook of emotions in education, pp. 36-55, (2014); 
Frijda N.H., Tcherkassof A., Facial expressions as modes of action readiness, The psychology of facial expression, pp. 103-132, (1997); 
Gavrilescu M., Vizireanu N., Predicting the sixteen personality factors (16PF) of an individual by analyzing facial features, EURASIP Journal on Image and Video Processing, 2017, 1, pp. 1-19, (2017); 
Gillies R.M., Promoting academically productive student dialogue during collaborative learning, International Journal of Educational Research, 97, July 2017, pp. 200-209, (2019); 
Goodman B.A., Linton F.N., Gaimari R.D., Hitzeman J.M., Ross H.J., Zarrella G., Using dialogue features to predict trouble during collaborative learning, User Modelling and User-Adapted Interaction, 15, 1, pp. 85-134, (2005); 
Hadwin A., Oshige M., Self-regulation, coregulation, and socially shared regulation: Exploring perspectives of social in self-regulated learning theory, Teachers College Record, 113, 2, pp. 240-264, (2011); 
Hayashi Y., Detecting collaborative learning through emotions: An investigation using facial expression recognition, Intelligent Tutoring Systems: 15th International Conference, ITS 2019, pp. 89-98, (2019); 
Hernandez-Garcia A., Acquila-Natale E., Chaparro-Pelaez J., Conde M., Predicting teamwork group assessment using log data-based learning analytics, Computers in Human Behavior, 89, March, pp. 373-384, (2018); 
Huang K., Bryant T., Schneider B., Identifying collaborative learning states using unsupervised machine learning on eye-tracking, physiological and motion sensor data, EDM 2019 - Proceedings of the 12th International Conference on Educational Data Mining, pp. 318-323, (2019); 
Huang X., Lajoie S.P., Social emotional interaction in collaborative learning: Why it matters and how can we measure it?, Social Sciences and Humanities Open, 7, 1, (2023); 
Isohatala J., Naykki P., Jarvela S., Cognitive and socio-emotional interaction in collaborative learning: Exploring fluctuations in Students' participation, Scandinavian Journal of Educational Research, 64, 6, pp. 831-851, (2020); 
Johnson D.W., Johnson R.T., Key to effective cooperation, Interaction in cooperative groups. The theoretical anatomy of group learning, pp. 174-199, (1992); 
King A., Structuring peer interaction to promote higher-order thinking and complex learning in cooperating groups, The teacher's role in implementing cooperative learning in the classroom, pp. 73-91, (2008); 
Liu Y., Wang T., Wang K., Zhang Y., Collaborative learning quality classification through physiological synchrony recorded by wearable biosensors, Frontiers in Psychology, 12, (2021); 
Martinez R., Kay J., Wallace J.R., Yacef K., Modelling symmetry of activity as an indicator of collocated group collaboration, User modeling, adaption and personalization, pp. 207-218, (2011); 
Martinez-Maldonado R., Clayphan A., Yacef K., Kay J., MTFeedback: Providing notifications to enhance teacher awareness of small group work in the classroom, IEEE Transactions on Learning Technologies, 8, 2, pp. 187-200, (2015); 
Martinez-Maldonado R., Dimitriadis Y., Martinez-Mones A., Kay J., Yacef K., Capturing and analyzing verbal and physical collaborative learning interactions at an enriched interactive tabletop, International Journal of Computer-Supported Collaborative Learning, 8, 4, pp. 455-485, (2013); 
Martinez-Maldonado R., Kay J., Buckingham Shum S., Yacef K., Collocated collaboration analytics: Principles and dilemmas for mining multimodal interaction data, Human-Computer Interaction, 34, 1, pp. 1-50, (2019); 
Ochoa X., Multimodal learning analytics, The handbook of learning analytics, pp. 129-141, (2017); 
Olsen J.K., Sharma K., Rummel N., Aleven V., Temporal analysis of multimodal data to predict collaborative learning outcomes, British Journal of Educational Technology, 51, 5, pp. 1527-1547, (2020); 
Ponce-Lopez V., Escalera S., Baro X., Multi-modal social signal analysis for predicting agreement in conversation settings, ICMI'13: Proceedings of the 2013 ACM International Conference on Multimodal Interaction, pp. 495-501, (2013); 
Praharaj S., Scheffel M., Drachsler H., Specht M., Co-located collaboration modelling using multimodal learning analytics—Can we go the whole nine yards ?, IEEE Transactions on Learning Technologies, 14, 3, pp. 367-385, (2021); 
Pugh S.L., Rao A., Stewart A.E.B., D'Mello S.K., Do speech-based collaboration analytics generalize across task contexts?, LAK22: 12th International Learning Analytics and Knowledge Conference, pp. 208-218, (2022); 
Reilly J.M., Schneider B., Predicting the quality of collaborative problem solving through linguistic analysis of discourse, EDM’2019: Proceedings of the 12th International Conference on Educational Data Mining, pp. 149-157, (2019); 
Rummel N., Deiglmayr A., Spada H., Kahrimanis G., Avouris N., Analyzing collaborative interactions across domains and settings: An adaptable rating scheme, Analyzing Interactions in CSCL, (2011); 
Rummel N., Spada H., Learning to collaborate: An instructional approach to promoting collaborative problem solving in computer-mediated settings, Journal of the Learning Sciences, 14, 2, pp. 201-241, (2005); 
Salomon G., Globerson T., When teams do not function the way they ought to, International Journal of Educational Research, 13, 1, pp. 89-99, (1989); 
Schneider B., Sung G., Chng E., Yang S., How can high-frequency sensors capture collaboration? A review of the empirical links between multimodal metrics and collaborative constructs, Sensors, 21, 24, (2022); 
Sell A., Cosmides L., Tooby J., The human anger face evolved to enhance cues of strength, Evolution and Human Behavior, 35, 5, pp. 425-429, (2014); 
Sharma K., Papavlasopoulou S., Giannakos M., Joint emotional state of children and perceived collaborative experience in coding activities, Proceedings of the 18th ACM International Conference on Interaction Design and Children, IDC 2019, pp. 133-145, (2019); 
Siatras S., Nikolaidis N., Krinidis M., Pitas I., Visual lip activity detection and speaker detection using mouth region intensities, IEEE Transactions on Circuits and Systems for Video Technology, 19, 1, pp. 133-137, (2009); 
Spikol D., Ruffaldi E., Dabisias G., Cukurova M., Supervised machine learning in multimodal learning analytics for estimating success in project-based learning, Journal of Computer Assisted Learning, 34, 4, pp. 366-377, (2018); 
Stahl G., Group cognition: Computer support for building collaborative knowledge, (2006); 
Stiefelhagen R., Zhu J., Head orientation and gaze direction in meetings, CHI 02 Extended Abstracts on Human Factors in Computer Systems CHI 02, 1, (2002); 
Storch N., How collaborative is pair work? ESL tertiary students composing in pairs, Language Teaching Research, 5, 1, pp. 29-53, (2001); 
Thomas C., Jayagopi D.B., Predicting student engagement in classrooms using facial behavioral cues, Proceedings of the 1st ACM SIGCHI International Workshop on Multimodal Interaction for Education, pp. 33-40, (2017); 
Viswanathan S.A., Vanlehn K., Using the tablet gestures and speech of pairs of students to classify their collaboration, IEEE Transactions on Learning Technologies, 11, 2, pp. 230-242, (2018); 
Webb N.M., Teacher practices and small-group dynamics in cooperative learning classrooms, The teacher's role in implementing cooperative learning in the classroom, pp. 201-221, (2008); 
Webb N.M., The teacher's role in promoting collaborative dialogue in the classroom, British Journal of Educational Psychology, 79, 1, pp. 1-28, (2009); 
Weinberger A., Fischer F., A framework to analyze argumentative knowledge construction in computer-supported collaborative learning, Computers & Education, 46, 1, pp. 71-95, (2006); 
Yoo J., Kim J., Can online discussion participation predict group project performance? Investigating the roles of linguistic features and participation patterns, International Journal of Artificial Intelligence in Education, 24, 1, pp. 8-32, (2014)#FRF#
