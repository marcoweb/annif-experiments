#ITI#Placebo or Assistant? Generative AI Between Externalization and Anthropomorphization#FTI#
#IRE# Generative AIs have been embraced by learners wishing to offload (parts of) complex tasks. However, recent research suggests that AI users are at risk of failing to correctly monitor the extent of their own contribution when being assisted by an AI. This difficulty in keeping track of the division of labor has been shown to result in placebo and ghostwriter effects. In case of the AI-based placebo effect, users overestimate their ability while or after being assisted by an AI. The ghostwriter effect occurs when AI users do not disclose their AI use despite being aware of the contribution made by an AI. These two troubling effects are discussed in the context of the conflict between cognitive externalization and anthropomorphization. While people tend to offload cognitive load into their environment, they also often perceive technology as human-like. However, despite the natural conversations that can be had with current AIs, the desire to attribute human-like qualities that would require the acknowledgment of AI contributions appears to be lacking. Implications and suggestions on how to improve AI use, for example, by employing embodied AI agents, are discussed.#FRE#
#IPC# Anthropomorphization; Artificial intelligence; Cognitive externalization; Embodiment; Ethics#FPC#
#IRF# Alkaissi H., McFarlane S.I., Artificial hallucinations in ChatGPT: Implications in scientific writing, Cureus, 15, 2, (2023); 
Baek T.H., Bakpayev M., Yoon S., Kim S., Smiling AI agents: How anthropomorphism and broad smiles increase charitable giving, International Journal of Advertising, 41, 5, pp. 850-867, (2022); 
Baek T.H., Kim M., Ai robo-advisor anthropomorphism: The impact of anthropomorphic appeals and regulatory focus on investment behaviors, Journal of Business Research, 164, (2023); 
Baek T.H., Kim M., Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence, Telematics and Informatics, 83, (2023); 
Bai L., Liu X., Su J., ChatGPT: The cognitive effects on learning and memory, Brain-X, 1, 3, (2023); 
Barrett A., Pack A., Not quite eye to AI: Student and teacher perspectives on the use of generative artificial intelligence in the writing process, International Journal of Educational Technology in Higher Education, 20, 1, (2023); 
Baylor A.L., The impact of three pedagogical agent roles, In Proceedings of the Second International Joint Conference on Autonomous Agents and Multiagent Systems, pp. 928-929, (2003); 
Bernabei M., Colabianchi S., Falegnami A., Costantino F., Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances, Computers and Education: Artificial Intelligence, 5, (2023); 
Blut M., Wang C., Wunderlich N.V., Brock C., Understanding anthropomorphism in service provision: A meta-analysis of physical robots, chatbots, and other AI, Journal of the Academy of Marketing Science, 49, pp. 632-658, (2021); 
Bouteraa M., Bin-Nashwan S.A., Al-Daihani M., Dirie K.A., Benlahcene A., Sadallah M., Chekima B., (2024); 
Bringula R., What do academics have to say about ChatGPT? A text mining analytics on the discussions regarding ChatGPT on research writing, AI and Ethics, pp. 1-13, (2023); 
Cassell J., Embodied conversational interface agents, Communications of the ACM, 43, 4, pp. 70-78, (2000); 
Chan C.K.Y., Hu W., Students’ voices on generative AI: Perceptions, benefits, and challenges in higher education, International Journal of Educational Technology in Higher Education, 20, 1, (2023); 
Czeszumski A., Gert A.L., Keshava A., Ghadirzadeh A., Kalthoff T., Ehinger B.V., Konig P., Coordinating with a robot partner affects neural processing related to action monitoring, Frontiers in Neurorobotics, 15, (2021); 
Draxler F., Werner A., Lehmann F., Hoppe M., Schmidt A., Buschek D., Welsch R., The AI ghostwriter effect: When users do not perceive ownership of AI-generated text but self-declare as authors, ACM Transactions on Computer-Human Interaction, 31, 2, pp. 1-40, (2024); 
Eaton S.E., Postplagiarism: Transdisciplinary ethics and integrity in the age of artificial intelligence and neurotechnology, International Journal for Educational Integrity, 19, 1, (2023); 
Eliseev E.D., Marsh E.J., Understanding why searching the internet inflates confidence in explanatory ability, Applied Cognitive Psychology, 37, 4, pp. 711-720, (2023); 
Elsayary A., An investigation of teachers’ perceptions of using ChatGPT as a supporting tool for teaching and learning in the digital era, Journal of Computer Assisted Learning, pp. 1-15, (2023); 
Farrokhnia M., Banihashem S.K., Noroozi O., Wals A., A SWOT analysis of ChatGPT: Implications for educational practice and research, Innovations in Education and Teaching International, pp. 1-15, (2023); 
Fisher M., Oppenheimer D.M., Harder than you think: How outside assistance leads to overconfidence, Psychological Science, 32, 4, pp. 598-610, (2021); 
Fisher M., Smiley A.H., Grillo T.L., Information without knowledge: The effects of Internet search on learning, Memory, 30, 4, pp. 375-387, (2022); 
Gao C.A., Howard F.M., Markov N.S., Dyer E.C., Ramesh S., Luo Y., Pearson A.T., Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers, npj Digital Medicine, 6, 1, (2023); 
Gill S.S., Kaur R., ChatGPT: Vision and challenges, Internet of Things and Cyber-Physical Systems, 3, pp. 262-271, (2023); 
Giray L., Prompt engineering with ChatGPT: A guide for academic writers, Annals of Biomedical Engineering, 51, 12, pp. 2629-2633, (2023); 
Haase J., Hanel P.H., Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity, Journal of Creativity, 33, 3, (2023); 
Habib S., Vogel T., Anli X., Thorne E., How does generative artificial intelligence impact student creativity?, Journal of Creativity, 34, 1, (2024); 
Hong J.W., Fischer K., Ha Y., Zeng Y., Human, I wrote a song for you: An experiment testing the influence of machines’ attributes on the AI-composed music evaluation, Computers in Human Behavior, 131, (2022); 
Hugenholtz P.B., Quintais J.P., Copyright and artificial creation: Does EU copyright law protect AI-assisted output?, IIC-International Review of Intellectual Property and Competition Law, 52, 9, pp. 1190-1216, (2021); 
Jacobs O., Pazhoohi F., Kingstone A., Brief exposure increases mind perception to ChatGPT and is moderated by the individual propensity to anthropomorphize, (2023); 
Janson A., How to leverage anthropomorphism for chatbot service interfaces: The interplay of communication style and personification, Computers in Human Behavior, 149, (2023); 
Kasneci E., Sessler K., Kuchemann S., Bannert M., Dementieva D., Fischer F., Kasneci G., ChatGPT for good? On opportunities and challenges of large language models for education, Learning and Individual Differences, (2023); 
Kosch T., Welsch R., Chuang L., Schmidt A., The placebo effect of artificial intelligence in human–computer interaction, ACM Transactions on Computer-Human Interaction, 29, 6, pp. 1-32, (2023); 
Laban G., Perceptions of anthropomorphism in a chatbot dialogue: The role of animacy and intelligence, . in Proceedings of the 9Th International Conference on Human-Agent Interaction, pp. 305-310, (2021); 
Lee H., The rise of ChatGPT: Exploring its potential in medical education, Anatomical Sciences Education, pp. 1-6, (2023); 
Lee S., Lee N., Sah Y.J., Perceiving a mind in a chatbot: Effect of mind perception and social cues on co-presence, closeness, and intention to use, International Journal of Human-Computer Interaction, 36, 10, pp. 930-940, (2020); 
Leon-Dominguez U., Potential cognitive risks of generative transformer-based AI chatbots on higher order executive functions, Neuropsychology, 38, 4, pp. 293-308, (2024); 
Li X., Sung Y., Anthropomorphism brings us closer: The mediating role of psychological distance in User–AI assistant interactions, Computers in Human Behavior, 118, (2021); 
Lund B.D., Wang T., Mannuru N.R., Nie B., Shimray S., Wang Z., ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing, Journal of the Association for Information Science and Technology, 74, 5, pp. 570-581, (2023); 
Ma X., Huo Y., Are users willing to embrace ChatGPT? Exploring the factors on the acceptance of chatbots from the perspective of AIDUA framework, Technology in Society, 75, (2023); 
Makady H., Human, I know how you feel: Individual psychological determinants influencing smartwatch anthropomorphism, Journal of Technology in Behavioral Science, pp. 1-18, (2023); 
Mogavi R.H., Deng C., Kim J.J., Zhou P., Kwon Y.D., Metwally A.H.S., Hui P., ChatGPT in education: A blessing or a curse? A qualitative study exploring early adopters’ utilization and perceptions, Computers in Human Behavior: Artificial Humans, 2, 1, (2024); 
Moorhouse B.L., Yeo M.A., Wan Y., Generative AI tools and assessment: Guidelines of the world's top-ranking universities, Computers and Education Open, 5, (2023); 
Mori M., The uncanny valley, Energy, 7, pp. 33-35, (1970); 
Ng D.T.K., Tan C.W., Leung J.K.L., Empowering student self-regulated learning and science education through ChatGPT: A pioneering pilot study, British Journal of Educational Technology, pp. 1-26, (2024); 
Nielsen Y.A., Pfattheicher S., Keijsers M., Prosocial behavior toward machines, Current Opinion in Psychology, 43, pp. 260-265, (2022); 
Niloy A.C., Akter S., Sultana N., Sultana J., Rahman S.I.U., Is Chatgpt a menace for creative writing ability? An experiment, Journal of Computer Assisted Learning, pp. 1-12, (2023); 
Pacherie E., The phenomenology of action: A conceptual framework, Cognition, 107, 1, pp. 179-217, (2008); 
Pelau C., Dabija D.C., Ene I., What makes an AI device human-like? The role of interaction quality, empathy and perceived psychological anthropomorphic characteristics in the acceptance of artificial intelligence in the service industry, Computers in Human Behavior, 122, (2021); 
Rajaobelina L., Prom Tep S., Arcand M., Ricard L., Creepiness: Its antecedents and impact on loyalty when interacting with a chatbot, Psychology & Marketing, 38, 12, pp. 2339-2356, (2021); 
Reeves B., Nass C., The media equation: How people treat computers, television, and new media like real people and places, (1996); 
Risko E.F., Gilbert S.J., Cognitive offloading, Trends in Cognitive Sciences, 20, 9, pp. 676-688, (2016); 
Roe J., Perkins M., What are automated paraphrasing tools and how do we address them? A review of a growing threat to academic integrity, International Journal for Educational Integrity, 18, 1, (2022); 
Seufert T., The interplay between self-regulation in learning and cognitive load, Educational Research Review, 24, pp. 116-129, (2018); 
Seufert T., Building bridges between self-regulation and cognitive load—An invitation for a broad and differentiated attempt, Educational Psychology Review, 32, 4, pp. 1151-1162, (2020); 
Siler J., Hamilton K.A., Benjamin A.S., Did you look that up? How retrieving from smartphones affects memory for source, Applied Cognitive Psychology, 36, 4, pp. 738-747, (2022); 
Skulmowski A., The cognitive architecture of digital externalization, Educational Psychology Review, 35, 4, (2023); 
Skulmowski A., Learning by doing or doing without learning? The potentials and challenges of activity-based learning, Educational Psychology Review, 36, (2024); 
Skulmowski A., Xu K.M., Understanding cognitive load in digital and online learning: A new perspective on extraneous cognitive load, Educational Psychology Review, 34, pp. 171-196, (2022); 
Sparrow B., Liu J., Wegner D.M., Google effects on memory: Cognitive consequences of having information at our fingertips, Science, 333, 6043, pp. 776-778, (2011); 
Stein J.P., Ohler P., Venturing into the uncanny valley of mind—The influence of mind attribution on the acceptance of human-like characters in a virtual reality setting, Cognition, 160, pp. 43-50, (2017); 
Sweller J., van Merrienboer J.J., Paas F.G., Cognitive architecture and instructional design, Educational Psychology Review, 10, 3, pp. 251-296, (1998); 
Sweller J., van Merrienboer J.J., Paas F., Cognitive architecture and instructional design: 20 years later, Educational Psychology Review, 31, 2, pp. 261-292, (2019); 
Thorp H.H., ChatGPT is fun, but not an author, Science, 379, 6630, (2023); 
Tlili A., Shehata B., Adarkwah M.A., Bozkurt A., Hickey D.T., Huang R., Agyemang B., What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education, Smart Learning Environments, 10, 1, (2023); 
Tschopp M., Gieselmann M., Sassenberg K., Servant by default? How humans perceive their relationship with conversational AI, Cyberpsychology: Journal of Psychosocial Research on Cyberspace, 17, 3, (2023); 
Urban M., Dechterenko F., Lukavsky J., Hrabalova V., Svacha F., Brom C., Urban K., ChatGPT improves creative problem-solving performance in university students: An experimental study, Computers & Education, (2024); 
Vaitonyte J., Alimardani M., Louwerse M.M., Scoping review of the neural evidence on the uncanny valley, Computers in Human Behavior Reports, 9, (2023); 
Villa S., Kosch T., Grelka F., Schmidt A., Welsch R., The placebo effect of human augmentation: Anticipating cognitive augmentation increases risk-taking behavior, Computers in Human Behavior, 146, (2023); 
Wahn B., Kingstone A., Humans share task load with a computer partner if (they believe that) it acts human-like, Acta Psychologica, 212, (2021); 
Wahn B., Schmitz L., Gerster F.N., Weiss M., Offloading under cognitive load: Humans are willing to offload parts of an attentionally demanding task to an algorithm, PLoS ONE, 18, 5, (2023); 
Wang S., Lilienfeld S.O., Rochat P., The uncanny valley: Existence and explanations, Review of General Psychology, 19, 4, pp. 393-407, (2015); 
Wang W., Smartphones as social actors? Social dispositional factors in assessing anthropomorphism, Computers in Human Behavior, 68, pp. 334-344, (2017); 
Ward A.F., People mistake the internet’s knowledge for their own, Proceedings of the National Academy of Sciences, 118, 43, (2021); 
Waytz A., Cacioppo J., Epley N., Who sees human? The stability and importance of individual differences in anthropomorphism, Perspectives on Psychological Science, 5, 3, pp. 219-232, (2010); 
Wirth J., Stebner F., Trypke M., Schuster C., Leutner D., An interactive layers model of self-regulated learning and cognitive load, Educational Psychology Review, 32, 4, pp. 1127-1149, (2020); 
Wolters C.A., Brady A.C., College students’ time management: A self-regulated learning perspective, Educational Psychology Review, 33, 4, pp. 1319-1351, (2021); 
Yam K.C., Bigman Y., Gray K., Reducing the uncanny valley by dehumanizing humanoid robots, Computers in Human Behavior, 125, (2021); 
Yam K.C., Goh E.Y., Fehr R., Lee R., Soh H., Gray K., When your boss is a robot: Workers are more spiteful to robot supervisors that seem more human, Journal of Experimental Social Psychology, 102, (2022); 
Yang Y., Liu Y., Lv X., Ai J., Li Y., Anthropomorphism and customers’ willingness to use artificial intelligence service agents, Journal of Hospitality Marketing & Management, 31, 1, pp. 1-23, (2022); 
Yilmaz R., Yilmaz F.G.K., The effect of generative artificial intelligence (AI)-based tool use on students’ computational thinking skills, programming self-efficacy and motivation, Computers and Education: Artificial Intelligence, 4, (2023); 
Zimmerman B.J., Becoming a self-regulated learner: An overview, Theory into Practice, 41, 2, pp. 64-70, (2002)#FRF#
