#ITI#The Impact of Sample Size and Various Other Factors on Estimation of Dichotomous Mixture IRT Models#FTI#
#IRE# The purpose of this study was to examine the effects of different data conditions on item parameter recovery and classification accuracy of three dichotomous mixture item response theory (IRT) models: the Mix1PL, Mix2PL, and Mix3PL. Manipulated factors in the simulation included the sample size (11 different sample sizes from 100 to 5000), test length (10, 30, and 50), number of classes (2 and 3), the degree of latent class separation (normal/no separation, small, medium, and large), and class sizes (equal vs. nonequal). Effects were assessed using root mean square error (RMSE) and classification accuracy percentage computed between true parameters and estimated parameters. The results of this simulation study showed that more precise estimates of item parameters were obtained with larger sample sizes and longer test lengths. Recovery of item parameters decreased as the number of classes increased with the decrease in sample size. Recovery of classification accuracy for the conditions with two-class solutions was also better than that of three-class solutions. Results of both item parameter estimates and classification accuracy differed by model type. More complex models and models with larger class separations produced less accurate results. The effect of the mixture proportions also differentially affected RMSE and classification accuracy results. Groups of equal size produced more precise item parameter estimates, but the reverse was the case for classification accuracy results. Results suggested that dichotomous mixture IRT models required more than 2,000 examinees to be able to obtain stable results as even shorter tests required such large sample sizes for more precise estimates. This number increased as the number of latent classes, the degree of separation, and model complexity increased.#FRE#
#IPC# dichotomous data; maximum likelihood estimation; mixture item response theory; Monte Carlo simulation; sample size#FPC#
#IRF# Akaike H., A new look at the statistical model identification, IEEE Transactions on Automatic Control, 19, pp. 716-723, (1974); 
Alexeev N., Templin J., Cohen A.S., Spurious latent classes in the mixture Rasch model, Journal of Educational Measurement, 48, 3, pp. 313-332, (2011); 
Austin E.J., Deary I.J., Egan V., Individual differences in response scale use: Mixed Rasch modelling of responses to NEO-FFI items, Personality and Individual Differences, 40, 6, pp. 1235-1245, (2006); 
Baker F.B., An investigation of the item parameter recovery characteristics of a Gibbs sampling approach, Applied Psychological Measurement, 22, pp. 153-169, (1998); 
Bolt D.M., Cohen A.S., Wollack J.A., A mixture item response model for multiple-choice data, Journal of Educational and Behavioral Statistics, 26, 4, pp. 381-409, (2001); 
Bolt D.M., Cohen A.S., Wollack J.A., Item parameter estimation under conditions of test speededness: Application of a mixture Rasch model with ordinal constraints, Journal of Educational Measurement, 39, 4, pp. 331-348, (2002); 
Cassiday K.R., Cho Y., Harring J.R., A comparison of label switching algorithms in the context of growth mixture models, Educational and Psychological Measurement, 81, 4, pp. 668-697, (2021); 
Cho H.J., Lee J., Kingston N., Examining the effectiveness of test accommodation using DIF and a mixture IRT model, Applied Measurement in Education, 25, 4, pp. 281-304, (2012); 
Cho S.J., Cohen A.S., Kim S.H., Markov chain Monte Carlo estimation of a mixture item response theory model, Journal of Statistical Computation and Simulation, 83, 2, pp. 278-306, (2013); 
Cho S.J., Cohen A.S., Kim S.H., Bottge B., Latent transition analysis with a mixture item response theory measurement model, Applied Psychological Measurement, 34, 7, pp. 483-504, (2010); 
Cho Y., The mixture distribution polytomous Rasch model used to account for response styles on rating scales: A simulation study of parameter recovery and classification accuracy, (2014); 
Cohen A.S., Bolt D.M., A mixture model analysis of differential item functioning, Journal of Educational Measurement, 42, 2, pp. 133-148, (2005); 
Cohen A.S., Bottge B.A., Wells C.S., Using item response theory to assess effects of mathematics instruction in special populations, Exceptional Children, 68, 1, pp. 23-44, (2001); 
Cohen A.S., Gregg N., Deng M., The role of extended time and item content on a high-stakes mathematics test, Learning Disabilities Research & Practice, 20, 4, pp. 225-233, (2005); 
de la Torre J., Hong Y., Parameter estimation with small sample size a higher-order IRT model approach, Applied Psychological Measurement, 34, 4, pp. 267-285, (2010); 
DeMars C.E., Lau A., Differential item functioning detection with latent classes: How accurately can we detect who is responding differentially?, Educational and Psychological Measurement, 71, 4, pp. 597-616, (2011); 
Finch H., French B.F., A comparison of estimation techniques for IRT models with small samples, Applied Measurement in Education, 32, 2, pp. 77-96, (2019); 
Finch W.H., French B.F., Parameter estimation with mixture item response theory models: A Monte Carlo comparison of maximum likelihood and Bayesian methods, Journal of Modern Applied Statistical Methods, 11, 1, pp. 167-178, (2012); 
Frederickx S., Tuerlinckx F., De Boeck P., Magis D., RIM: A random item mixture model to detect differential item functioning, Journal of Educational Measurement, 47, 4, pp. 432-457, (2010); 
Gluck J., Machat R., Jirasko M., Rollett B., Training-related changes in solution strategy in a spatial test: An application of item response models, Learning and Individual Differences, 13, 1, pp. 1-22, (2002); 
Hallquist M.N., Wiley J.F., MplusAutomation: An R package for facilitating large scale latent variable analyses in M plus, Structural Equation Modeling: A Multidisciplinary Journal, 25, 4, pp. 621-638, (2018); 
Hamner B., Frasco M., LeDell E., Package “Metrics, (2018); 
Huang H.Y., Mixture random-effect IRT models for controlling extreme response style on rating scales, Frontiers in Psychology, 7, (2016); 
Jiao H., Macready G., Liu J., Cho Y., A mixture Rasch model–based computerized adaptive test for latent class identification, Applied Psychological Measurement, 36, 6, pp. 469-493, (2012); 
Kelderman H., Macready G.B., The use of loglinear models for assessing differential item functioning across manifest and latent examinee groups, Journal of Educational Measurement, 27, 4, pp. 307-327, (1990); 
Kutscher T., Eid M., Crayen C., Sample size requirements for applying mixed Polytomous item response models: Results of a Monte Carlo simulation study, Frontiers in Psychology, 10, (2019); 
Lee S., Han S., Choi S.W., DIF detection with zero-inflation under the factor mixture modeling framework, Educational and Psychological Measurement, (2021); 
Lee W.Y., Cho S.J., Sterba S.K., Ignoring a multilevel structure in mixture item response models: Impact on parameter recovery and model selection, Applied Psychological Measurement, 42, 2, pp. 136-154, (2018); 
Li F., Cohen A.S., Kim S.H., Cho S.J., Model selection methods for mixture dichotomous IRT models, Applied Psychological Measurement, 33, 5, pp. 353-373, (2009); 
Maij-de Meij A.M., Kelderman H., van der Flier H., Fitting a mixture item response theory model to personality questionnaire data: Characterizing latent classes and investigating possibilities for improving prediction, Applied Psychological Measurement, 32, 8, pp. 611-631, (2008); 
Maij-de Meij A.M., Kelderman H., van der Flier H., Improvement in detection of differential item functioning using a mixture item response theory model, Multivariate Behavioral Research, 45, 6, pp. 975-999, (2010); 
Mislevy R.J., Verhelst N., Modeling item responses when different subjects employ different solution strategies, Psychometrika, 55, 2, pp. 195-215, (1990); 
Nye C.D., Joo S.H., Zhang B., Stark S., Advancing and evaluating IRT model data fit Indices in organizational research, Organizational Research Methods, 23, 3, pp. 457-486, (2020); 
Oliveri M.E., von Davier M., Investigation of model fit and score scale comparability in international assessments, Psychological Test and Assessment Modeling, 53, 3, pp. 315-333, (2011); 
Olmez I.B., Cohen A.S., A mixture partial credit analysis of math anxiety, International Journal of Assessment Tools in Education, 5, 4, pp. 611-630, (2018); 
Preinerstorfer D., Formann A.K., Parameter recovery and model selection in mixed Rasch models, British Journal of Mathematical and Statistical Psychology, 65, 2, pp. 251-262, (2012); 
R: A language and environment for statistical computing, (2021); 
Rost J., Rasch models in latent classes: An integration of two approaches to item analysis, Applied Psychological Measurement, 14, 3, pp. 271-282, (1990); 
Schwarz G., Estimating the dimension of a model, Annals of Statistics, 6, pp. 461-464, (1978); 
Sen S., Applying the mixed Rasch model to the Runco ideational behavior scale, Creativity Research Journal, 28, 4, pp. 426-434, (2016); 
Sen S., Cohen A.S., Applications of mixture IRT models: A literature review, Measurement: Interdisciplinary Research and Perspectives, 17, 4, pp. 177-191, (2019); 
Spiegelhalter D.J., Best N.G., Carlin B.P., Bayesian deviance, the effective number of parameters, and the comparison of arbitrarily complex models, (1998); 
Swaminathan H., Gifford J.A., Estimation of parameters in the three-parameter latent trait model, New horizons in testing, pp. 13-30, (1983); 
Swaminathan H., Hambleton R.K., Sireci S.G., Xing D., Rizavi S.M., Small sample estimation in dichotomous item response models: Effect of priors based on judgmental information on the accuracy of item parameter estimates, Applied Psychological Measurement, 27, 1, pp. 27-51, (2003); 
Wetzel E., Bohnke J.R., Rose N., A simulation study on methods of correcting for the effects of extreme response style, Educational and Psychological Measurement, 76, 2, pp. 304-324, (2016); 
Wright B.D., Solving measurement problems with the Rasch model, Journal of Educational Measurement, 14, 2, pp. 97-116, (1977)#FRF#
