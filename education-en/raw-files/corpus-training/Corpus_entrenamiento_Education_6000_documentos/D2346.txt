#ITI#Implementing a Standardized Effect Size in the POLYSIBTEST Procedure#FTI#
#IRE# A study was conducted to implement the use of a standardized effect size and corresponding classification guidelines for polytomous data with the POLYSIBTEST procedure and compare those guidelines with prior recommendations. Two simulation studies were included. The first identifies new unstandardized test heuristics for classifying moderate and large differential item functioning (DIF) for polytomous response data with three to seven response options. These are provided for researchers studying polytomous data using POLYSIBTEST software that has been published previously. The second simulation study provides one pair of standardized effect size heuristics that can be employed with items having any number of response options and compares true-positive and false-positive rates for the standardized effect size proposed by Weese with one proposed by Zwick et al. and two unstandardized classification procedures (Gierl; Golia). All four procedures retained false-positive rates generally below the level of significance at both moderate and large DIF levels. However, Weese’s standardized effect size was not affected by sample size and provided slightly higher true-positive rates than the Zwick et al. and Golia’s recommendations, while flagging substantially fewer items that might be characterized as having negligible DIF when compared with Gierl’s suggested criterion. The proposed effect size allows for easier use and interpretation by practitioners as it can be applied to items with any number of response options and is interpreted as a difference in standard deviation units.#FRE#
#IPC# DIF; differential item functioning; POLYSIBTEST; polytomous data; standardized effect size#FPC#
#IRF# ACT Aspire summative technical manual, (2020); 
Standards for educational and psychological testing, (2014); 
Andresen E., Malmgren J., Carter W., Patrick D., Screening for depression in well older adults—Evaluation of a short-form of the CES-D, American Journal of Preventive Medicine, 10, 2, pp. 77-84, (1994); 
Beck A.T., Ward C.H., Mendelson M., Mock J., Earbaugh J., An inventory for measuring depression, Archives of General Psychiatry, 4, pp. 561-571, (1961); 
Bock R.D., Estimating item parameters and latent ability when responses are scored in two or more nominal categories, Psychometrika, 37, pp. 29-51, (1972); 
Bolt D.M., A Monte Carlo comparison of parametric and nonparametric polytomous DIF detection methods, Applied Measurement in Education, 15, 2, pp. 113-141, (2002); 
Bolt D.M., Stout W., Differential item functioning: Its multidimensional model and resulting SIBTEST detection procedure, Behaviormetrika, 23, pp. 67-96, (1996); 
Chalmers R.P., mirt: A multidimensional item response theory package for the R environment, Journal of Statistical Software, 48, 6, pp. 1-29, (2012); 
Chang H.H., Mazzeo J., Roussos L., Detecting DIF for polytomously scored items: An adaptation of the SIBTEST procedure, Journal of Educational Measurement, 33, 3, pp. 333-353, (1996); 
Clauser B.E., Mazor K.M., Using statistical procedures to identify differentially functioning test items, Educational Measurement: Issues and Practice, 17, 1, pp. 31-44, (1998); 
Cohen A., Kim S., Baker F., Detection of differential item functioning in the graded response model, Applied Psychological Measurement, 17, 4, pp. 335-350, (1993); 
Crocker L.M., Algina J., Introduction to classical and modern test theory, (1986); 
French A., Miller T., Logistic regression and its use in detecting differential item functioning in polytomous items, Journal of Educational Measurement, 33, 3, pp. 315-332, (1996); 
Gierl M.J., Using dimensionality-based DIF analyses to identify and interpret constructs that elicit group differences, Educational Measurement: Issues and Practice, 24, 1, pp. 3-14, (2005); 
Gitchel W.D., Roessler R.T., Turner R.C., Gender effect according to item directionality on the perceived stress scale for adults with multiple sclerosis, Rehabilitation Counseling Bulletin, 55, 1, pp. 20-28, (2011); 
Gitchel W.D., Turner R., Rumrill P., Differential item functioning in rehabilitation research, Work (Reading, Mass.), 36, 3, pp. 361-369, (2010); 
Golia S., Differential item functioning classification for polytomously scored items, Electronic Journal of Applied Statistical Analysis, 5, 3, pp. 367-373, (2012); 
Hambleton R.K., Swaminathan H., Item response theory: Principles and applications, (1985); 
Hao S., Two SAS macros for differential item functioning analysis, Applied Psychological Measurement, 38, 1, pp. 81-82, (2014); 
Jiang H., Stout W., Improved type I error control and reduced estimation bias for DIF detection using SIBTEST, Journal of Educational and Behavioral Statistics, 23, 4, pp. 291-322, (1998); 
Jiang S., Wang C., Weiss D.J., Sample size requirements for estimation of item parameters in the multidimensional graded response model, Frontiers in Psychology, 7, (2016); 
John O.P., Donahue E.M., Kentle R.L., The Big Five Inventory, (1991); 
Keiffer E.A., Group-specific effects of matching subtest contamination on the identification of differential item functioning, (2011); 
Kelley K., Preacher K.J., On effect size, Psychological Methods, 17, 2, pp. 137-152, (2012); 
Kim S., Cohen A., Detection of differential item functioning under the graded response model with the likelihood ratio test, Applied Psychological Measurement, 22, 4, pp. 345-355, (1998); 
Kirk R.E., Experimental design: Procedures for the behavioral sciences, (1995); 
Lautenschlager G.J., Meade A.W., Kim S.-H., (2006); 
Masters G.N., A Rasch model for partial credit scoring, Psychometrika, 47, pp. 149-174, (1982); 
Muraki E., A generalized partial credit model: Application of an EM algorithm, Applied Psychological Measurement, 16, pp. 159-176, (1992); 
NAEP analysis and scaling—The SIBTEST procedure, (2008); 
Narayanan P., Swaminathan H., Performance of the Mantel-Haenszel and simultaneous item bias procedures for detecting differential item functioning, Applied Psychological Measurement, 18, 4, pp. 315-328, (1994); 
Penfield R.D., An approach for categorizing DIF in polytomous items, Applied Measurement in Education, 20, 3, pp. 335-355, (2007); 
Penfield R.D., Distinguishing between Net and Global DIF in polytomous items, Journal of Educational Measurement, 47, 2, pp. 129-149, (2010); 
Penfield R.D., An NCME instructional module on polytomous item response theory models, Educational Measurement, Issues and Practice, 33, 1, pp. 36-48, (2014); 
Penfield R.D., Alvarez K., Lee O., Using a taxonomy of differential step functioning to improve the interpretation of DIF in polytomous items: An illustration, Applied Measurement in Education, 22, 1, pp. 61-78, (2008); 
Preacher K.J., Kelley K., Effect size measures for mediation models: Quantitative strategies for communicating indirect effects, Psychological Methods, 16, 2, pp. 93-115, (2011); 
Radloff L.S., The CES-D scale: A self-report depression scale for research in the general population, Applied Psychological Measurement, 1, 3, pp. 385-401, (1977); 
Raju, The area between two item characteristic curves, Psychometrika, 53, 4, pp. 495-502, (1988); 
R: A language and environment for statistical computing, (2020); 
Rosenberg M., Society and the adolescent self-image, (1965); 
Roussos L.A., Stout W.F., Simulation studies of the effects of small sample size and studied item parameters on SIBTEST and Mantel-Haenszel type I error performance, Journal of Educational Measurement, 33, 2, pp. 215-230, (1996); 
Samejima F., Estimation of latent ability using a response pattern of graded scores, (1969); 
Shealy R., Stout W., A model-based standardization approach that separates true bias/DIF from group ability differences and detects test bias/DTF as well as item bias/DIF, Psychometrika, 58, 2, pp. 159-194, (1993); 
Smith T.W., Son J., Trends in public attitudes towards abortion, (2013); 
Steinberg L., Thissen D., Using effect sizes for research reporting: Examples using item response theory to analyze differential item functioning, Psychological Methods, 11, 4, pp. 402-415, (2006); 
Taylor C.S., Lee Y., Gender DIF in reading and mathematics tests with mixed item formats, Applied Measurement in Education, 25, 3, pp. 246-280, (2012); 
Thompson B., Statistical significance and effect size reporting: Portrait of a possible future, Research in the Schools, 5, 2, pp. 33-38, (1998); 
The World Bank, (2020); 
Turner R.C., Gitchel W.D., Keiffer E.A., Comparing Type I error and power rates in DIF analyses when combining significance tests with effect size criteria, (2011); 
Walker C.M., Gocer Sahin S., Using differential item functioning to test for interrater reliability in constructed response items, Educational and Psychological Measurement, 80, 4, pp. 808-820, (2020); 
Walker C.M., Zhang B., Banks K., Cappaert K., Establishing effect size guidelines for interpreting the results of differential bundle functioning analyses using SIBTEST, Educational and Psychological Measurement, 72, 3, pp. 415-434, (2011); 
Weese J.D., Development of an effect size to classify the magnitude of DIF in dichotomous and polytomous items, (2020); 
Weese J.D., DIFSIB: A SIBTEST package, Applied Psychological Measurement, 46, 1, pp. 68-69, (2021); 
Woods C.M., DIF testing for ordinal items with Poly-SIBTEST, the Mantel and GMH tests, and IRT-LR-DIF when the latent distribution is nonnormal for both groups, Applied Psychological Measurement, 35, 2, pp. 145-164, (2010); 
Yarkoni T., The abbreviation of personality, or how to measure 200 personality scales with 200 items, Journal of Research in Personality, 44, 2, pp. 180-198, (2010); 
Zung W.W., A rating instrument for anxiety disorders, Psychosomatics: Journal of Consultation and Liaison Psychiatry, 12, 6, pp. 371-379, (1971); 
Zwick R., A review of ETS differential item functioning assessment procedures: Flagging rules, minimum sample size requirements, and criterion refinement, ETS Research Report Series, 2012, 1, (2012); 
Zwick R., Thayer D.T., Mazzeo J., Describing and categorizing DIF in polytomous items, (1997)#FRF#
