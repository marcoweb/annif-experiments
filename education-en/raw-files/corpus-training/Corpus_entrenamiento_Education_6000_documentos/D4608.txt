#ITI#Can you spot the bot? Identifying AI-generated writing in college essays#FTI#
#IRE#The release of ChatGPT in 2022 has generated extensive speculation about how Artificial Intelligence (AI) will impact the capacity of institutions for higher learning to achieve their central missions of promoting learning and certifying knowledge. Our main questions were whether people could identify AI-generated text and whether factors such as expertise or confidence would predict this ability. The present research provides empirical data to inform these speculations through an assessment given to a convenience sample of 140 college instructors and 145 college students (Study 1) as well as to ChatGPT itself (Study 2). The assessment was administered in an online survey and included an AI Identification Test which presented pairs of essays: In each case, one was written by a college student during an in-class exam and the other was generated by ChatGPT. Analyses with binomial tests and linear modeling suggested that the AI Identification Test was challenging: On average, instructors were able to guess which one was written by ChatGPT only 70% of the time (compared to 60% for students and 63% for ChatGPT). Neither experience with ChatGPT nor content expertise improved performance. Even people who were confident in their abilities struggled with the test. ChatGPT responses reflected much more confidence than human participants despite performing just as poorly. ChatGPT responses on an AI Attitude Assessment measure were similar to those reported by instructors and students except that ChatGPT rated several AI uses more favorably and indicated substantially more optimism about the positive educational benefits of AI. The findings highlight challenges for scholars and practitioners to consider as they navigate the integration of AI in education. © The Author(s) 2024.#FRE#
#IPC#Academic integrity; Artificial intelligence; ChatGPT; Cheating; Confidence; Higher education#FPC#
#IRF#Al Darayseh A., Acceptance of artificial intelligence in teaching science: Science teachers’ perspective, Computers Education: Artif Intell, 4, (2023); 
Bertram Gallant T., Creating the ethical academy, (2011); 
Biswas S.S., Potential use of Chat GPT in global warming, Ann Biomed Eng, 51, pp. 1126-1127, (2023); 
Borenstein J., Howard A., Emerging challenges in AI and the need for AI ethics education, AI Ethics, 1, pp. 61-65, (2021); 
Bretag T., Handbook of Academic Integrity, (2016); 
Bretag T., Harper R., Burton M., Ellis C., Newton P., Rozenberg P., van Haeringen K., Contract cheating: a survey of Australian university students, Stud High Educ, 44, 11, pp. 1837-1856, (2019); 
Brown T.B., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D., Wu J., Winter C., Amodei D., Language models are few-shot learners, Adv Neural Inf Process Syst, 33, (2020); 
Chen Y., Andiappan M., Jenkin T., Ovchinnikov A., A Manager and an AI Walk into a Bar: Does Chatgpt Make Biased Decisions like We Do? SSRN 4380365, (2023); 
Chi M.T.H., Wylie R., The ICAP framework: linking cognitive engagement to active learning outcomes, Educational Psychol, 49, 4, pp. 219-243, (2014); 
Chocarro R., Cortinas M., Marcos-Matas G., Teachers’ attitudes towards chatbots in education: a technology acceptance model approach considering the effect of social language, bot proactiveness, and users’ characteristics, Educational Stud, 49, 2, pp. 295-313, (2023); 
Cizek G.J., Cheating on tests: How to do it, detect it, and prevent it, (1999); 
: A language and environment for statistical computing R Foundation for Statistical Computing, Vienna, Austria., (2021); 
Cotton D.R.E., Cotton P.A., Shipway J.R., Chatting and cheating: ensuring academic integrity in the era of ChatGPT, Innovations Educ Teach Int, (2023); 
Curtis G.J., Clare J., How prevalent is contract cheating and to what extent are students repeat offenders?, J Acad Ethics, 15, pp. 115-124, (2017); 
Dalalah D., Dalalah O.M.A., The false positives and false negatives of generative AI detection tools in education and academic research: the case of ChatGPT, Int J Manage Educ, 21, 2, (2023); 
Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: pre-training of deep bidirectional transformers for language understanding, ArXiv, (2018); 
Dwivedi Y.K., Kshetri N., Hughes L., Slade E.L., Jeyaraj A., Kar A.K., Baabdullah A.M., Koohang A., Raghavan V., Ahuja M., Albanna H., Albashrawi M.A., Al-Busaidi A.S., Balakrishnan J., Barlette Y., Basu S., Bose I., Brooks L., Buhalis D., Wright R., So what if ChatGPT wrote it? Multidisciplinary perspectives on opportunities, challenges, and implications of generative conversational AI for research, practice, and policy, Int J Inf Manag, 71, (2023); 
Eke D.O., ChatGPT and the rise of generative AI: threat to academic integrity?, J Responsible Technol, 13, (2023); 
Erickson S., Heit E., Metacognition and confidence: comparing math to other academic subjects, Front Psychol, 6, (2015); 
Fischer I., Budescu D.V., When do those who know more also know more about how much they know? The development of confidence and performance in categorical decision tasks, Organ Behav Hum Decis Process, 98, pp. 39-53, (2005); 
Fleming S.M., Weil R.S., Nagy Z., Dolan R.J., Rees G., Relating introspective accuracy to individual differences in brain structure, Science, 329, pp. 1541-1543, (2010); 
Fowler G.A., April 14 We tested a new ChatGPT-detector for teachers, It Flagged an Innocent Student., (2023); 
Gigerenzer G., From tools to theories: a heuristic of discovery in cognitive psychology, Psychol Rev, 98, (1991); 
Gigerenzer G., Hoffrage U., Kleinbolting H., Probabilistic mental models: a brunswikian theory of confidence, Psychol Rev, 98, 4, pp. 506-528, (1991); 
Gilson A., Safranek C., Huang T., Socrates V., Chi L., Taylor R.A., Chartash D., How well does ChatGPT do when taking the medical licensing exams? The implications of large language models for medical education and knowledge assessment, MedRxiv, (2022); 
Goodwins T., December 12 ChatGPT has mastered the confidence trick, and that’s a terrible look for AI, The Register, (2022); 
Gunser V.E., Gottschling S., Brucker B., Richter S., Gerjets P., Can users distinguish narrative texts written by an artificial intelligence writing tool from purely human text?, HCI International 2021, Communications in Computer and Information Science, 1419, pp. 520-527, (2021); 
Hartshorne H., May M.A., Studies in the nature of character: vol. I. studies in deceit, (1928); 
Hox J., Multilevel analysis: techniques and applications, (2010); 
Jakesch M., Hancock J.T., Naaman M., Human heuristics for AI-generated language are flawed, Proceedings of the National Academy of Sciences, 120, 11, (2023); 
Jiang F., Jiang Y., Zhi H., Dong Y., Li H., Ma S., Wang Y., Dong Q., Shen H., Wang Y., Artificial intelligence in healthcare: past, present and future, Stroke Vascular Neurol, 2, 4, pp. 230-243, (2017); 
Joo Y.J., Park S., Lim E., Factors influencing preservice teachers’ intention to use technology: TPACK, teacher self-efficacy, and technology acceptance model, J Educational Technol Soc, 21, 3, pp. 48-59, (2018); 
Kasneci E., Sessler K., Kuchemann S., Bannert M., Dementieva D., Fischer F., Kasneci G., ChatGPT for good? On opportunities and challenges of large language models for education, Learn Individual Differences, 103, (2023); 
Katz D.M., Bommarito M.J., Gao S., Arredondo P., GPT-4 passes the bar exam, SSRN Electron J, (2023); 
Kobis N., Mossink L.D., Artificial intelligence versus Maya Angelou: experimental evidence that people cannot differentiate AI-generated from human-written poetry, Comput Hum Behav, 114, (2021); 
Kobis N.C., Dolezalova B., Soraperra I., Fooled twice: people cannot detect deepfakes but think they can, iScience, 24, 11, (2021); 
Lo C.K., What is the impact of ChatGPT on education? A rapid review of the literature, Educ Sci, 13, 4, (2023); 
McCabe D.L., Butterfield K.D., Trevino L.K., Cheating in college: why students do it and what educators can do about it, (2012); 
Mitchell A., Professor catches student cheating with ChatGPT: ‘I feel abject terror, New York Post, (2022); 
Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language models are unsupervised multitask learners, (2019); 
Rettinger D.A., Bertram Gallant T., Cheating Academic Integrity: Lessons from 30 Years of Research, (2022); 
Rosenzweig-Ziff D., New York City blocks use of the ChatGPT bot in its schools, Wash Post, (2023); 
Salvi F., Ribeiro M.H., Gallotti R., West R., On the conversational persuasiveness of large language models: a randomized controlled trial, ArXiv, (2024); 
Shynkaruk J.M., Thompson V.A., Confidence and accuracy in deductive reasoning, Mem Cognit, 34, 3, pp. 619-632, (2006); 
Stokel-Walker C., AI bot ChatGPT writes smart essays — should professors worry?, Nature, (2022); 
Susnjak T., ChatGPT: The end of online exam integrity?, Arxiv, (2022); 
Svrluga S., Princeton student builds app to detect essays written by a popular AI bot, Wash Post, (2023); 
Terwiesch C., Would Chat GPT3 get a Wharton MBA? A prediction based on its performance in the Operations Management course, Mack Institute for Innovation Management at the Wharton School, (2023); 
Tlili A., Shehata B., Adarkwah M.A., Bozkurt A., Hickey D.T., Huang R., Agyemang B., What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education, Smart Learn Environ, 10, (2023); 
Turing A.M., Computing machinery and intelligence, Mind - Q Rev Psychol Philos, 236, pp. 433-460, (1950); 
GenAI, cheating and reporting to the AI office [Announcement], UCSD Academic Integrity Office, (2023); 
Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Polosukhin I., Attention is all you need, Adv Neural Inf Process Syst, 30, (2017); 
Waltzer T., Dahl A., Why do students cheat? Perceptions, evaluations, and motivations, Ethics Behav, 33, 2, pp. 130-150, (2023); 
Waltzer T., Cox R.L., Heyman G.D., Testing the ability of teachers and students to differentiate between essays generated by ChatGPT and high school students, Hum Behav Emerg Technol, 2023, (2023); 
Waltzer T., DeBernardi F.C., Dahl A., Student and teacher views on cheating in high school: perceptions, evaluations, and decisions, J Res Adolescence, 33, 1, pp. 108-126, (2023); 
Weidinger L., Mellor J., Rauh M., Griffin C., Uesato J., Huang P.S., Gabriel I., Ethical and social risks of harm from language models, ArXiv, (2021); 
Wixted J.T., Wells G.L., The relationship between eyewitness confidence and identification accuracy: a new synthesis, Psychol Sci Public Interest, 18, 1, pp. 10-65, (2017); 
Yeadon W., Inyang O.O., Mizouri A., Peach A., Testrow C., The death of the short-form physics essay in the coming AI revolution, Phys Educ, 58, (2023); 
Zhuo T.Y., Huang Y., Chen C., Xing Z., Red teaming ChatGPT via jailbreaking: bias, robustness, reliability and toxicity, ArXiv, (2023)#FRF#
