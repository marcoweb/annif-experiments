#ITI#Using data walls to display assessment results: a review of their affective impacts on teachers and students#FTI#
#IRE#Data walls are a data use practice increasingly being adopted in western, Anglophone countries to display student academic achievement data. The purpose of data walls is to improve teaching and learning by helping teachers and/or students to identify patterns of growth and achievement, set goals, and plan instructional interventions or self-regulate. This paper presents a systematic review of 30 empirical studies to explore how data wall use affectively impacts students and teachers, as well as related effects on their privacy and motivation. The review found that data wall displays elicited a range of positive and negative emotional responses, depending on variables such as the display’s location, contents, and associated social practices. Data walls were reported as enhancing motivation by helping stakeholders to sustain focus on and track progress towards goals, or by fostering comparison and competition. Data walls where class and/or individual students’ data could be identified, for example, through names, pictures, or small sample size, also generated concerns around privacy. These issues highlight the need to consider how data wall use aligns not only with relevant legislation, but also community expectations#FRE#
#IPC#Data wall/s; emotional response; motivation; privacy; public display of data; student and teacher well-being#FPC#
#IRF#Abrams L., Varier D., Jackson L., Unpacking instructional alignment: The influence of teachers’ use of assessment data on instruction, Perspectives in Education, 34, 4, pp. 15-28, (2016); 
Testing, motivation, and learning, (2002); 
Azevedo R., Taub M., Mudrick N.V., Millar G.C., Bradbury A.E., Price M.J., Using data visualizations to foster emotion regulation during self-regulated learning with advanced learning technologies, Informational environments: Effects of use, effective designs, pp. 225-247, (2017); 
Boekaerts M., Corno L., Self-regulation in the classroom: A perspective on assessment and intervention, Applied Psychology, 54, 2, pp. 199-231, (2005); 
Brown G., Harris L.R., Handbook of human and social conditions in assessment, (2016); 
Campbell T., Implementing professional learning communities at the high school level: Obstacles and solutions experienced by one Tennessee high school, Unpublished doctoral thesis, (2016); 
Carless D., Lam R., The examined life: Perspectives of lower primary school students in Hong Kong, Education 3-13, 42, 3, pp. 313-329, (2014); 
Carter M., A multiple case study of NAPLAN numeracy testing of Year 9 students in three Queensland secondary schools, Unpublished doctoral thesis, (2014); 
Christoph R., Organizing data for instructional use in one elementary school: An action research study, Unpublished doctoral thesis, (2014); 
Cizek G., More unintended consequences of high-stakes testing, Educational Measurement: Issues and Practice, 20, 4, pp. 19-27, (2001); 
Cochrane S., The little school that could: A case study contextualizing “data to inform instruction” through one school’s data transformation story, Unpublished doctoral thesis, (2016); 
Coffey A., Atkinson P., Making sense of qualitative data: Complementary research strategies, (1996); 
Cumming J., Wyatt-Smith C., Colbert P., Students at risk and NAPLAN: The collateral damage, National testing in schools: An Australian assessment, pp. 126-138, (2016); 
Earl L., Leadership for evidence-informed conversations, Professional learning conversations: Challenges in using evidence for improvement, pp. 43-52, (2009); 
Elwood J., Murphy P., Assessment systems as cultural scripts: A sociocultural theoretical lens on assessment practice and products, Assessment in Education: Principles, Policy and Practice, 22, 2, pp. 182-192, (2015); 
Glasswell K., Singh P., McNaughton S., Partners in design: Co-inquiry for quality teaching in disadvantaged schools, Australian Journal of Language & Literacy, 39, 1, pp. 20-29, (2016); 
Goss P., Hunter J., Romanes D., Parsonage H., Targeted teaching: How better use of data can improve student learning, (2015); 
Gough D., Oliver S., Tomas J., An introduction to systematic reviews, (2012); 
Green L., Holloway D., Introduction: Problematising the treatment of children’s data, Media International Australia, 170, 1, pp. 22-26, (2019); 
Hardy I., A logic of appropriation: Enacting national testing (NAPLAN) in Australia, Journal of Education Policy, 29, 1, pp. 1-18, (2014); 
Harris L.M., Perceptions of teachers about using and analyzing data to inform instruction, Unpublished doctoral thesis, (2018); 
Harris L.R., Brown G., The human and social experience of assessment: Valuing the person and context, Handbook of human and social conditions in assessment, pp. 1-17, (2016); 
Hartong S., Between assessments, digital technologies and big data: The growing influence of ‘hidden’ data mediators in education, European Educational Research Journal, 15, 5, pp. 523-536, (2016); 
Hazelkorn E., The impact of league tables and ranking systems on higher education decision making, Higher Education Management and Policy, 19, 2, pp. 87-110, (2007); 
Hazelkorn E., Attitudes to rankings: Comparing German, Australian and Japanese experiences, Quality assurance and university rankings in higher education in the Asia Pacific: Challenges for universities and nations, pp. 123-146, (2010); 
Jimerson J., Cho V., Scroggins K., Balial R., Robinson R., How and why teachers engage students with data, Educational Studies, 45, 6, pp. 667-691, (2019); 
Jimerson J., Cho V., Wayman J., Student-involved data use: Teacher practices and considerations for professional learning, Teaching and Teacher Education, 60, pp. 413-424, (2016); 
Jimerson J., Reames E., Student-involved data use: Establishing the evidence base, Journal of Educational Change, 16, 3, pp. 281-304, (2015); 
Kensler L., Reames E., Murray J., Patrick L., Systems thinking tools for improving evidence-based practice: A cross-case analysis of two high school leadership teams, The High School Journal, 95, 2, pp. 32-53, (2012); 
Kiro C., Hynds A., Eaton J., Irving E., Wilson A., Bendikson L., Cockle V., Broadwith M., Linley-Richardson T., Rangi M., The Starpath Project: Starpath phase 2 final summative evaluation report, (2016); 
Klenowski V., Wyatt-Smith C., The impact of high stakes testing: The Australian story, Assessment in Education: Principles, Policy & Practice, 19, 1, pp. 65-79, (2012); 
Koyama J., Global scare tactics and the call for US schools to be held accountable, American Journal of Education, 120, 1, pp. 77-99, (2013); 
Lonn S., Aguilar S.J., Teasley S.D., Investigating student motivation in the context of a learning analytics intervention during a summer bridge program, Computers in Human Behavior, 47, pp. 90-97, (2015); 
Lupton D., Williamson B., The datafied child: The dataveillance of children and implications for their rights, New Media & Society, 19, 5, pp. 780-794, (2017); 
Mandinach E., Parton B., Gummer E., Anderson R., Ethical and appropriate data use requires data literacy, Phi Delta Kappan, 96, 5, pp. 25-28, (2015); 
Manolev J., Sullivan A., Slee R., The datafication of discipline: ClassDojo, surveillance and a performative classroom culture, Learning, Media and Technology, 44, 1, pp. 36-51, (2019); 
Marsh J., Farrell C., Bertrand M., Trickle- down accountability: How middle school teachers engage students in data use, Educational Policy, 30, 2, pp. 243-280, (2016); 
McMillan J., Using students’ assessment mistakes and learning deficits to enhance motivation and learning, (2018); 
Messick S., Validity, Educational measurement, pp. 13-103, (1989); 
Nichols S., Berliner D., Collateral damage: How high-stakes testing corrupts America’s schools, (2007); 
Nichols S., Harris L.R., Accountability assessment’s effects on teachers and schools, Handbook of human and social conditions in assessment, pp. 40-56, (2016); 
Parham A., Data driven decision making for school improvement planning: Toward a model and process for distributive leadership and shared decision making, Unpublished doctoral thesis, (2015); 
Polonetsky J., Jerome J., Student data: Trust, transparency and the role of consent, (2014); 
Potenziano P., Opportunity to learn: The role of structures and routines in understanding and addressing educational inequities, Unpublished doctoral thesis, (2014); 
Rennie E., Schmieder K., Thomas J., Howard S.K., Ma J., Yang J., Privacy and app use in Australian primary schools: Insights into school-based internet governance, Media International Australia, 170, 1, pp. 78-89, (2019); 
Renshaw P., Baroutsis A., van Kraayenoord C., Goos M., Dole S., Teachers using classroom data well: Identifying key features of effective practices, (2013); 
Reyes A., Garcia A., Turnaround policy and practice: A case study of turning around a failing school with English-Language-Learners, The Urban Review, 46, 3, pp. 349-371, (2014); 
Roegman R., Perkins-Williams R., Maeda Y., Greenan K.A., Developing data leadership: Contextual influences on administrators’ data use, Journal of Research on Leadership Education, 13, 4, pp. 348-374, (2018); 
Salmi J., Saroyan A., League tables as policy instruments: Uses and misuses, Higher Education Management and Policy, 19, 2, pp. 31-68, (2007); 
Sharratt L., Fullan M., Putting FACES on the data: What great leaders do!, (2012); 
Sims W., Similarities and differences in decision-making processes and practices among elementary school principals in program improvement Year I, Year 3, and Year 5 schools, Unpublished doctoral thesis, (2011); 
Singh P., Performativity, affectivity and pedagogic identities, European Educational Research Journal, 17, 4, pp. 489-506, (2018); 
Singh P., Glasswell K., Chasing social change: Matters of concern and the mattering practice of educational research, International Journal of Innovation, Creativity and Change, 1, 2, pp. 1-15, (2013); 
Singh P., Glasswell K., Distributed leadership policies and practices: Striving for educational equity in high poverty contexts, Leadership in diverse learning contexts, pp. 255-274, (2016); 
Singh P., Martsin M., Glasswell K., Dilemmatic spaces: High-stakes testing and the possibilities of collaborative knowledge work to generate learning innovations, Teachers and Teaching, 21, 4, pp. 379-399, (2015); 
Spina N., The quantification of education and the reorganisation of teachers’ work: An institutional ethnography, Unpublished doctoral thesis, (2017); 
Supovitz J., Klein V., Mapping a course for improved student learning: How innovative schools systematically use student performance data to guide improvement, (2003); 
Thrupp M., The search for better educational standards: A cautionary tale, (2018); 
Thrupp M., White M., Research, analysis and insight into national standards (RAINS) project final report: National standards and the damage done, (2013); 
Tierney R., Koch M., Privacy in classroom assessment, Handbook of human and social conditions in assessment, pp. 267-283, (2016); 
Vogl E., Pekrun R., Emotions that matter to achievement: Student feelings about assessment, Handbook of human and social conditions in assessment, pp. 111-128, (2016); 
Williamson B., Digital education governance: Data visualization, predictive analytics, and ‘real-time’ policy instruments, Journal of Education Policy, 31, 2, pp. 123-141, (2016); 
Wyatt-Smith C., Adie L., Harris L., Data walls and classroom learning: What are the questions that matter? Independent Education Union (NSW/ACU)Newsmonth, 38(4), 4. , (2018); 
Wyatt-Smith C., Lingard B., Heck E., Digital learning assessments and big data: Implications for teacher professionalism, UNESCO Education Research and Foresight Working Papers, (2019)

﻿Scopus
EXPORT DATE: 28 July 2024#FRF#
